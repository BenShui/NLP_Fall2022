{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99fee9e0-8fac-4617-a4c5-1264232dfa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Collecting transformers\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/a4/df/3248eac2923ceffdf55686ff318e002b558e7c51f6a909dd870cf3185949/transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/5d/b7/33ebbd6b6b362203c19c854935f72381ba36525bc996c63bfce6b9874e09/huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 62.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Collecting filelock\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/94/b3/ff2845971788613e646e667043fdb5f128e2e540aefa09a3c55be8290d6d/filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/d7/42/7ad4b6d67a16229496d4f6e74201bdbebcf4bc1e87d5a70c9297d4961bd2/PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[K     |████████████████████████████████| 701 kB 23.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/21/1f/f54c156ac95a89d33113d78a18c03db8c00600392d6d6c5a18249c563c58/regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[K     |████████████████████████████████| 772 kB 45.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/fa/33/acfd230f5c3e7d19bfae949dca45c230fbf1d4d6f62a0b2365caac17c37a/tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 72.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in ./miniconda3/lib/python3.8/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./miniconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Installing collected packages: pyyaml, filelock, tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.11.0 pyyaml-6.0 regex-2022.10.31 tokenizers-0.13.2 transformers-4.24.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a3289f-c477-4835-bcce-4723b1de0b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Collecting seqeval\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 942 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in ./miniconda3/lib/python3.8/site-packages (from seqeval) (1.21.2)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/91/d1/50eb92222e8b2f315ec5499b97a926d271305e19e254fdced4db899647d6/scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 20.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/3e/d5/0163eb0cfa0b673aa4fe1cd3ea9d8a81ea0f32e50807b0c295871e4aab2e/joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 51.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.3.2\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/56/af/6a2b90fe280e89466d84747054667f74b84a8304f75931a173090919991f/scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.8 MB 55.6 MB/s eta 0:00:01��████████████████▍       | 25.7 MB 55.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=bec7e221c253c7e6925e716ec740e17944b85dd5c1537f633139e811d78cd6f2\n",
      "  Stored in directory: /root/.cache/pip/wheels/d8/60/5b/7babf53ca8486b6c5465ec2612e473bd61bd34bd1997d07bd9\n",
      "Successfully built seqeval\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, seqeval\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.1.2 scipy-1.9.3 seqeval-1.2.2 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c951292d-4c8a-4184-a497-15ee5c9f2410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 6365 tokens, filter count<5 tokens, save 5319 tokens.\n",
      "data/dev.txt's datasize is 28626\n",
      "data/test.txt's datasize is 28626\n",
      "data/train.txt's datasize is 229017\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b18fbf-7ce0-46c0-a08c-7ec7cabba079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(adam_epsilon=1e-08, dev_batch_size=6, dev_file='./data/dev.txt', device=device(type='cuda', index=0), embedding_dim=50, evaluate_step=1000, hidden_dim=200, hidden_dropout_prob=0.2, learning_rate=5e-05, max_grad_norm=1.0, max_len=256, mode='train', num_train_epochs=5, output_dir='./output/bilstm.result', save_model='./save_model/bilstm.pt', test_file='./data/test.txt', train_batch_size=12, train_file='./data/train.txt', warmup_steps=0, word2id_file='./data/word2id.json')\n",
      "loading training dataset\n",
      "100%|████████████████████████████████| 229016/229016 [00:22<00:00, 10144.22it/s]\n",
      "loading dev datasets...\n",
      "100%|██████████████████████████████████| 28626/28626 [00:01<00:00, 15271.49it/s]\n",
      "/root/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples =  229016\n",
      "  Num Epochs =  5\n",
      "/root/bilstm_crf.py:363: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorCompare.cpp:255.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "Train Epoch[1] Step[1 / 19085] - loss: 132.314850  \n",
      "Train Epoch[1] Step[21 / 19085] - loss: 118.913940  \n",
      "Train Epoch[1] Step[41 / 19085] - loss: 94.056030  \n",
      "Train Epoch[1] Step[61 / 19085] - loss: 122.951019  \n",
      "Train Epoch[1] Step[81 / 19085] - loss: 76.036057  \n",
      "Train Epoch[1] Step[101 / 19085] - loss: 49.493999  \n",
      "Train Epoch[1] Step[121 / 19085] - loss: 29.867542  \n",
      "Train Epoch[1] Step[141 / 19085] - loss: 58.683086  \n",
      "Train Epoch[1] Step[161 / 19085] - loss: 38.567520  \n",
      "Train Epoch[1] Step[181 / 19085] - loss: 55.569225  \n",
      "Train Epoch[1] Step[201 / 19085] - loss: 30.647030  \n",
      "Train Epoch[1] Step[221 / 19085] - loss: 49.810711  \n",
      "Train Epoch[1] Step[241 / 19085] - loss: 42.517162  \n",
      "Train Epoch[1] Step[261 / 19085] - loss: 19.508137  \n",
      "Train Epoch[1] Step[281 / 19085] - loss: 44.825176  \n",
      "Train Epoch[1] Step[301 / 19085] - loss: 27.748938  \n",
      "Train Epoch[1] Step[321 / 19085] - loss: 39.708771  \n",
      "Train Epoch[1] Step[341 / 19085] - loss: 30.779205  \n",
      "Train Epoch[1] Step[361 / 19085] - loss: 44.985210  \n",
      "Train Epoch[1] Step[381 / 19085] - loss: 42.069221  \n",
      "Train Epoch[1] Step[401 / 19085] - loss: 21.892052  \n",
      "Train Epoch[1] Step[421 / 19085] - loss: 43.317909  \n",
      "Train Epoch[1] Step[441 / 19085] - loss: 49.924591  \n",
      "Train Epoch[1] Step[461 / 19085] - loss: 19.720734  \n",
      "Train Epoch[1] Step[481 / 19085] - loss: 36.351681  \n",
      "Train Epoch[1] Step[501 / 19085] - loss: 36.881256  \n",
      "Train Epoch[1] Step[521 / 19085] - loss: 14.808632  \n",
      "Train Epoch[1] Step[541 / 19085] - loss: 36.669498  \n",
      "Train Epoch[1] Step[561 / 19085] - loss: 40.386311  \n",
      "Train Epoch[1] Step[581 / 19085] - loss: 20.536072  \n",
      "Train Epoch[1] Step[601 / 19085] - loss: 44.532814  \n",
      "Train Epoch[1] Step[621 / 19085] - loss: 42.190392  \n",
      "Train Epoch[1] Step[641 / 19085] - loss: 29.537106  \n",
      "Train Epoch[1] Step[661 / 19085] - loss: 24.636993  \n",
      "Train Epoch[1] Step[681 / 19085] - loss: 56.236629  \n",
      "Train Epoch[1] Step[701 / 19085] - loss: 52.009354  \n",
      "Train Epoch[1] Step[721 / 19085] - loss: 33.803341  \n",
      "Train Epoch[1] Step[741 / 19085] - loss: 27.874640  \n",
      "Train Epoch[1] Step[761 / 19085] - loss: 36.998123  \n",
      "Train Epoch[1] Step[781 / 19085] - loss: 42.977013  \n",
      "Train Epoch[1] Step[801 / 19085] - loss: 36.015343  \n",
      "Train Epoch[1] Step[821 / 19085] - loss: 32.794502  \n",
      "Train Epoch[1] Step[841 / 19085] - loss: 45.212372  \n",
      "Train Epoch[1] Step[861 / 19085] - loss: 37.562706  \n",
      "Train Epoch[1] Step[881 / 19085] - loss: 30.652075  \n",
      "Train Epoch[1] Step[901 / 19085] - loss: 38.211178  \n",
      "Train Epoch[1] Step[921 / 19085] - loss: 37.400719  \n",
      "Train Epoch[1] Step[941 / 19085] - loss: 42.792446  \n",
      "Train Epoch[1] Step[961 / 19085] - loss: 49.259438  \n",
      "Train Epoch[1] Step[981 / 19085] - loss: 28.010834  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:13<00:00, 11.00it/s]\n",
      "Dev Loss: 49.303460\n",
      "/root/miniconda3/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.0000    0.0000    0.0000     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0000    0.0000    0.0000     22839\n",
      "           T     0.0000    0.0000    0.0000     22956\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000     73869\n",
      "   macro avg     0.0000    0.0000    0.0000     73869\n",
      "weighted avg     0.0000    0.0000    0.0000     73869\n",
      "\n",
      "best f1: 0.00, current f1: 0.00\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[1001 / 19085] - loss: 37.258495  \n",
      "Train Epoch[1] Step[1021 / 19085] - loss: 25.250702  \n",
      "Train Epoch[1] Step[1041 / 19085] - loss: 39.098854  \n",
      "Train Epoch[1] Step[1061 / 19085] - loss: 61.429485  \n",
      "Train Epoch[1] Step[1081 / 19085] - loss: 37.766907  \n",
      "Train Epoch[1] Step[1101 / 19085] - loss: 76.267181  \n",
      "Train Epoch[1] Step[1121 / 19085] - loss: 30.338299  \n",
      "Train Epoch[1] Step[1141 / 19085] - loss: 26.510763  \n",
      "Train Epoch[1] Step[1161 / 19085] - loss: 23.894651  \n",
      "Train Epoch[1] Step[1181 / 19085] - loss: 52.244076  \n",
      "Train Epoch[1] Step[1201 / 19085] - loss: 44.337307  \n",
      "Train Epoch[1] Step[1221 / 19085] - loss: 21.127609  \n",
      "Train Epoch[1] Step[1241 / 19085] - loss: 34.251999  \n",
      "Train Epoch[1] Step[1261 / 19085] - loss: 19.332016  \n",
      "Train Epoch[1] Step[1281 / 19085] - loss: 40.780346  \n",
      "Train Epoch[1] Step[1301 / 19085] - loss: 52.944756  \n",
      "Train Epoch[1] Step[1321 / 19085] - loss: 23.231987  \n",
      "Train Epoch[1] Step[1341 / 19085] - loss: 35.632961  \n",
      "Train Epoch[1] Step[1361 / 19085] - loss: 23.528036  \n",
      "Train Epoch[1] Step[1381 / 19085] - loss: 27.038582  \n",
      "Train Epoch[1] Step[1401 / 19085] - loss: 22.229710  \n",
      "Train Epoch[1] Step[1421 / 19085] - loss: 28.227409  \n",
      "Train Epoch[1] Step[1441 / 19085] - loss: 45.643799  \n",
      "Train Epoch[1] Step[1461 / 19085] - loss: 55.642929  \n",
      "Train Epoch[1] Step[1481 / 19085] - loss: 44.783775  \n",
      "Train Epoch[1] Step[1501 / 19085] - loss: 41.236923  \n",
      "Train Epoch[1] Step[1521 / 19085] - loss: 42.594788  \n",
      "Train Epoch[1] Step[1541 / 19085] - loss: 39.046413  \n",
      "Train Epoch[1] Step[1561 / 19085] - loss: 38.099571  \n",
      "Train Epoch[1] Step[1581 / 19085] - loss: 37.615822  \n",
      "Train Epoch[1] Step[1601 / 19085] - loss: 45.655193  \n",
      "Train Epoch[1] Step[1621 / 19085] - loss: 37.134308  \n",
      "Train Epoch[1] Step[1641 / 19085] - loss: 24.671865  \n",
      "Train Epoch[1] Step[1661 / 19085] - loss: 26.491980  \n",
      "Train Epoch[1] Step[1681 / 19085] - loss: 42.009182  \n",
      "Train Epoch[1] Step[1701 / 19085] - loss: 22.797018  \n",
      "Train Epoch[1] Step[1721 / 19085] - loss: 41.497902  \n",
      "Train Epoch[1] Step[1741 / 19085] - loss: 38.642342  \n",
      "Train Epoch[1] Step[1761 / 19085] - loss: 31.611141  \n",
      "Train Epoch[1] Step[1781 / 19085] - loss: 44.922180  \n",
      "Train Epoch[1] Step[1801 / 19085] - loss: 23.178595  \n",
      "Train Epoch[1] Step[1821 / 19085] - loss: 25.789974  \n",
      "Train Epoch[1] Step[1841 / 19085] - loss: 54.624840  \n",
      "Train Epoch[1] Step[1861 / 19085] - loss: 37.767166  \n",
      "Train Epoch[1] Step[1881 / 19085] - loss: 41.916424  \n",
      "Train Epoch[1] Step[1901 / 19085] - loss: 43.669579  \n",
      "Train Epoch[1] Step[1921 / 19085] - loss: 36.865536  \n",
      "Train Epoch[1] Step[1941 / 19085] - loss: 49.237526  \n",
      "Train Epoch[1] Step[1961 / 19085] - loss: 22.783566  \n",
      "Train Epoch[1] Step[1981 / 19085] - loss: 21.627119  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:57<00:00, 11.43it/s]\n",
      "Dev Loss: 43.058583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.0000    0.0000    0.0000     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0000    0.0000    0.0000     22839\n",
      "           T     0.0000    0.0000    0.0000     22956\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000     73869\n",
      "   macro avg     0.0000    0.0000    0.0000     73869\n",
      "weighted avg     0.0000    0.0000    0.0000     73869\n",
      "\n",
      "best f1: 0.00, current f1: 0.00\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[2001 / 19085] - loss: 28.865446  \n",
      "Train Epoch[1] Step[2021 / 19085] - loss: 19.758980  \n",
      "Train Epoch[1] Step[2041 / 19085] - loss: 41.968716  \n",
      "Train Epoch[1] Step[2061 / 19085] - loss: 39.666229  \n",
      "Train Epoch[1] Step[2081 / 19085] - loss: 27.704624  \n",
      "Train Epoch[1] Step[2101 / 19085] - loss: 36.877010  \n",
      "Train Epoch[1] Step[2121 / 19085] - loss: 37.799324  \n",
      "Train Epoch[1] Step[2141 / 19085] - loss: 61.467297  \n",
      "Train Epoch[1] Step[2161 / 19085] - loss: 13.824959  \n",
      "Train Epoch[1] Step[2181 / 19085] - loss: 46.360039  \n",
      "Train Epoch[1] Step[2201 / 19085] - loss: 29.123821  \n",
      "Train Epoch[1] Step[2221 / 19085] - loss: 20.938211  \n",
      "Train Epoch[1] Step[2241 / 19085] - loss: 33.389091  \n",
      "Train Epoch[1] Step[2261 / 19085] - loss: 46.340607  \n",
      "Train Epoch[1] Step[2281 / 19085] - loss: 43.986710  \n",
      "Train Epoch[1] Step[2301 / 19085] - loss: 51.879761  \n",
      "Train Epoch[1] Step[2321 / 19085] - loss: 21.861912  \n",
      "Train Epoch[1] Step[2341 / 19085] - loss: 20.827164  \n",
      "Train Epoch[1] Step[2361 / 19085] - loss: 17.831652  \n",
      "Train Epoch[1] Step[2381 / 19085] - loss: 38.748459  \n",
      "Train Epoch[1] Step[2401 / 19085] - loss: 30.396179  \n",
      "Train Epoch[1] Step[2421 / 19085] - loss: 48.439983  \n",
      "Train Epoch[1] Step[2441 / 19085] - loss: 30.073128  \n",
      "Train Epoch[1] Step[2461 / 19085] - loss: 42.242939  \n",
      "Train Epoch[1] Step[2481 / 19085] - loss: 36.778950  \n",
      "Train Epoch[1] Step[2501 / 19085] - loss: 26.169189  \n",
      "Train Epoch[1] Step[2521 / 19085] - loss: 22.681120  \n",
      "Train Epoch[1] Step[2541 / 19085] - loss: 43.957733  \n",
      "Train Epoch[1] Step[2561 / 19085] - loss: 45.350506  \n",
      "Train Epoch[1] Step[2581 / 19085] - loss: 42.019997  \n",
      "Train Epoch[1] Step[2601 / 19085] - loss: 34.593758  \n",
      "Train Epoch[1] Step[2621 / 19085] - loss: 32.996635  \n",
      "Train Epoch[1] Step[2641 / 19085] - loss: 31.114391  \n",
      "Train Epoch[1] Step[2661 / 19085] - loss: 33.811893  \n",
      "Train Epoch[1] Step[2681 / 19085] - loss: 21.973303  \n",
      "Train Epoch[1] Step[2701 / 19085] - loss: 29.626692  \n",
      "Train Epoch[1] Step[2721 / 19085] - loss: 46.088303  \n",
      "Train Epoch[1] Step[2741 / 19085] - loss: 31.168127  \n",
      "Train Epoch[1] Step[2761 / 19085] - loss: 20.683920  \n",
      "Train Epoch[1] Step[2781 / 19085] - loss: 30.703825  \n",
      "Train Epoch[1] Step[2801 / 19085] - loss: 26.154539  \n",
      "Train Epoch[1] Step[2821 / 19085] - loss: 20.114792  \n",
      "Train Epoch[1] Step[2841 / 19085] - loss: 25.093246  \n",
      "Train Epoch[1] Step[2861 / 19085] - loss: 28.418079  \n",
      "Train Epoch[1] Step[2881 / 19085] - loss: 26.608353  \n",
      "Train Epoch[1] Step[2901 / 19085] - loss: 34.904114  \n",
      "Train Epoch[1] Step[2921 / 19085] - loss: 29.949461  \n",
      "Train Epoch[1] Step[2941 / 19085] - loss: 19.464294  \n",
      "Train Epoch[1] Step[2961 / 19085] - loss: 22.482702  \n",
      "Train Epoch[1] Step[2981 / 19085] - loss: 29.494564  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:16<00:00, 12.67it/s]\n",
      "Dev Loss: 32.707876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.0000    0.0000    0.0000     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0000    0.0000    0.0000     22839\n",
      "           T     0.0345    0.0001    0.0003     22956\n",
      "\n",
      "   micro avg     0.0345    0.0000    0.0001     73869\n",
      "   macro avg     0.0086    0.0000    0.0001     73869\n",
      "weighted avg     0.0107    0.0000    0.0001     73869\n",
      "\n",
      "best f1: 0.00, current f1: 0.00\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[3001 / 19085] - loss: 23.137350  \n",
      "Train Epoch[1] Step[3021 / 19085] - loss: 23.971954  \n",
      "Train Epoch[1] Step[3041 / 19085] - loss: 48.308758  \n",
      "Train Epoch[1] Step[3061 / 19085] - loss: 52.879295  \n",
      "Train Epoch[1] Step[3081 / 19085] - loss: 33.493782  \n",
      "Train Epoch[1] Step[3101 / 19085] - loss: 39.481133  \n",
      "Train Epoch[1] Step[3121 / 19085] - loss: 36.309639  \n",
      "Train Epoch[1] Step[3141 / 19085] - loss: 37.228531  \n",
      "Train Epoch[1] Step[3161 / 19085] - loss: 29.250793  \n",
      "Train Epoch[1] Step[3181 / 19085] - loss: 17.344938  \n",
      "Train Epoch[1] Step[3201 / 19085] - loss: 28.197645  \n",
      "Train Epoch[1] Step[3221 / 19085] - loss: 29.487141  \n",
      "Train Epoch[1] Step[3241 / 19085] - loss: 31.690481  \n",
      "Train Epoch[1] Step[3261 / 19085] - loss: 30.495657  \n",
      "Train Epoch[1] Step[3281 / 19085] - loss: 31.754057  \n",
      "Train Epoch[1] Step[3301 / 19085] - loss: 16.743851  \n",
      "Train Epoch[1] Step[3321 / 19085] - loss: 20.130924  \n",
      "Train Epoch[1] Step[3341 / 19085] - loss: 43.958916  \n",
      "Train Epoch[1] Step[3361 / 19085] - loss: 30.689260  \n",
      "Train Epoch[1] Step[3381 / 19085] - loss: 28.832218  \n",
      "Train Epoch[1] Step[3401 / 19085] - loss: 24.592909  \n",
      "Train Epoch[1] Step[3421 / 19085] - loss: 18.684008  \n",
      "Train Epoch[1] Step[3441 / 19085] - loss: 26.559408  \n",
      "Train Epoch[1] Step[3461 / 19085] - loss: 32.924938  \n",
      "Train Epoch[1] Step[3481 / 19085] - loss: 29.311874  \n",
      "Train Epoch[1] Step[3501 / 19085] - loss: 34.225506  \n",
      "Train Epoch[1] Step[3521 / 19085] - loss: 38.366173  \n",
      "Train Epoch[1] Step[3541 / 19085] - loss: 36.472515  \n",
      "Train Epoch[1] Step[3561 / 19085] - loss: 19.602695  \n",
      "Train Epoch[1] Step[3581 / 19085] - loss: 16.705204  \n",
      "Train Epoch[1] Step[3601 / 19085] - loss: 21.083092  \n",
      "Train Epoch[1] Step[3621 / 19085] - loss: 41.797867  \n",
      "Train Epoch[1] Step[3641 / 19085] - loss: 38.383553  \n",
      "Train Epoch[1] Step[3661 / 19085] - loss: 41.496964  \n",
      "Train Epoch[1] Step[3681 / 19085] - loss: 33.597084  \n",
      "Train Epoch[1] Step[3701 / 19085] - loss: 39.322571  \n",
      "Train Epoch[1] Step[3721 / 19085] - loss: 31.089315  \n",
      "Train Epoch[1] Step[3741 / 19085] - loss: 26.101074  \n",
      "Train Epoch[1] Step[3761 / 19085] - loss: 24.739197  \n",
      "Train Epoch[1] Step[3781 / 19085] - loss: 28.202595  \n",
      "Train Epoch[1] Step[3801 / 19085] - loss: 19.175114  \n",
      "Train Epoch[1] Step[3821 / 19085] - loss: 35.424931  \n",
      "Train Epoch[1] Step[3841 / 19085] - loss: 17.978466  \n",
      "Train Epoch[1] Step[3861 / 19085] - loss: 28.893026  \n",
      "Train Epoch[1] Step[3881 / 19085] - loss: 15.956717  \n",
      "Train Epoch[1] Step[3901 / 19085] - loss: 30.692467  \n",
      "Train Epoch[1] Step[3921 / 19085] - loss: 26.392563  \n",
      "Train Epoch[1] Step[3941 / 19085] - loss: 17.281181  \n",
      "Train Epoch[1] Step[3961 / 19085] - loss: 33.943035  \n",
      "Train Epoch[1] Step[3981 / 19085] - loss: 36.898529  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:09<00:00, 12.92it/s]\n",
      "Dev Loss: 27.183085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.0000    0.0000    0.0000     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0000    0.0000    0.0000     22839\n",
      "           T     0.0501    0.0482    0.0491     22956\n",
      "\n",
      "   micro avg     0.0501    0.0150    0.0231     73869\n",
      "   macro avg     0.0125    0.0120    0.0123     73869\n",
      "weighted avg     0.0156    0.0150    0.0153     73869\n",
      "\n",
      "best f1: 0.00, current f1: 0.02\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[4001 / 19085] - loss: 30.350769  \n",
      "Train Epoch[1] Step[4021 / 19085] - loss: 27.468771  \n",
      "Train Epoch[1] Step[4041 / 19085] - loss: 44.929596  \n",
      "Train Epoch[1] Step[4061 / 19085] - loss: 31.704266  \n",
      "Train Epoch[1] Step[4081 / 19085] - loss: 27.500332  \n",
      "Train Epoch[1] Step[4101 / 19085] - loss: 12.004947  \n",
      "Train Epoch[1] Step[4121 / 19085] - loss: 22.348167  \n",
      "Train Epoch[1] Step[4141 / 19085] - loss: 35.648865  \n",
      "Train Epoch[1] Step[4161 / 19085] - loss: 30.452042  \n",
      "Train Epoch[1] Step[4181 / 19085] - loss: 17.911776  \n",
      "Train Epoch[1] Step[4201 / 19085] - loss: 22.977566  \n",
      "Train Epoch[1] Step[4221 / 19085] - loss: 28.220245  \n",
      "Train Epoch[1] Step[4241 / 19085] - loss: 25.481853  \n",
      "Train Epoch[1] Step[4261 / 19085] - loss: 22.986969  \n",
      "Train Epoch[1] Step[4281 / 19085] - loss: 37.744141  \n",
      "Train Epoch[1] Step[4301 / 19085] - loss: 13.878859  \n",
      "Train Epoch[1] Step[4321 / 19085] - loss: 23.362989  \n",
      "Train Epoch[1] Step[4341 / 19085] - loss: 14.170303  \n",
      "Train Epoch[1] Step[4361 / 19085] - loss: 23.063728  \n",
      "Train Epoch[1] Step[4381 / 19085] - loss: 30.093147  \n",
      "Train Epoch[1] Step[4401 / 19085] - loss: 27.399914  \n",
      "Train Epoch[1] Step[4421 / 19085] - loss: 30.771557  \n",
      "Train Epoch[1] Step[4441 / 19085] - loss: 14.602836  \n",
      "Train Epoch[1] Step[4461 / 19085] - loss: 26.855015  \n",
      "Train Epoch[1] Step[4481 / 19085] - loss: 39.321938  \n",
      "Train Epoch[1] Step[4501 / 19085] - loss: 23.600172  \n",
      "Train Epoch[1] Step[4521 / 19085] - loss: 36.046139  \n",
      "Train Epoch[1] Step[4541 / 19085] - loss: 19.501350  \n",
      "Train Epoch[1] Step[4561 / 19085] - loss: 26.672651  \n",
      "Train Epoch[1] Step[4581 / 19085] - loss: 33.268707  \n",
      "Train Epoch[1] Step[4601 / 19085] - loss: 60.197876  \n",
      "Train Epoch[1] Step[4621 / 19085] - loss: 27.843100  \n",
      "Train Epoch[1] Step[4641 / 19085] - loss: 21.908966  \n",
      "Train Epoch[1] Step[4661 / 19085] - loss: 28.898087  \n",
      "Train Epoch[1] Step[4681 / 19085] - loss: 11.236468  \n",
      "Train Epoch[1] Step[4701 / 19085] - loss: 32.506542  \n",
      "Train Epoch[1] Step[4721 / 19085] - loss: 27.845587  \n",
      "Train Epoch[1] Step[4741 / 19085] - loss: 14.663630  \n",
      "Train Epoch[1] Step[4761 / 19085] - loss: 17.282417  \n",
      "Train Epoch[1] Step[4781 / 19085] - loss: 33.853317  \n",
      "Train Epoch[1] Step[4801 / 19085] - loss: 25.916546  \n",
      "Train Epoch[1] Step[4821 / 19085] - loss: 26.944195  \n",
      "Train Epoch[1] Step[4841 / 19085] - loss: 20.723822  \n",
      "Train Epoch[1] Step[4861 / 19085] - loss: 23.710339  \n",
      "Train Epoch[1] Step[4881 / 19085] - loss: 40.311356  \n",
      "Train Epoch[1] Step[4901 / 19085] - loss: 26.140707  \n",
      "Train Epoch[1] Step[4921 / 19085] - loss: 18.280037  \n",
      "Train Epoch[1] Step[4941 / 19085] - loss: 22.359875  \n",
      "Train Epoch[1] Step[4961 / 19085] - loss: 33.093105  \n",
      "Train Epoch[1] Step[4981 / 19085] - loss: 20.871534  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:59<00:00, 13.28it/s]\n",
      "Dev Loss: 24.614939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.0000    0.0000    0.0000     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0000    0.0000    0.0000     22839\n",
      "           T     0.0837    0.0863    0.0850     22956\n",
      "\n",
      "   micro avg     0.0837    0.0268    0.0406     73869\n",
      "   macro avg     0.0209    0.0216    0.0212     73869\n",
      "weighted avg     0.0260    0.0268    0.0264     73869\n",
      "\n",
      "best f1: 0.02, current f1: 0.04\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[5001 / 19085] - loss: 22.555212  \n",
      "Train Epoch[1] Step[5021 / 19085] - loss: 30.613991  \n",
      "Train Epoch[1] Step[5041 / 19085] - loss: 22.888851  \n",
      "Train Epoch[1] Step[5061 / 19085] - loss: 14.861533  \n",
      "Train Epoch[1] Step[5081 / 19085] - loss: 22.275238  \n",
      "Train Epoch[1] Step[5101 / 19085] - loss: 20.369411  \n",
      "Train Epoch[1] Step[5121 / 19085] - loss: 14.498623  \n",
      "Train Epoch[1] Step[5141 / 19085] - loss: 21.306786  \n",
      "Train Epoch[1] Step[5161 / 19085] - loss: 32.606808  \n",
      "Train Epoch[1] Step[5181 / 19085] - loss: 19.987957  \n",
      "Train Epoch[1] Step[5201 / 19085] - loss: 22.046551  \n",
      "Train Epoch[1] Step[5221 / 19085] - loss: 33.073639  \n",
      "Train Epoch[1] Step[5241 / 19085] - loss: 9.703259  \n",
      "Train Epoch[1] Step[5261 / 19085] - loss: 7.435546  \n",
      "Train Epoch[1] Step[5281 / 19085] - loss: 21.711250  \n",
      "Train Epoch[1] Step[5301 / 19085] - loss: 29.801254  \n",
      "Train Epoch[1] Step[5321 / 19085] - loss: 25.855038  \n",
      "Train Epoch[1] Step[5341 / 19085] - loss: 20.865541  \n",
      "Train Epoch[1] Step[5361 / 19085] - loss: 21.122038  \n",
      "Train Epoch[1] Step[5381 / 19085] - loss: 33.166382  \n",
      "Train Epoch[1] Step[5401 / 19085] - loss: 23.885199  \n",
      "Train Epoch[1] Step[5421 / 19085] - loss: 31.021103  \n",
      "Train Epoch[1] Step[5441 / 19085] - loss: 9.816126  \n",
      "Train Epoch[1] Step[5461 / 19085] - loss: 18.067110  \n",
      "Train Epoch[1] Step[5481 / 19085] - loss: 16.106647  \n",
      "Train Epoch[1] Step[5501 / 19085] - loss: 6.571771  \n",
      "Train Epoch[1] Step[5521 / 19085] - loss: 24.296272  \n",
      "Train Epoch[1] Step[5541 / 19085] - loss: 18.566898  \n",
      "Train Epoch[1] Step[5561 / 19085] - loss: 26.856880  \n",
      "Train Epoch[1] Step[5581 / 19085] - loss: 31.509207  \n",
      "Train Epoch[1] Step[5601 / 19085] - loss: 40.124249  \n",
      "Train Epoch[1] Step[5621 / 19085] - loss: 40.565582  \n",
      "Train Epoch[1] Step[5641 / 19085] - loss: 26.706274  \n",
      "Train Epoch[1] Step[5661 / 19085] - loss: 19.316496  \n",
      "Train Epoch[1] Step[5681 / 19085] - loss: 18.526993  \n",
      "Train Epoch[1] Step[5701 / 19085] - loss: 24.702942  \n",
      "Train Epoch[1] Step[5721 / 19085] - loss: 27.300070  \n",
      "Train Epoch[1] Step[5741 / 19085] - loss: 22.577808  \n",
      "Train Epoch[1] Step[5761 / 19085] - loss: 22.464123  \n",
      "Train Epoch[1] Step[5781 / 19085] - loss: 13.775421  \n",
      "Train Epoch[1] Step[5801 / 19085] - loss: 19.360554  \n",
      "Train Epoch[1] Step[5821 / 19085] - loss: 20.189198  \n",
      "Train Epoch[1] Step[5841 / 19085] - loss: 27.787046  \n",
      "Train Epoch[1] Step[5861 / 19085] - loss: 20.993217  \n",
      "Train Epoch[1] Step[5881 / 19085] - loss: 29.011463  \n",
      "Train Epoch[1] Step[5901 / 19085] - loss: 16.490635  \n",
      "Train Epoch[1] Step[5921 / 19085] - loss: 18.730145  \n",
      "Train Epoch[1] Step[5941 / 19085] - loss: 24.237728  \n",
      "Train Epoch[1] Step[5961 / 19085] - loss: 21.951435  \n",
      "Train Epoch[1] Step[5981 / 19085] - loss: 23.754812  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:58<00:00, 13.32it/s]\n",
      "Dev Loss: 22.669182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.0051    0.0001    0.0002     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0000    0.0000    0.0000     22839\n",
      "           T     0.1310    0.1393    0.1350     22956\n",
      "\n",
      "   micro avg     0.1280    0.0433    0.0648     73869\n",
      "   macro avg     0.0340    0.0349    0.0338     73869\n",
      "weighted avg     0.0425    0.0433    0.0420     73869\n",
      "\n",
      "best f1: 0.04, current f1: 0.06\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[6001 / 19085] - loss: 25.738401  \n",
      "Train Epoch[1] Step[6021 / 19085] - loss: 19.207695  \n",
      "Train Epoch[1] Step[6041 / 19085] - loss: 23.367813  \n",
      "Train Epoch[1] Step[6061 / 19085] - loss: 14.995108  \n",
      "Train Epoch[1] Step[6081 / 19085] - loss: 22.477278  \n",
      "Train Epoch[1] Step[6101 / 19085] - loss: 20.022497  \n",
      "Train Epoch[1] Step[6121 / 19085] - loss: 27.932755  \n",
      "Train Epoch[1] Step[6141 / 19085] - loss: 17.358503  \n",
      "Train Epoch[1] Step[6161 / 19085] - loss: 20.045769  \n",
      "Train Epoch[1] Step[6181 / 19085] - loss: 16.906727  \n",
      "Train Epoch[1] Step[6201 / 19085] - loss: 23.355431  \n",
      "Train Epoch[1] Step[6221 / 19085] - loss: 22.884335  \n",
      "Train Epoch[1] Step[6241 / 19085] - loss: 16.321619  \n",
      "Train Epoch[1] Step[6261 / 19085] - loss: 13.659759  \n",
      "Train Epoch[1] Step[6281 / 19085] - loss: 11.570820  \n",
      "Train Epoch[1] Step[6301 / 19085] - loss: 16.154163  \n",
      "Train Epoch[1] Step[6321 / 19085] - loss: 24.160824  \n",
      "Train Epoch[1] Step[6341 / 19085] - loss: 30.741028  \n",
      "Train Epoch[1] Step[6361 / 19085] - loss: 7.547403  \n",
      "Train Epoch[1] Step[6381 / 19085] - loss: 15.382373  \n",
      "Train Epoch[1] Step[6401 / 19085] - loss: 15.197871  \n",
      "Train Epoch[1] Step[6421 / 19085] - loss: 34.917934  \n",
      "Train Epoch[1] Step[6441 / 19085] - loss: 22.828159  \n",
      "Train Epoch[1] Step[6461 / 19085] - loss: 14.259741  \n",
      "Train Epoch[1] Step[6481 / 19085] - loss: 22.011852  \n",
      "Train Epoch[1] Step[6501 / 19085] - loss: 23.617706  \n",
      "Train Epoch[1] Step[6521 / 19085] - loss: 20.435482  \n",
      "Train Epoch[1] Step[6541 / 19085] - loss: 19.290188  \n",
      "Train Epoch[1] Step[6561 / 19085] - loss: 19.099297  \n",
      "Train Epoch[1] Step[6581 / 19085] - loss: 13.932578  \n",
      "Train Epoch[1] Step[6601 / 19085] - loss: 21.111193  \n",
      "Train Epoch[1] Step[6621 / 19085] - loss: 35.839027  \n",
      "Train Epoch[1] Step[6641 / 19085] - loss: 20.340343  \n",
      "Train Epoch[1] Step[6661 / 19085] - loss: 14.791202  \n",
      "Train Epoch[1] Step[6681 / 19085] - loss: 25.381559  \n",
      "Train Epoch[1] Step[6701 / 19085] - loss: 11.895714  \n",
      "Train Epoch[1] Step[6721 / 19085] - loss: 16.865866  \n",
      "Train Epoch[1] Step[6741 / 19085] - loss: 21.991697  \n",
      "Train Epoch[1] Step[6761 / 19085] - loss: 22.608122  \n",
      "Train Epoch[1] Step[6781 / 19085] - loss: 18.975704  \n",
      "Train Epoch[1] Step[6801 / 19085] - loss: 13.106382  \n",
      "Train Epoch[1] Step[6821 / 19085] - loss: 28.055759  \n",
      "Train Epoch[1] Step[6841 / 19085] - loss: 16.513241  \n",
      "Train Epoch[1] Step[6861 / 19085] - loss: 16.354771  \n",
      "Train Epoch[1] Step[6881 / 19085] - loss: 19.333044  \n",
      "Train Epoch[1] Step[6901 / 19085] - loss: 13.812958  \n",
      "Train Epoch[1] Step[6921 / 19085] - loss: 24.067434  \n",
      "Train Epoch[1] Step[6941 / 19085] - loss: 20.157791  \n",
      "Train Epoch[1] Step[6961 / 19085] - loss: 33.867630  \n",
      "Train Epoch[1] Step[6981 / 19085] - loss: 11.869778  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:52<00:00, 13.54it/s]\n",
      "Dev Loss: 21.129128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.1354    0.0103    0.0191     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0610    0.0002    0.0004     22839\n",
      "           T     0.1511    0.1347    0.1424     22956\n",
      "\n",
      "   micro avg     0.1494    0.0456    0.0698     73869\n",
      "   macro avg     0.0869    0.0363    0.0405     73869\n",
      "weighted avg     0.1137    0.0456    0.0512     73869\n",
      "\n",
      "best f1: 0.06, current f1: 0.07\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[7001 / 19085] - loss: 25.683754  \n",
      "Train Epoch[1] Step[7021 / 19085] - loss: 15.726420  \n",
      "Train Epoch[1] Step[7041 / 19085] - loss: 29.037121  \n",
      "Train Epoch[1] Step[7061 / 19085] - loss: 21.200909  \n",
      "Train Epoch[1] Step[7081 / 19085] - loss: 23.337706  \n",
      "Train Epoch[1] Step[7101 / 19085] - loss: 17.906120  \n",
      "Train Epoch[1] Step[7121 / 19085] - loss: 18.516142  \n",
      "Train Epoch[1] Step[7141 / 19085] - loss: 9.504290  \n",
      "Train Epoch[1] Step[7161 / 19085] - loss: 24.888388  \n",
      "Train Epoch[1] Step[7181 / 19085] - loss: 14.191847  \n",
      "Train Epoch[1] Step[7201 / 19085] - loss: 22.588711  \n",
      "Train Epoch[1] Step[7221 / 19085] - loss: 21.179913  \n",
      "Train Epoch[1] Step[7241 / 19085] - loss: 25.952475  \n",
      "Train Epoch[1] Step[7261 / 19085] - loss: 16.484386  \n",
      "Train Epoch[1] Step[7281 / 19085] - loss: 14.021990  \n",
      "Train Epoch[1] Step[7301 / 19085] - loss: 28.564587  \n",
      "Train Epoch[1] Step[7321 / 19085] - loss: 21.304821  \n",
      "Train Epoch[1] Step[7341 / 19085] - loss: 17.433426  \n",
      "Train Epoch[1] Step[7361 / 19085] - loss: 28.665928  \n",
      "Train Epoch[1] Step[7381 / 19085] - loss: 28.062374  \n",
      "Train Epoch[1] Step[7401 / 19085] - loss: 22.476788  \n",
      "Train Epoch[1] Step[7421 / 19085] - loss: 38.765888  \n",
      "Train Epoch[1] Step[7441 / 19085] - loss: 16.440479  \n",
      "Train Epoch[1] Step[7461 / 19085] - loss: 13.818542  \n",
      "Train Epoch[1] Step[7481 / 19085] - loss: 13.985533  \n",
      "Train Epoch[1] Step[7501 / 19085] - loss: 26.578503  \n",
      "Train Epoch[1] Step[7521 / 19085] - loss: 22.445950  \n",
      "Train Epoch[1] Step[7541 / 19085] - loss: 12.332983  \n",
      "Train Epoch[1] Step[7561 / 19085] - loss: 25.044424  \n",
      "Train Epoch[1] Step[7581 / 19085] - loss: 32.210571  \n",
      "Train Epoch[1] Step[7601 / 19085] - loss: 19.532219  \n",
      "Train Epoch[1] Step[7621 / 19085] - loss: 19.681763  \n",
      "Train Epoch[1] Step[7641 / 19085] - loss: 9.048252  \n",
      "Train Epoch[1] Step[7661 / 19085] - loss: 24.058561  \n",
      "Train Epoch[1] Step[7681 / 19085] - loss: 15.820686  \n",
      "Train Epoch[1] Step[7701 / 19085] - loss: 14.848353  \n",
      "Train Epoch[1] Step[7721 / 19085] - loss: 17.789701  \n",
      "Train Epoch[1] Step[7741 / 19085] - loss: 25.497269  \n",
      "Train Epoch[1] Step[7761 / 19085] - loss: 12.179733  \n",
      "Train Epoch[1] Step[7781 / 19085] - loss: 10.181355  \n",
      "Train Epoch[1] Step[7801 / 19085] - loss: 16.609531  \n",
      "Train Epoch[1] Step[7821 / 19085] - loss: 18.595150  \n",
      "Train Epoch[1] Step[7841 / 19085] - loss: 14.552780  \n",
      "Train Epoch[1] Step[7861 / 19085] - loss: 16.692225  \n",
      "Train Epoch[1] Step[7881 / 19085] - loss: 17.800055  \n",
      "Train Epoch[1] Step[7901 / 19085] - loss: 36.131683  \n",
      "Train Epoch[1] Step[7921 / 19085] - loss: 19.152697  \n",
      "Train Epoch[1] Step[7941 / 19085] - loss: 18.823574  \n",
      "Train Epoch[1] Step[7961 / 19085] - loss: 31.049252  \n",
      "Train Epoch[1] Step[7981 / 19085] - loss: 10.949623  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:05<00:00, 13.05it/s]\n",
      "Dev Loss: 19.800812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.2666    0.0336    0.0596     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0564    0.0011    0.0022     22839\n",
      "           T     0.1747    0.1433    0.1574     22956\n",
      "\n",
      "   micro avg     0.1857    0.0567    0.0869     73869\n",
      "   macro avg     0.1244    0.0445    0.0548     73869\n",
      "weighted avg     0.1660    0.0567    0.0707     73869\n",
      "\n",
      "best f1: 0.07, current f1: 0.09\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[8001 / 19085] - loss: 20.491241  \n",
      "Train Epoch[1] Step[8021 / 19085] - loss: 31.491028  \n",
      "Train Epoch[1] Step[8041 / 19085] - loss: 19.753819  \n",
      "Train Epoch[1] Step[8061 / 19085] - loss: 11.934600  \n",
      "Train Epoch[1] Step[8081 / 19085] - loss: 16.089733  \n",
      "Train Epoch[1] Step[8101 / 19085] - loss: 23.026905  \n",
      "Train Epoch[1] Step[8121 / 19085] - loss: 12.216192  \n",
      "Train Epoch[1] Step[8141 / 19085] - loss: 13.697894  \n",
      "Train Epoch[1] Step[8161 / 19085] - loss: 16.528221  \n",
      "Train Epoch[1] Step[8181 / 19085] - loss: 20.566635  \n",
      "Train Epoch[1] Step[8201 / 19085] - loss: 25.431911  \n",
      "Train Epoch[1] Step[8221 / 19085] - loss: 15.211334  \n",
      "Train Epoch[1] Step[8241 / 19085] - loss: 17.314848  \n",
      "Train Epoch[1] Step[8261 / 19085] - loss: 20.389507  \n",
      "Train Epoch[1] Step[8281 / 19085] - loss: 12.551743  \n",
      "Train Epoch[1] Step[8301 / 19085] - loss: 20.886490  \n",
      "Train Epoch[1] Step[8321 / 19085] - loss: 8.832293  \n",
      "Train Epoch[1] Step[8341 / 19085] - loss: 21.232979  \n",
      "Train Epoch[1] Step[8361 / 19085] - loss: 18.736694  \n",
      "Train Epoch[1] Step[8381 / 19085] - loss: 14.407486  \n",
      "Train Epoch[1] Step[8401 / 19085] - loss: 14.798281  \n",
      "Train Epoch[1] Step[8421 / 19085] - loss: 18.206226  \n",
      "Train Epoch[1] Step[8441 / 19085] - loss: 21.750965  \n",
      "Train Epoch[1] Step[8461 / 19085] - loss: 19.923672  \n",
      "Train Epoch[1] Step[8481 / 19085] - loss: 6.511599  \n",
      "Train Epoch[1] Step[8501 / 19085] - loss: 14.260773  \n",
      "Train Epoch[1] Step[8521 / 19085] - loss: 19.523909  \n",
      "Train Epoch[1] Step[8541 / 19085] - loss: 18.379587  \n",
      "Train Epoch[1] Step[8561 / 19085] - loss: 25.059599  \n",
      "Train Epoch[1] Step[8581 / 19085] - loss: 14.626490  \n",
      "Train Epoch[1] Step[8601 / 19085] - loss: 15.518695  \n",
      "Train Epoch[1] Step[8621 / 19085] - loss: 17.770689  \n",
      "Train Epoch[1] Step[8641 / 19085] - loss: 9.288332  \n",
      "Train Epoch[1] Step[8661 / 19085] - loss: 21.020321  \n",
      "Train Epoch[1] Step[8681 / 19085] - loss: 20.131939  \n",
      "Train Epoch[1] Step[8701 / 19085] - loss: 9.098407  \n",
      "Train Epoch[1] Step[8721 / 19085] - loss: 18.441919  \n",
      "Train Epoch[1] Step[8741 / 19085] - loss: 16.488861  \n",
      "Train Epoch[1] Step[8761 / 19085] - loss: 17.873978  \n",
      "Train Epoch[1] Step[8781 / 19085] - loss: 13.277105  \n",
      "Train Epoch[1] Step[8801 / 19085] - loss: 16.124802  \n",
      "Train Epoch[1] Step[8821 / 19085] - loss: 10.903079  \n",
      "Train Epoch[1] Step[8841 / 19085] - loss: 22.314291  \n",
      "Train Epoch[1] Step[8861 / 19085] - loss: 23.981161  \n",
      "Train Epoch[1] Step[8881 / 19085] - loss: 22.890713  \n",
      "Train Epoch[1] Step[8901 / 19085] - loss: 12.181143  \n",
      "Train Epoch[1] Step[8921 / 19085] - loss: 23.744574  \n",
      "Train Epoch[1] Step[8941 / 19085] - loss: 25.028204  \n",
      "Train Epoch[1] Step[8961 / 19085] - loss: 17.978477  \n",
      "Train Epoch[1] Step[8981 / 19085] - loss: 26.205051  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:06<00:00, 13.02it/s]\n",
      "Dev Loss: 18.543844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.2579    0.0483    0.0814     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0533    0.0057    0.0103     22839\n",
      "           T     0.2570    0.2182    0.2360     22956\n",
      "\n",
      "   micro avg     0.2386    0.0866    0.1271     73869\n",
      "   macro avg     0.1420    0.0680    0.0819     73869\n",
      "weighted avg     0.1875    0.0866    0.1053     73869\n",
      "\n",
      "best f1: 0.09, current f1: 0.13\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[9001 / 19085] - loss: 16.764210  \n",
      "Train Epoch[1] Step[9021 / 19085] - loss: 6.812055  \n",
      "Train Epoch[1] Step[9041 / 19085] - loss: 15.400093  \n",
      "Train Epoch[1] Step[9061 / 19085] - loss: 13.052101  \n",
      "Train Epoch[1] Step[9081 / 19085] - loss: 18.506500  \n",
      "Train Epoch[1] Step[9101 / 19085] - loss: 27.199886  \n",
      "Train Epoch[1] Step[9121 / 19085] - loss: 8.143503  \n",
      "Train Epoch[1] Step[9141 / 19085] - loss: 18.941441  \n",
      "Train Epoch[1] Step[9161 / 19085] - loss: 19.602613  \n",
      "Train Epoch[1] Step[9181 / 19085] - loss: 15.843891  \n",
      "Train Epoch[1] Step[9201 / 19085] - loss: 20.385937  \n",
      "Train Epoch[1] Step[9221 / 19085] - loss: 32.455528  \n",
      "Train Epoch[1] Step[9241 / 19085] - loss: 20.721821  \n",
      "Train Epoch[1] Step[9261 / 19085] - loss: 20.531528  \n",
      "Train Epoch[1] Step[9281 / 19085] - loss: 14.050650  \n",
      "Train Epoch[1] Step[9301 / 19085] - loss: 12.802435  \n",
      "Train Epoch[1] Step[9321 / 19085] - loss: 22.601612  \n",
      "Train Epoch[1] Step[9341 / 19085] - loss: 30.806202  \n",
      "Train Epoch[1] Step[9361 / 19085] - loss: 17.338818  \n",
      "Train Epoch[1] Step[9381 / 19085] - loss: 24.743587  \n",
      "Train Epoch[1] Step[9401 / 19085] - loss: 9.819866  \n",
      "Train Epoch[1] Step[9421 / 19085] - loss: 8.253039  \n",
      "Train Epoch[1] Step[9441 / 19085] - loss: 11.903074  \n",
      "Train Epoch[1] Step[9461 / 19085] - loss: 17.847733  \n",
      "Train Epoch[1] Step[9481 / 19085] - loss: 27.782736  \n",
      "Train Epoch[1] Step[9501 / 19085] - loss: 21.082151  \n",
      "Train Epoch[1] Step[9521 / 19085] - loss: 23.042709  \n",
      "Train Epoch[1] Step[9541 / 19085] - loss: 7.904907  \n",
      "Train Epoch[1] Step[9561 / 19085] - loss: 18.798988  \n",
      "Train Epoch[1] Step[9581 / 19085] - loss: 12.241827  \n",
      "Train Epoch[1] Step[9601 / 19085] - loss: 14.554049  \n",
      "Train Epoch[1] Step[9621 / 19085] - loss: 14.713545  \n",
      "Train Epoch[1] Step[9641 / 19085] - loss: 12.970397  \n",
      "Train Epoch[1] Step[9661 / 19085] - loss: 16.630291  \n",
      "Train Epoch[1] Step[9681 / 19085] - loss: 15.630087  \n",
      "Train Epoch[1] Step[9701 / 19085] - loss: 16.827293  \n",
      "Train Epoch[1] Step[9721 / 19085] - loss: 7.403336  \n",
      "Train Epoch[1] Step[9741 / 19085] - loss: 12.325460  \n",
      "Train Epoch[1] Step[9761 / 19085] - loss: 13.366473  \n",
      "Train Epoch[1] Step[9781 / 19085] - loss: 21.607718  \n",
      "Train Epoch[1] Step[9801 / 19085] - loss: 10.917834  \n",
      "Train Epoch[1] Step[9821 / 19085] - loss: 13.994932  \n",
      "Train Epoch[1] Step[9841 / 19085] - loss: 23.077808  \n",
      "Train Epoch[1] Step[9861 / 19085] - loss: 31.167004  \n",
      "Train Epoch[1] Step[9881 / 19085] - loss: 26.976177  \n",
      "Train Epoch[1] Step[9901 / 19085] - loss: 15.258350  \n",
      "Train Epoch[1] Step[9921 / 19085] - loss: 16.861843  \n",
      "Train Epoch[1] Step[9941 / 19085] - loss: 14.154802  \n",
      "Train Epoch[1] Step[9961 / 19085] - loss: 13.582182  \n",
      "Train Epoch[1] Step[9981 / 19085] - loss: 11.738250  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:16<00:00, 12.69it/s]\n",
      "Dev Loss: 17.535613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.2982    0.0636    0.1048     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.0732    0.0155    0.0256     22839\n",
      "           T     0.2811    0.2168    0.2448     22956\n",
      "\n",
      "   micro avg     0.2487    0.0947    0.1371     73869\n",
      "   macro avg     0.1631    0.0740    0.0938     73869\n",
      "weighted avg     0.2154    0.0947    0.1210     73869\n",
      "\n",
      "best f1: 0.13, current f1: 0.14\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[10001 / 19085] - loss: 13.319548  \n",
      "Train Epoch[1] Step[10021 / 19085] - loss: 10.744665  \n",
      "Train Epoch[1] Step[10041 / 19085] - loss: 24.822767  \n",
      "Train Epoch[1] Step[10061 / 19085] - loss: 32.586636  \n",
      "Train Epoch[1] Step[10081 / 19085] - loss: 26.230818  \n",
      "Train Epoch[1] Step[10101 / 19085] - loss: 17.087841  \n",
      "Train Epoch[1] Step[10121 / 19085] - loss: 11.457522  \n",
      "Train Epoch[1] Step[10141 / 19085] - loss: 17.375465  \n",
      "Train Epoch[1] Step[10161 / 19085] - loss: 23.421143  \n",
      "Train Epoch[1] Step[10181 / 19085] - loss: 19.072765  \n",
      "Train Epoch[1] Step[10201 / 19085] - loss: 21.536749  \n",
      "Train Epoch[1] Step[10221 / 19085] - loss: 13.955343  \n",
      "Train Epoch[1] Step[10241 / 19085] - loss: 12.958820  \n",
      "Train Epoch[1] Step[10261 / 19085] - loss: 12.605297  \n",
      "Train Epoch[1] Step[10281 / 19085] - loss: 42.056831  \n",
      "Train Epoch[1] Step[10301 / 19085] - loss: 19.280159  \n",
      "Train Epoch[1] Step[10321 / 19085] - loss: 19.391302  \n",
      "Train Epoch[1] Step[10341 / 19085] - loss: 7.630447  \n",
      "Train Epoch[1] Step[10361 / 19085] - loss: 21.957237  \n",
      "Train Epoch[1] Step[10381 / 19085] - loss: 7.767784  \n",
      "Train Epoch[1] Step[10401 / 19085] - loss: 18.603064  \n",
      "Train Epoch[1] Step[10421 / 19085] - loss: 13.702908  \n",
      "Train Epoch[1] Step[10441 / 19085] - loss: 10.776693  \n",
      "Train Epoch[1] Step[10461 / 19085] - loss: 19.208967  \n",
      "Train Epoch[1] Step[10481 / 19085] - loss: 13.579509  \n",
      "Train Epoch[1] Step[10501 / 19085] - loss: 17.139219  \n",
      "Train Epoch[1] Step[10521 / 19085] - loss: 19.522537  \n",
      "Train Epoch[1] Step[10541 / 19085] - loss: 10.517698  \n",
      "Train Epoch[1] Step[10561 / 19085] - loss: 16.448311  \n",
      "Train Epoch[1] Step[10581 / 19085] - loss: 17.650043  \n",
      "Train Epoch[1] Step[10601 / 19085] - loss: 14.518087  \n",
      "Train Epoch[1] Step[10621 / 19085] - loss: 18.217321  \n",
      "Train Epoch[1] Step[10641 / 19085] - loss: 29.468380  \n",
      "Train Epoch[1] Step[10661 / 19085] - loss: 16.232582  \n",
      "Train Epoch[1] Step[10681 / 19085] - loss: 22.961811  \n",
      "Train Epoch[1] Step[10701 / 19085] - loss: 23.435669  \n",
      "Train Epoch[1] Step[10721 / 19085] - loss: 11.278013  \n",
      "Train Epoch[1] Step[10741 / 19085] - loss: 3.998952  \n",
      "Train Epoch[1] Step[10761 / 19085] - loss: 18.036798  \n",
      "Train Epoch[1] Step[10781 / 19085] - loss: 15.146864  \n",
      "Train Epoch[1] Step[10801 / 19085] - loss: 13.975887  \n",
      "Train Epoch[1] Step[10821 / 19085] - loss: 13.304602  \n",
      "Train Epoch[1] Step[10841 / 19085] - loss: 14.855392  \n",
      "Train Epoch[1] Step[10861 / 19085] - loss: 16.244476  \n",
      "Train Epoch[1] Step[10881 / 19085] - loss: 25.001593  \n",
      "Train Epoch[1] Step[10901 / 19085] - loss: 16.395584  \n",
      "Train Epoch[1] Step[10921 / 19085] - loss: 13.374929  \n",
      "Train Epoch[1] Step[10941 / 19085] - loss: 7.186382  \n",
      "Train Epoch[1] Step[10961 / 19085] - loss: 29.781715  \n",
      "Train Epoch[1] Step[10981 / 19085] - loss: 15.470863  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:48<00:00, 13.69it/s]\n",
      "Dev Loss: 16.651097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.3361    0.0686    0.1140     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.1112    0.0303    0.0476     22839\n",
      "           T     0.3393    0.2527    0.2896     22956\n",
      "\n",
      "   micro avg     0.2891    0.1122    0.1616     73869\n",
      "   macro avg     0.1967    0.0879    0.1128     73869\n",
      "weighted avg     0.2587    0.1122    0.1450     73869\n",
      "\n",
      "best f1: 0.14, current f1: 0.16\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[11001 / 19085] - loss: 13.683482  \n",
      "Train Epoch[1] Step[11021 / 19085] - loss: 15.287154  \n",
      "Train Epoch[1] Step[11041 / 19085] - loss: 12.419163  \n",
      "Train Epoch[1] Step[11061 / 19085] - loss: 9.688740  \n",
      "Train Epoch[1] Step[11081 / 19085] - loss: 16.607639  \n",
      "Train Epoch[1] Step[11101 / 19085] - loss: 15.816381  \n",
      "Train Epoch[1] Step[11121 / 19085] - loss: 19.301695  \n",
      "Train Epoch[1] Step[11141 / 19085] - loss: 19.313969  \n",
      "Train Epoch[1] Step[11161 / 19085] - loss: 15.458569  \n",
      "Train Epoch[1] Step[11181 / 19085] - loss: 19.082111  \n",
      "Train Epoch[1] Step[11201 / 19085] - loss: 18.964321  \n",
      "Train Epoch[1] Step[11221 / 19085] - loss: 17.928942  \n",
      "Train Epoch[1] Step[11241 / 19085] - loss: 14.261683  \n",
      "Train Epoch[1] Step[11261 / 19085] - loss: 16.516907  \n",
      "Train Epoch[1] Step[11281 / 19085] - loss: 15.854752  \n",
      "Train Epoch[1] Step[11301 / 19085] - loss: 23.866795  \n",
      "Train Epoch[1] Step[11321 / 19085] - loss: 11.075034  \n",
      "Train Epoch[1] Step[11341 / 19085] - loss: 14.141821  \n",
      "Train Epoch[1] Step[11361 / 19085] - loss: 24.564947  \n",
      "Train Epoch[1] Step[11381 / 19085] - loss: 18.422573  \n",
      "Train Epoch[1] Step[11401 / 19085] - loss: 26.357489  \n",
      "Train Epoch[1] Step[11421 / 19085] - loss: 16.300053  \n",
      "Train Epoch[1] Step[11441 / 19085] - loss: 17.158401  \n",
      "Train Epoch[1] Step[11461 / 19085] - loss: 14.371249  \n",
      "Train Epoch[1] Step[11481 / 19085] - loss: 11.178610  \n",
      "Train Epoch[1] Step[11501 / 19085] - loss: 17.190926  \n",
      "Train Epoch[1] Step[11521 / 19085] - loss: 9.734509  \n",
      "Train Epoch[1] Step[11541 / 19085] - loss: 10.642202  \n",
      "Train Epoch[1] Step[11561 / 19085] - loss: 13.736110  \n",
      "Train Epoch[1] Step[11581 / 19085] - loss: 12.808176  \n",
      "Train Epoch[1] Step[11601 / 19085] - loss: 19.684370  \n",
      "Train Epoch[1] Step[11621 / 19085] - loss: 12.699244  \n",
      "Train Epoch[1] Step[11641 / 19085] - loss: 16.450058  \n",
      "Train Epoch[1] Step[11661 / 19085] - loss: 26.728436  \n",
      "Train Epoch[1] Step[11681 / 19085] - loss: 14.938938  \n",
      "Train Epoch[1] Step[11701 / 19085] - loss: 26.556450  \n",
      "Train Epoch[1] Step[11721 / 19085] - loss: 8.102413  \n",
      "Train Epoch[1] Step[11741 / 19085] - loss: 14.872657  \n",
      "Train Epoch[1] Step[11761 / 19085] - loss: 23.338928  \n",
      "Train Epoch[1] Step[11781 / 19085] - loss: 21.776236  \n",
      "Train Epoch[1] Step[11801 / 19085] - loss: 15.338133  \n",
      "Train Epoch[1] Step[11821 / 19085] - loss: 13.675227  \n",
      "Train Epoch[1] Step[11841 / 19085] - loss: 23.426716  \n",
      "Train Epoch[1] Step[11861 / 19085] - loss: 18.585861  \n",
      "Train Epoch[1] Step[11881 / 19085] - loss: 19.453094  \n",
      "Train Epoch[1] Step[11901 / 19085] - loss: 14.279375  \n",
      "Train Epoch[1] Step[11921 / 19085] - loss: 17.553061  \n",
      "Train Epoch[1] Step[11941 / 19085] - loss: 20.426439  \n",
      "Train Epoch[1] Step[11961 / 19085] - loss: 28.957890  \n",
      "Train Epoch[1] Step[11981 / 19085] - loss: 17.632114  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:00<00:00, 13.24it/s]\n",
      "Dev Loss: 15.753627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.3823    0.0873    0.1421     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.1450    0.0437    0.0672     22839\n",
      "           T     0.3958    0.2925    0.3364     22956\n",
      "\n",
      "   micro avg     0.3352    0.1353    0.1928     73869\n",
      "   macro avg     0.2308    0.1059    0.1364     73869\n",
      "weighted avg     0.3030    0.1353    0.1756     73869\n",
      "\n",
      "best f1: 0.16, current f1: 0.19\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[12001 / 19085] - loss: 20.030836  \n",
      "Train Epoch[1] Step[12021 / 19085] - loss: 17.729240  \n",
      "Train Epoch[1] Step[12041 / 19085] - loss: 20.941223  \n",
      "Train Epoch[1] Step[12061 / 19085] - loss: 14.323741  \n",
      "Train Epoch[1] Step[12081 / 19085] - loss: 19.640697  \n",
      "Train Epoch[1] Step[12101 / 19085] - loss: 20.202427  \n",
      "Train Epoch[1] Step[12121 / 19085] - loss: 25.761658  \n",
      "Train Epoch[1] Step[12141 / 19085] - loss: 17.940031  \n",
      "Train Epoch[1] Step[12161 / 19085] - loss: 21.437805  \n",
      "Train Epoch[1] Step[12181 / 19085] - loss: 10.291740  \n",
      "Train Epoch[1] Step[12201 / 19085] - loss: 16.867645  \n",
      "Train Epoch[1] Step[12221 / 19085] - loss: 12.078524  \n",
      "Train Epoch[1] Step[12241 / 19085] - loss: 13.955585  \n",
      "Train Epoch[1] Step[12261 / 19085] - loss: 30.222046  \n",
      "Train Epoch[1] Step[12281 / 19085] - loss: 20.223366  \n",
      "Train Epoch[1] Step[12301 / 19085] - loss: 21.865049  \n",
      "Train Epoch[1] Step[12321 / 19085] - loss: 14.588367  \n",
      "Train Epoch[1] Step[12341 / 19085] - loss: 9.405414  \n",
      "Train Epoch[1] Step[12361 / 19085] - loss: 15.549945  \n",
      "Train Epoch[1] Step[12381 / 19085] - loss: 14.059829  \n",
      "Train Epoch[1] Step[12401 / 19085] - loss: 14.592175  \n",
      "Train Epoch[1] Step[12421 / 19085] - loss: 22.000988  \n",
      "Train Epoch[1] Step[12441 / 19085] - loss: 10.291808  \n",
      "Train Epoch[1] Step[12461 / 19085] - loss: 11.256403  \n",
      "Train Epoch[1] Step[12481 / 19085] - loss: 15.905935  \n",
      "Train Epoch[1] Step[12501 / 19085] - loss: 18.670574  \n",
      "Train Epoch[1] Step[12521 / 19085] - loss: 18.305525  \n",
      "Train Epoch[1] Step[12541 / 19085] - loss: 7.468923  \n",
      "Train Epoch[1] Step[12561 / 19085] - loss: 14.001282  \n",
      "Train Epoch[1] Step[12581 / 19085] - loss: 18.437979  \n",
      "Train Epoch[1] Step[12601 / 19085] - loss: 7.128558  \n",
      "Train Epoch[1] Step[12621 / 19085] - loss: 21.157019  \n",
      "Train Epoch[1] Step[12641 / 19085] - loss: 9.698248  \n",
      "Train Epoch[1] Step[12661 / 19085] - loss: 9.603059  \n",
      "Train Epoch[1] Step[12681 / 19085] - loss: 19.956858  \n",
      "Train Epoch[1] Step[12701 / 19085] - loss: 21.305807  \n",
      "Train Epoch[1] Step[12721 / 19085] - loss: 27.096359  \n",
      "Train Epoch[1] Step[12741 / 19085] - loss: 24.594658  \n",
      "Train Epoch[1] Step[12761 / 19085] - loss: 19.321785  \n",
      "Train Epoch[1] Step[12781 / 19085] - loss: 26.723492  \n",
      "Train Epoch[1] Step[12801 / 19085] - loss: 21.940456  \n",
      "Train Epoch[1] Step[12821 / 19085] - loss: 13.011536  \n",
      "Train Epoch[1] Step[12841 / 19085] - loss: 10.241293  \n",
      "Train Epoch[1] Step[12861 / 19085] - loss: 15.162402  \n",
      "Train Epoch[1] Step[12881 / 19085] - loss: 10.110601  \n",
      "Train Epoch[1] Step[12901 / 19085] - loss: 15.862155  \n",
      "Train Epoch[1] Step[12921 / 19085] - loss: 10.510833  \n",
      "Train Epoch[1] Step[12941 / 19085] - loss: 19.843510  \n",
      "Train Epoch[1] Step[12961 / 19085] - loss: 15.543852  \n",
      "Train Epoch[1] Step[12981 / 19085] - loss: 19.070894  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:10<00:00, 12.87it/s]\n",
      "Dev Loss: 15.018129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.4055    0.0999    0.1603     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.1673    0.0542    0.0819     22839\n",
      "           T     0.4309    0.3077    0.3590     22956\n",
      "\n",
      "   micro avg     0.3609    0.1477    0.2096     73869\n",
      "   macro avg     0.2509    0.1155    0.1503     73869\n",
      "weighted avg     0.3290    0.1477    0.1936     73869\n",
      "\n",
      "best f1: 0.19, current f1: 0.21\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[13001 / 19085] - loss: 12.101684  \n",
      "Train Epoch[1] Step[13021 / 19085] - loss: 18.182270  \n",
      "Train Epoch[1] Step[13041 / 19085] - loss: 14.405174  \n",
      "Train Epoch[1] Step[13061 / 19085] - loss: 9.185576  \n",
      "Train Epoch[1] Step[13081 / 19085] - loss: 22.568756  \n",
      "Train Epoch[1] Step[13101 / 19085] - loss: 24.230078  \n",
      "Train Epoch[1] Step[13121 / 19085] - loss: 18.412823  \n",
      "Train Epoch[1] Step[13141 / 19085] - loss: 14.340315  \n",
      "Train Epoch[1] Step[13161 / 19085] - loss: 12.891505  \n",
      "Train Epoch[1] Step[13181 / 19085] - loss: 18.521074  \n",
      "Train Epoch[1] Step[13201 / 19085] - loss: 18.232224  \n",
      "Train Epoch[1] Step[13221 / 19085] - loss: 17.966721  \n",
      "Train Epoch[1] Step[13241 / 19085] - loss: 17.358679  \n",
      "Train Epoch[1] Step[13261 / 19085] - loss: 8.383224  \n",
      "Train Epoch[1] Step[13281 / 19085] - loss: 22.781012  \n",
      "Train Epoch[1] Step[13301 / 19085] - loss: 10.202470  \n",
      "Train Epoch[1] Step[13321 / 19085] - loss: 22.560410  \n",
      "Train Epoch[1] Step[13341 / 19085] - loss: 8.991102  \n",
      "Train Epoch[1] Step[13361 / 19085] - loss: 8.972527  \n",
      "Train Epoch[1] Step[13381 / 19085] - loss: 9.559577  \n",
      "Train Epoch[1] Step[13401 / 19085] - loss: 14.864042  \n",
      "Train Epoch[1] Step[13421 / 19085] - loss: 6.071069  \n",
      "Train Epoch[1] Step[13441 / 19085] - loss: 10.058556  \n",
      "Train Epoch[1] Step[13461 / 19085] - loss: 12.292923  \n",
      "Train Epoch[1] Step[13481 / 19085] - loss: 9.743460  \n",
      "Train Epoch[1] Step[13501 / 19085] - loss: 16.052828  \n",
      "Train Epoch[1] Step[13521 / 19085] - loss: 19.015469  \n",
      "Train Epoch[1] Step[13541 / 19085] - loss: 13.650770  \n",
      "Train Epoch[1] Step[13561 / 19085] - loss: 13.966339  \n",
      "Train Epoch[1] Step[13581 / 19085] - loss: 20.521236  \n",
      "Train Epoch[1] Step[13601 / 19085] - loss: 10.788478  \n",
      "Train Epoch[1] Step[13621 / 19085] - loss: 13.690771  \n",
      "Train Epoch[1] Step[13641 / 19085] - loss: 17.914043  \n",
      "Train Epoch[1] Step[13661 / 19085] - loss: 8.649427  \n",
      "Train Epoch[1] Step[13681 / 19085] - loss: 10.284347  \n",
      "Train Epoch[1] Step[13701 / 19085] - loss: 4.505143  \n",
      "Train Epoch[1] Step[13721 / 19085] - loss: 13.872219  \n",
      "Train Epoch[1] Step[13741 / 19085] - loss: 20.930943  \n",
      "Train Epoch[1] Step[13761 / 19085] - loss: 17.565128  \n",
      "Train Epoch[1] Step[13781 / 19085] - loss: 10.665346  \n",
      "Train Epoch[1] Step[13801 / 19085] - loss: 13.256572  \n",
      "Train Epoch[1] Step[13821 / 19085] - loss: 19.807812  \n",
      "Train Epoch[1] Step[13841 / 19085] - loss: 10.597464  \n",
      "Train Epoch[1] Step[13861 / 19085] - loss: 11.794151  \n",
      "Train Epoch[1] Step[13881 / 19085] - loss: 12.616976  \n",
      "Train Epoch[1] Step[13901 / 19085] - loss: 13.331480  \n",
      "Train Epoch[1] Step[13921 / 19085] - loss: 20.567492  \n",
      "Train Epoch[1] Step[13941 / 19085] - loss: 9.012531  \n",
      "Train Epoch[1] Step[13961 / 19085] - loss: 13.944351  \n",
      "Train Epoch[1] Step[13981 / 19085] - loss: 17.241163  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:25<00:00, 12.39it/s]\n",
      "Dev Loss: 14.358516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.4421    0.0967    0.1587     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.2032    0.0755    0.1101     22839\n",
      "           T     0.4902    0.3096    0.3795     22956\n",
      "\n",
      "   micro avg     0.3957    0.1538    0.2215     73869\n",
      "   macro avg     0.2839    0.1205    0.1621     73869\n",
      "weighted avg     0.3715    0.1538    0.2081     73869\n",
      "\n",
      "best f1: 0.21, current f1: 0.22\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[14001 / 19085] - loss: 13.172178  \n",
      "Train Epoch[1] Step[14021 / 19085] - loss: 17.167738  \n",
      "Train Epoch[1] Step[14041 / 19085] - loss: 12.392971  \n",
      "Train Epoch[1] Step[14061 / 19085] - loss: 21.313915  \n",
      "Train Epoch[1] Step[14081 / 19085] - loss: 17.387106  \n",
      "Train Epoch[1] Step[14101 / 19085] - loss: 17.502464  \n",
      "Train Epoch[1] Step[14121 / 19085] - loss: 6.814088  \n",
      "Train Epoch[1] Step[14141 / 19085] - loss: 10.749165  \n",
      "Train Epoch[1] Step[14161 / 19085] - loss: 13.029204  \n",
      "Train Epoch[1] Step[14181 / 19085] - loss: 14.272853  \n",
      "Train Epoch[1] Step[14201 / 19085] - loss: 15.317756  \n",
      "Train Epoch[1] Step[14221 / 19085] - loss: 18.134872  \n",
      "Train Epoch[1] Step[14241 / 19085] - loss: 17.098995  \n",
      "Train Epoch[1] Step[14261 / 19085] - loss: 13.489406  \n",
      "Train Epoch[1] Step[14281 / 19085] - loss: 13.023659  \n",
      "Train Epoch[1] Step[14301 / 19085] - loss: 20.225620  \n",
      "Train Epoch[1] Step[14321 / 19085] - loss: 10.452392  \n",
      "Train Epoch[1] Step[14341 / 19085] - loss: 14.662903  \n",
      "Train Epoch[1] Step[14361 / 19085] - loss: 12.589359  \n",
      "Train Epoch[1] Step[14381 / 19085] - loss: 19.100451  \n",
      "Train Epoch[1] Step[14401 / 19085] - loss: 11.906721  \n",
      "Train Epoch[1] Step[14421 / 19085] - loss: 14.893512  \n",
      "Train Epoch[1] Step[14441 / 19085] - loss: 20.064484  \n",
      "Train Epoch[1] Step[14461 / 19085] - loss: 13.747272  \n",
      "Train Epoch[1] Step[14481 / 19085] - loss: 12.248362  \n",
      "Train Epoch[1] Step[14501 / 19085] - loss: 14.182590  \n",
      "Train Epoch[1] Step[14521 / 19085] - loss: 11.768837  \n",
      "Train Epoch[1] Step[14541 / 19085] - loss: 10.165142  \n",
      "Train Epoch[1] Step[14561 / 19085] - loss: 8.719566  \n",
      "Train Epoch[1] Step[14581 / 19085] - loss: 17.640488  \n",
      "Train Epoch[1] Step[14601 / 19085] - loss: 11.230190  \n",
      "Train Epoch[1] Step[14621 / 19085] - loss: 8.059155  \n",
      "Train Epoch[1] Step[14641 / 19085] - loss: 15.007850  \n",
      "Train Epoch[1] Step[14661 / 19085] - loss: 15.422366  \n",
      "Train Epoch[1] Step[14681 / 19085] - loss: 12.660304  \n",
      "Train Epoch[1] Step[14701 / 19085] - loss: 10.047840  \n",
      "Train Epoch[1] Step[14721 / 19085] - loss: 13.306095  \n",
      "Train Epoch[1] Step[14741 / 19085] - loss: 13.259272  \n",
      "Train Epoch[1] Step[14761 / 19085] - loss: 11.848946  \n",
      "Train Epoch[1] Step[14781 / 19085] - loss: 17.150581  \n",
      "Train Epoch[1] Step[14801 / 19085] - loss: 12.561605  \n",
      "Train Epoch[1] Step[14821 / 19085] - loss: 18.344254  \n",
      "Train Epoch[1] Step[14841 / 19085] - loss: 15.374866  \n",
      "Train Epoch[1] Step[14861 / 19085] - loss: 10.685442  \n",
      "Train Epoch[1] Step[14881 / 19085] - loss: 14.723414  \n",
      "Train Epoch[1] Step[14901 / 19085] - loss: 12.561707  \n",
      "Train Epoch[1] Step[14921 / 19085] - loss: 14.797690  \n",
      "Train Epoch[1] Step[14941 / 19085] - loss: 9.096877  \n",
      "Train Epoch[1] Step[14961 / 19085] - loss: 19.041790  \n",
      "Train Epoch[1] Step[14981 / 19085] - loss: 10.713562  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:01<00:00, 13.21it/s]\n",
      "Dev Loss: 13.786269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.4796    0.1153    0.1859     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.2134    0.0859    0.1225     22839\n",
      "           T     0.5185    0.2636    0.3495     22956\n",
      "\n",
      "   micro avg     0.4062    0.1493    0.2183     73869\n",
      "   macro avg     0.3029    0.1162    0.1645     73869\n",
      "weighted avg     0.3967    0.1493    0.2122     73869\n",
      "\n",
      "best f1: 0.22, current f1: 0.22\n",
      "\n",
      "Train Epoch[1] Step[15001 / 19085] - loss: 20.609453  \n",
      "Train Epoch[1] Step[15021 / 19085] - loss: 17.221764  \n",
      "Train Epoch[1] Step[15041 / 19085] - loss: 14.029562  \n",
      "Train Epoch[1] Step[15061 / 19085] - loss: 27.709011  \n",
      "Train Epoch[1] Step[15081 / 19085] - loss: 4.479277  \n",
      "Train Epoch[1] Step[15101 / 19085] - loss: 17.728271  \n",
      "Train Epoch[1] Step[15121 / 19085] - loss: 10.502004  \n",
      "Train Epoch[1] Step[15141 / 19085] - loss: 27.276047  \n",
      "Train Epoch[1] Step[15161 / 19085] - loss: 6.095013  \n",
      "Train Epoch[1] Step[15181 / 19085] - loss: 9.581335  \n",
      "Train Epoch[1] Step[15201 / 19085] - loss: 14.984686  \n",
      "Train Epoch[1] Step[15221 / 19085] - loss: 16.388474  \n",
      "Train Epoch[1] Step[15241 / 19085] - loss: 10.653486  \n",
      "Train Epoch[1] Step[15261 / 19085] - loss: 11.784526  \n",
      "Train Epoch[1] Step[15281 / 19085] - loss: 11.673594  \n",
      "Train Epoch[1] Step[15301 / 19085] - loss: 10.235271  \n",
      "Train Epoch[1] Step[15321 / 19085] - loss: 14.936248  \n",
      "Train Epoch[1] Step[15341 / 19085] - loss: 8.662248  \n",
      "Train Epoch[1] Step[15361 / 19085] - loss: 8.759502  \n",
      "Train Epoch[1] Step[15381 / 19085] - loss: 13.466769  \n",
      "Train Epoch[1] Step[15401 / 19085] - loss: 10.270328  \n",
      "Train Epoch[1] Step[15421 / 19085] - loss: 9.794033  \n",
      "Train Epoch[1] Step[15441 / 19085] - loss: 13.037035  \n",
      "Train Epoch[1] Step[15461 / 19085] - loss: 7.825279  \n",
      "Train Epoch[1] Step[15481 / 19085] - loss: 13.143313  \n",
      "Train Epoch[1] Step[15501 / 19085] - loss: 22.902090  \n",
      "Train Epoch[1] Step[15521 / 19085] - loss: 13.381241  \n",
      "Train Epoch[1] Step[15541 / 19085] - loss: 17.349768  \n",
      "Train Epoch[1] Step[15561 / 19085] - loss: 16.146873  \n",
      "Train Epoch[1] Step[15581 / 19085] - loss: 15.293124  \n",
      "Train Epoch[1] Step[15601 / 19085] - loss: 20.693501  \n",
      "Train Epoch[1] Step[15621 / 19085] - loss: 10.693290  \n",
      "Train Epoch[1] Step[15641 / 19085] - loss: 9.843015  \n",
      "Train Epoch[1] Step[15661 / 19085] - loss: 20.923559  \n",
      "Train Epoch[1] Step[15681 / 19085] - loss: 18.347275  \n",
      "Train Epoch[1] Step[15701 / 19085] - loss: 15.941166  \n",
      "Train Epoch[1] Step[15721 / 19085] - loss: 8.197557  \n",
      "Train Epoch[1] Step[15741 / 19085] - loss: 10.073233  \n",
      "Train Epoch[1] Step[15761 / 19085] - loss: 7.456278  \n",
      "Train Epoch[1] Step[15781 / 19085] - loss: 8.065490  \n",
      "Train Epoch[1] Step[15801 / 19085] - loss: 8.130063  \n",
      "Train Epoch[1] Step[15821 / 19085] - loss: 11.536300  \n",
      "Train Epoch[1] Step[15841 / 19085] - loss: 8.010671  \n",
      "Train Epoch[1] Step[15861 / 19085] - loss: 3.798029  \n",
      "Train Epoch[1] Step[15881 / 19085] - loss: 8.106503  \n",
      "Train Epoch[1] Step[15901 / 19085] - loss: 20.731728  \n",
      "Train Epoch[1] Step[15921 / 19085] - loss: 12.148845  \n",
      "Train Epoch[1] Step[15941 / 19085] - loss: 12.282557  \n",
      "Train Epoch[1] Step[15961 / 19085] - loss: 9.167144  \n",
      "Train Epoch[1] Step[15981 / 19085] - loss: 16.561638  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:52<00:00, 11.56it/s]\n",
      "Dev Loss: 13.139515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.4951    0.1355    0.2128     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.2491    0.1082    0.1509     22839\n",
      "           T     0.6037    0.3246    0.4222     22956\n",
      "\n",
      "   micro avg     0.4577    0.1823    0.2607     73869\n",
      "   macro avg     0.3370    0.1421    0.1965     73869\n",
      "weighted avg     0.4397    0.1823    0.2531     73869\n",
      "\n",
      "best f1: 0.22, current f1: 0.26\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[16001 / 19085] - loss: 12.815424  \n",
      "Train Epoch[1] Step[16021 / 19085] - loss: 14.003832  \n",
      "Train Epoch[1] Step[16041 / 19085] - loss: 15.205012  \n",
      "Train Epoch[1] Step[16061 / 19085] - loss: 9.671446  \n",
      "Train Epoch[1] Step[16081 / 19085] - loss: 7.808029  \n",
      "Train Epoch[1] Step[16101 / 19085] - loss: 14.774292  \n",
      "Train Epoch[1] Step[16121 / 19085] - loss: 8.727016  \n",
      "Train Epoch[1] Step[16141 / 19085] - loss: 7.913639  \n",
      "Train Epoch[1] Step[16161 / 19085] - loss: 13.713663  \n",
      "Train Epoch[1] Step[16181 / 19085] - loss: 9.461187  \n",
      "Train Epoch[1] Step[16201 / 19085] - loss: 11.900846  \n",
      "Train Epoch[1] Step[16221 / 19085] - loss: 17.194439  \n",
      "Train Epoch[1] Step[16241 / 19085] - loss: 9.312641  \n",
      "Train Epoch[1] Step[16261 / 19085] - loss: 14.325623  \n",
      "Train Epoch[1] Step[16281 / 19085] - loss: 14.078921  \n",
      "Train Epoch[1] Step[16301 / 19085] - loss: 12.367701  \n",
      "Train Epoch[1] Step[16321 / 19085] - loss: 9.316225  \n",
      "Train Epoch[1] Step[16341 / 19085] - loss: 5.715587  \n",
      "Train Epoch[1] Step[16361 / 19085] - loss: 27.590965  \n",
      "Train Epoch[1] Step[16381 / 19085] - loss: 17.513729  \n",
      "Train Epoch[1] Step[16401 / 19085] - loss: 9.882364  \n",
      "Train Epoch[1] Step[16421 / 19085] - loss: 10.136204  \n",
      "Train Epoch[1] Step[16441 / 19085] - loss: 16.466391  \n",
      "Train Epoch[1] Step[16461 / 19085] - loss: 28.314831  \n",
      "Train Epoch[1] Step[16481 / 19085] - loss: 9.451953  \n",
      "Train Epoch[1] Step[16501 / 19085] - loss: 9.700492  \n",
      "Train Epoch[1] Step[16521 / 19085] - loss: 11.220987  \n",
      "Train Epoch[1] Step[16541 / 19085] - loss: 8.894091  \n",
      "Train Epoch[1] Step[16561 / 19085] - loss: 6.918130  \n",
      "Train Epoch[1] Step[16581 / 19085] - loss: 18.386356  \n",
      "Train Epoch[1] Step[16601 / 19085] - loss: 18.566399  \n",
      "Train Epoch[1] Step[16621 / 19085] - loss: 9.152966  \n",
      "Train Epoch[1] Step[16641 / 19085] - loss: 8.174850  \n",
      "Train Epoch[1] Step[16661 / 19085] - loss: 9.615305  \n",
      "Train Epoch[1] Step[16681 / 19085] - loss: 15.277435  \n",
      "Train Epoch[1] Step[16701 / 19085] - loss: 12.458794  \n",
      "Train Epoch[1] Step[16721 / 19085] - loss: 11.033689  \n",
      "Train Epoch[1] Step[16741 / 19085] - loss: 12.438492  \n",
      "Train Epoch[1] Step[16761 / 19085] - loss: 13.478389  \n",
      "Train Epoch[1] Step[16781 / 19085] - loss: 11.312180  \n",
      "Train Epoch[1] Step[16801 / 19085] - loss: 14.508451  \n",
      "Train Epoch[1] Step[16821 / 19085] - loss: 17.578154  \n",
      "Train Epoch[1] Step[16841 / 19085] - loss: 29.879150  \n",
      "Train Epoch[1] Step[16861 / 19085] - loss: 15.019046  \n",
      "Train Epoch[1] Step[16881 / 19085] - loss: 12.606524  \n",
      "Train Epoch[1] Step[16901 / 19085] - loss: 10.225315  \n",
      "Train Epoch[1] Step[16921 / 19085] - loss: 12.307331  \n",
      "Train Epoch[1] Step[16941 / 19085] - loss: 9.452194  \n",
      "Train Epoch[1] Step[16961 / 19085] - loss: 12.518077  \n",
      "Train Epoch[1] Step[16981 / 19085] - loss: 11.594107  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:07<00:00, 11.15it/s]\n",
      "Dev Loss: 12.471593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.5276    0.1747    0.2625     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.3121    0.1739    0.2234     22839\n",
      "           T     0.6416    0.4114    0.5014     22956\n",
      "\n",
      "   micro avg     0.4981    0.2434    0.3270     73869\n",
      "   macro avg     0.3703    0.1900    0.2468     73869\n",
      "weighted avg     0.4824    0.2434    0.3177     73869\n",
      "\n",
      "best f1: 0.26, current f1: 0.33\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[1] Step[17001 / 19085] - loss: 14.994020  \n",
      "Train Epoch[1] Step[17021 / 19085] - loss: 7.522944  \n",
      "Train Epoch[1] Step[17041 / 19085] - loss: 21.691551  \n",
      "Train Epoch[1] Step[17061 / 19085] - loss: 4.376665  \n",
      "Train Epoch[1] Step[17081 / 19085] - loss: 10.492001  \n",
      "Train Epoch[1] Step[17101 / 19085] - loss: 12.096118  \n",
      "Train Epoch[1] Step[17121 / 19085] - loss: 6.628573  \n",
      "Train Epoch[1] Step[17141 / 19085] - loss: 16.023098  \n",
      "Train Epoch[1] Step[17161 / 19085] - loss: 13.187320  \n",
      "Train Epoch[1] Step[17181 / 19085] - loss: 13.835505  \n",
      "Train Epoch[1] Step[17201 / 19085] - loss: 17.322346  \n",
      "Train Epoch[1] Step[17221 / 19085] - loss: 21.478613  \n",
      "Train Epoch[1] Step[17241 / 19085] - loss: 13.664446  \n",
      "Train Epoch[1] Step[17261 / 19085] - loss: 15.674345  \n",
      "Train Epoch[1] Step[17281 / 19085] - loss: 13.238780  \n",
      "Train Epoch[1] Step[17301 / 19085] - loss: 13.075081  \n",
      "Train Epoch[1] Step[17321 / 19085] - loss: 18.166569  \n",
      "Train Epoch[1] Step[17341 / 19085] - loss: 6.919197  \n",
      "Train Epoch[1] Step[17361 / 19085] - loss: 16.958595  \n",
      "Train Epoch[1] Step[17381 / 19085] - loss: 7.125694  \n",
      "Train Epoch[1] Step[17401 / 19085] - loss: 15.550322  \n",
      "Train Epoch[1] Step[17421 / 19085] - loss: 14.487015  \n",
      "Train Epoch[1] Step[17441 / 19085] - loss: 8.186588  \n",
      "Train Epoch[1] Step[17461 / 19085] - loss: 5.791921  \n",
      "Train Epoch[1] Step[17481 / 19085] - loss: 13.693552  \n",
      "Train Epoch[1] Step[17501 / 19085] - loss: 14.506227  \n",
      "Train Epoch[1] Step[17521 / 19085] - loss: 10.835854  \n",
      "Train Epoch[1] Step[17541 / 19085] - loss: 11.452330  \n",
      "Train Epoch[1] Step[17561 / 19085] - loss: 8.967898  \n",
      "Train Epoch[1] Step[17581 / 19085] - loss: 12.655333  \n",
      "Train Epoch[1] Step[17601 / 19085] - loss: 15.034617  \n",
      "Train Epoch[1] Step[17621 / 19085] - loss: 9.741626  \n",
      "Train Epoch[1] Step[17641 / 19085] - loss: 16.824684  \n",
      "Train Epoch[1] Step[17661 / 19085] - loss: 14.672920  \n",
      "Train Epoch[1] Step[17681 / 19085] - loss: 14.974165  \n",
      "Train Epoch[1] Step[17701 / 19085] - loss: 9.563120  \n",
      "Train Epoch[1] Step[17721 / 19085] - loss: 16.975355  \n",
      "Train Epoch[1] Step[17741 / 19085] - loss: 9.668742  \n",
      "Train Epoch[1] Step[17761 / 19085] - loss: 13.608900  \n",
      "Train Epoch[1] Step[17781 / 19085] - loss: 10.322651  \n",
      "Train Epoch[1] Step[17801 / 19085] - loss: 13.948370  \n",
      "Train Epoch[1] Step[17821 / 19085] - loss: 14.331829  \n",
      "Train Epoch[1] Step[17841 / 19085] - loss: 9.983665  \n",
      "Train Epoch[1] Step[17861 / 19085] - loss: 14.956274  \n",
      "Train Epoch[1] Step[17881 / 19085] - loss: 10.733068  \n",
      "Train Epoch[1] Step[17901 / 19085] - loss: 6.023075  \n",
      "Train Epoch[1] Step[17921 / 19085] - loss: 8.473837  \n",
      "Train Epoch[1] Step[17941 / 19085] - loss: 10.114322  \n",
      "Train Epoch[1] Step[17961 / 19085] - loss: 16.326635  \n",
      "Train Epoch[1] Step[17981 / 19085] - loss: 9.023502  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:14<00:00, 10.99it/s]\n",
      "Dev Loss: 12.018122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.5494    0.1970    0.2900     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.3211    0.1810    0.2315     22839\n",
      "           T     0.6576    0.3627    0.4676     22956\n",
      "\n",
      "   micro avg     0.5045    0.2383    0.3237     73869\n",
      "   macro avg     0.3820    0.1852    0.2473     73869\n",
      "weighted avg     0.4979    0.2383    0.3194     73869\n",
      "\n",
      "best f1: 0.33, current f1: 0.32\n",
      "\n",
      "Train Epoch[1] Step[18001 / 19085] - loss: 5.216474  \n",
      "Train Epoch[1] Step[18021 / 19085] - loss: 10.015108  \n",
      "Train Epoch[1] Step[18041 / 19085] - loss: 17.154140  \n",
      "Train Epoch[1] Step[18061 / 19085] - loss: 11.146297  \n",
      "Train Epoch[1] Step[18081 / 19085] - loss: 15.570299  \n",
      "Train Epoch[1] Step[18101 / 19085] - loss: 15.211879  \n",
      "Train Epoch[1] Step[18121 / 19085] - loss: 8.309948  \n",
      "Train Epoch[1] Step[18141 / 19085] - loss: 6.151941  \n",
      "Train Epoch[1] Step[18161 / 19085] - loss: 9.906015  \n",
      "Train Epoch[1] Step[18181 / 19085] - loss: 4.834279  \n",
      "Train Epoch[1] Step[18201 / 19085] - loss: 3.828491  \n",
      "Train Epoch[1] Step[18221 / 19085] - loss: 15.895285  \n",
      "Train Epoch[1] Step[18241 / 19085] - loss: 12.339001  \n",
      "Train Epoch[1] Step[18261 / 19085] - loss: 5.968352  \n",
      "Train Epoch[1] Step[18281 / 19085] - loss: 8.950447  \n",
      "Train Epoch[1] Step[18301 / 19085] - loss: 13.967143  \n",
      "Train Epoch[1] Step[18321 / 19085] - loss: 9.273277  \n",
      "Train Epoch[1] Step[18341 / 19085] - loss: 14.750271  \n",
      "Train Epoch[1] Step[18361 / 19085] - loss: 8.286179  \n",
      "Train Epoch[1] Step[18381 / 19085] - loss: 8.601345  \n",
      "Train Epoch[1] Step[18401 / 19085] - loss: 8.186284  \n",
      "Train Epoch[1] Step[18421 / 19085] - loss: 9.173136  \n",
      "Train Epoch[1] Step[18441 / 19085] - loss: 13.001273  \n",
      "Train Epoch[1] Step[18461 / 19085] - loss: 17.490587  \n",
      "Train Epoch[1] Step[18481 / 19085] - loss: 9.043896  \n",
      "Train Epoch[1] Step[18501 / 19085] - loss: 11.928413  \n",
      "Train Epoch[1] Step[18521 / 19085] - loss: 6.378913  \n",
      "Train Epoch[1] Step[18541 / 19085] - loss: 8.366850  \n",
      "Train Epoch[1] Step[18561 / 19085] - loss: 18.465561  \n",
      "Train Epoch[1] Step[18581 / 19085] - loss: 14.688360  \n",
      "Train Epoch[1] Step[18601 / 19085] - loss: 13.376656  \n",
      "Train Epoch[1] Step[18621 / 19085] - loss: 12.605852  \n",
      "Train Epoch[1] Step[18641 / 19085] - loss: 7.431541  \n",
      "Train Epoch[1] Step[18661 / 19085] - loss: 22.777454  \n",
      "Train Epoch[1] Step[18681 / 19085] - loss: 19.991486  \n",
      "Train Epoch[1] Step[18701 / 19085] - loss: 14.940762  \n",
      "Train Epoch[1] Step[18721 / 19085] - loss: 7.571533  \n",
      "Train Epoch[1] Step[18741 / 19085] - loss: 10.848895  \n",
      "Train Epoch[1] Step[18761 / 19085] - loss: 9.922432  \n",
      "Train Epoch[1] Step[18781 / 19085] - loss: 9.278925  \n",
      "Train Epoch[1] Step[18801 / 19085] - loss: 10.759833  \n",
      "Train Epoch[1] Step[18821 / 19085] - loss: 11.878384  \n",
      "Train Epoch[1] Step[18841 / 19085] - loss: 14.781291  \n",
      "Train Epoch[1] Step[18861 / 19085] - loss: 8.917343  \n",
      "Train Epoch[1] Step[18881 / 19085] - loss: 10.543304  \n",
      "Train Epoch[1] Step[18901 / 19085] - loss: 9.365312  \n",
      "Train Epoch[1] Step[18921 / 19085] - loss: 14.305336  \n",
      "Train Epoch[1] Step[18941 / 19085] - loss: 12.609158  \n",
      "Train Epoch[1] Step[18961 / 19085] - loss: 10.936945  \n",
      "Train Epoch[1] Step[18981 / 19085] - loss: 11.230937  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:18<00:00, 10.87it/s]\n",
      "Dev Loss: 11.700414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.5534    0.1654    0.2547     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.3188    0.1683    0.2203     22839\n",
      "           T     0.6721    0.3611    0.4698     22956\n",
      "\n",
      "   micro avg     0.5111    0.2227    0.3103     73869\n",
      "   macro avg     0.3861    0.1737    0.2362     73869\n",
      "weighted avg     0.5031    0.2227    0.3042     73869\n",
      "\n",
      "best f1: 0.33, current f1: 0.31\n",
      "\n",
      "Train Epoch[1] Step[19001 / 19085] - loss: 9.879735  \n",
      "Train Epoch[1] Step[19021 / 19085] - loss: 9.141099  \n",
      "Train Epoch[1] Step[19041 / 19085] - loss: 16.215113  \n",
      "Train Epoch[1] Step[19061 / 19085] - loss: 7.614310  \n",
      "Train Epoch[1] Step[19081 / 19085] - loss: 9.191364  \n",
      "Train Epoch[2] Step[1 / 19085] - loss: 17.240503  \n",
      "Train Epoch[2] Step[21 / 19085] - loss: 7.759197  \n",
      "Train Epoch[2] Step[41 / 19085] - loss: 14.435003  \n",
      "Train Epoch[2] Step[61 / 19085] - loss: 10.009296  \n",
      "Train Epoch[2] Step[81 / 19085] - loss: 18.209312  \n",
      "Train Epoch[2] Step[101 / 19085] - loss: 14.334479  \n",
      "Train Epoch[2] Step[121 / 19085] - loss: 10.536468  \n",
      "Train Epoch[2] Step[141 / 19085] - loss: 11.299519  \n",
      "Train Epoch[2] Step[161 / 19085] - loss: 8.312535  \n",
      "Train Epoch[2] Step[181 / 19085] - loss: 16.032446  \n",
      "Train Epoch[2] Step[201 / 19085] - loss: 15.086143  \n",
      "Train Epoch[2] Step[221 / 19085] - loss: 7.747350  \n",
      "Train Epoch[2] Step[241 / 19085] - loss: 14.792318  \n",
      "Train Epoch[2] Step[261 / 19085] - loss: 9.612548  \n",
      "Train Epoch[2] Step[281 / 19085] - loss: 15.663020  \n",
      "Train Epoch[2] Step[301 / 19085] - loss: 5.981210  \n",
      "Train Epoch[2] Step[321 / 19085] - loss: 8.431211  \n",
      "Train Epoch[2] Step[341 / 19085] - loss: 21.329994  \n",
      "Train Epoch[2] Step[361 / 19085] - loss: 8.881240  \n",
      "Train Epoch[2] Step[381 / 19085] - loss: 15.881933  \n",
      "Train Epoch[2] Step[401 / 19085] - loss: 14.075518  \n",
      "Train Epoch[2] Step[421 / 19085] - loss: 9.230827  \n",
      "Train Epoch[2] Step[441 / 19085] - loss: 6.222440  \n",
      "Train Epoch[2] Step[461 / 19085] - loss: 9.337728  \n",
      "Train Epoch[2] Step[481 / 19085] - loss: 10.731471  \n",
      "Train Epoch[2] Step[501 / 19085] - loss: 17.931293  \n",
      "Train Epoch[2] Step[521 / 19085] - loss: 9.582596  \n",
      "Train Epoch[2] Step[541 / 19085] - loss: 10.560551  \n",
      "Train Epoch[2] Step[561 / 19085] - loss: 12.273125  \n",
      "Train Epoch[2] Step[581 / 19085] - loss: 9.777029  \n",
      "Train Epoch[2] Step[601 / 19085] - loss: 12.726176  \n",
      "Train Epoch[2] Step[621 / 19085] - loss: 10.004539  \n",
      "Train Epoch[2] Step[641 / 19085] - loss: 20.449606  \n",
      "Train Epoch[2] Step[661 / 19085] - loss: 8.969769  \n",
      "Train Epoch[2] Step[681 / 19085] - loss: 3.513572  \n",
      "Train Epoch[2] Step[701 / 19085] - loss: 10.136580  \n",
      "Train Epoch[2] Step[721 / 19085] - loss: 6.627603  \n",
      "Train Epoch[2] Step[741 / 19085] - loss: 17.018475  \n",
      "Train Epoch[2] Step[761 / 19085] - loss: 12.406711  \n",
      "Train Epoch[2] Step[781 / 19085] - loss: 13.773475  \n",
      "Train Epoch[2] Step[801 / 19085] - loss: 18.826603  \n",
      "Train Epoch[2] Step[821 / 19085] - loss: 6.872600  \n",
      "Train Epoch[2] Step[841 / 19085] - loss: 12.709598  \n",
      "Train Epoch[2] Step[861 / 19085] - loss: 8.742422  \n",
      "Train Epoch[2] Step[881 / 19085] - loss: 11.556911  \n",
      "Train Epoch[2] Step[901 / 19085] - loss: 16.517818  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:13<00:00, 11.00it/s]\n",
      "Dev Loss: 11.125119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6020    0.2440    0.3472     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.3817    0.2434    0.2972     22839\n",
      "           T     0.7111    0.4728    0.5679     22956\n",
      "\n",
      "   micro avg     0.5638    0.3084    0.3987     73869\n",
      "   macro avg     0.4237    0.2400    0.3031     73869\n",
      "weighted avg     0.5519    0.3084    0.3912     73869\n",
      "\n",
      "best f1: 0.33, current f1: 0.40\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[921 / 19085] - loss: 10.693188  \n",
      "Train Epoch[2] Step[941 / 19085] - loss: 10.450485  \n",
      "Train Epoch[2] Step[961 / 19085] - loss: 11.680987  \n",
      "Train Epoch[2] Step[981 / 19085] - loss: 8.113177  \n",
      "Train Epoch[2] Step[1001 / 19085] - loss: 11.101280  \n",
      "Train Epoch[2] Step[1021 / 19085] - loss: 13.530449  \n",
      "Train Epoch[2] Step[1041 / 19085] - loss: 12.699351  \n",
      "Train Epoch[2] Step[1061 / 19085] - loss: 6.764764  \n",
      "Train Epoch[2] Step[1081 / 19085] - loss: 9.947774  \n",
      "Train Epoch[2] Step[1101 / 19085] - loss: 10.863636  \n",
      "Train Epoch[2] Step[1121 / 19085] - loss: 7.798356  \n",
      "Train Epoch[2] Step[1141 / 19085] - loss: 14.045328  \n",
      "Train Epoch[2] Step[1161 / 19085] - loss: 12.319427  \n",
      "Train Epoch[2] Step[1181 / 19085] - loss: 11.305546  \n",
      "Train Epoch[2] Step[1201 / 19085] - loss: 14.345741  \n",
      "Train Epoch[2] Step[1221 / 19085] - loss: 8.933453  \n",
      "Train Epoch[2] Step[1241 / 19085] - loss: 8.161807  \n",
      "Train Epoch[2] Step[1261 / 19085] - loss: 6.778013  \n",
      "Train Epoch[2] Step[1281 / 19085] - loss: 11.697039  \n",
      "Train Epoch[2] Step[1301 / 19085] - loss: 10.467624  \n",
      "Train Epoch[2] Step[1321 / 19085] - loss: 13.620977  \n",
      "Train Epoch[2] Step[1341 / 19085] - loss: 14.645034  \n",
      "Train Epoch[2] Step[1361 / 19085] - loss: 12.671618  \n",
      "Train Epoch[2] Step[1381 / 19085] - loss: 8.319750  \n",
      "Train Epoch[2] Step[1401 / 19085] - loss: 14.249393  \n",
      "Train Epoch[2] Step[1421 / 19085] - loss: 15.829052  \n",
      "Train Epoch[2] Step[1441 / 19085] - loss: 12.637931  \n",
      "Train Epoch[2] Step[1461 / 19085] - loss: 18.166565  \n",
      "Train Epoch[2] Step[1481 / 19085] - loss: 7.002303  \n",
      "Train Epoch[2] Step[1501 / 19085] - loss: 8.390425  \n",
      "Train Epoch[2] Step[1521 / 19085] - loss: 13.562805  \n",
      "Train Epoch[2] Step[1541 / 19085] - loss: 8.946989  \n",
      "Train Epoch[2] Step[1561 / 19085] - loss: 14.042160  \n",
      "Train Epoch[2] Step[1581 / 19085] - loss: 6.849332  \n",
      "Train Epoch[2] Step[1601 / 19085] - loss: 9.050204  \n",
      "Train Epoch[2] Step[1621 / 19085] - loss: 9.978966  \n",
      "Train Epoch[2] Step[1641 / 19085] - loss: 6.722787  \n",
      "Train Epoch[2] Step[1661 / 19085] - loss: 9.805317  \n",
      "Train Epoch[2] Step[1681 / 19085] - loss: 9.310489  \n",
      "Train Epoch[2] Step[1701 / 19085] - loss: 8.734764  \n",
      "Train Epoch[2] Step[1721 / 19085] - loss: 6.790147  \n",
      "Train Epoch[2] Step[1741 / 19085] - loss: 7.347911  \n",
      "Train Epoch[2] Step[1761 / 19085] - loss: 9.319036  \n",
      "Train Epoch[2] Step[1781 / 19085] - loss: 14.290043  \n",
      "Train Epoch[2] Step[1801 / 19085] - loss: 10.643878  \n",
      "Train Epoch[2] Step[1821 / 19085] - loss: 11.150543  \n",
      "Train Epoch[2] Step[1841 / 19085] - loss: 7.761752  \n",
      "Train Epoch[2] Step[1861 / 19085] - loss: 16.106794  \n",
      "Train Epoch[2] Step[1881 / 19085] - loss: 9.121573  \n",
      "Train Epoch[2] Step[1901 / 19085] - loss: 9.633860  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:03<00:00, 11.26it/s]\n",
      "Dev Loss: 10.814427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6128    0.2176    0.3211     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.3975    0.2592    0.3138     22839\n",
      "           T     0.6994    0.4083    0.5156     22956\n",
      "\n",
      "   micro avg     0.5584    0.2840    0.3765     73869\n",
      "   macro avg     0.4274    0.2213    0.2876     73869\n",
      "weighted avg     0.5569    0.2840    0.3708     73869\n",
      "\n",
      "best f1: 0.40, current f1: 0.38\n",
      "\n",
      "Train Epoch[2] Step[1921 / 19085] - loss: 4.883205  \n",
      "Train Epoch[2] Step[1941 / 19085] - loss: 6.593371  \n",
      "Train Epoch[2] Step[1961 / 19085] - loss: 7.768410  \n",
      "Train Epoch[2] Step[1981 / 19085] - loss: 6.989100  \n",
      "Train Epoch[2] Step[2001 / 19085] - loss: 2.413248  \n",
      "Train Epoch[2] Step[2021 / 19085] - loss: 8.096985  \n",
      "Train Epoch[2] Step[2041 / 19085] - loss: 12.034309  \n",
      "Train Epoch[2] Step[2061 / 19085] - loss: 11.300337  \n",
      "Train Epoch[2] Step[2081 / 19085] - loss: 14.869169  \n",
      "Train Epoch[2] Step[2101 / 19085] - loss: 5.544280  \n",
      "Train Epoch[2] Step[2121 / 19085] - loss: 11.919966  \n",
      "Train Epoch[2] Step[2141 / 19085] - loss: 7.034814  \n",
      "Train Epoch[2] Step[2161 / 19085] - loss: 10.773780  \n",
      "Train Epoch[2] Step[2181 / 19085] - loss: 8.106999  \n",
      "Train Epoch[2] Step[2201 / 19085] - loss: 11.086314  \n",
      "Train Epoch[2] Step[2221 / 19085] - loss: 6.822440  \n",
      "Train Epoch[2] Step[2241 / 19085] - loss: 10.859781  \n",
      "Train Epoch[2] Step[2261 / 19085] - loss: 10.474113  \n",
      "Train Epoch[2] Step[2281 / 19085] - loss: 11.784096  \n",
      "Train Epoch[2] Step[2301 / 19085] - loss: 9.232712  \n",
      "Train Epoch[2] Step[2321 / 19085] - loss: 9.546923  \n",
      "Train Epoch[2] Step[2341 / 19085] - loss: 10.889644  \n",
      "Train Epoch[2] Step[2361 / 19085] - loss: 13.209620  \n",
      "Train Epoch[2] Step[2381 / 19085] - loss: 5.253526  \n",
      "Train Epoch[2] Step[2401 / 19085] - loss: 13.101002  \n",
      "Train Epoch[2] Step[2421 / 19085] - loss: 4.791426  \n",
      "Train Epoch[2] Step[2441 / 19085] - loss: 9.736197  \n",
      "Train Epoch[2] Step[2461 / 19085] - loss: 8.917426  \n",
      "Train Epoch[2] Step[2481 / 19085] - loss: 10.315777  \n",
      "Train Epoch[2] Step[2501 / 19085] - loss: 12.983847  \n",
      "Train Epoch[2] Step[2521 / 19085] - loss: 7.899389  \n",
      "Train Epoch[2] Step[2541 / 19085] - loss: 3.394336  \n",
      "Train Epoch[2] Step[2561 / 19085] - loss: 8.152744  \n",
      "Train Epoch[2] Step[2581 / 19085] - loss: 21.102804  \n",
      "Train Epoch[2] Step[2601 / 19085] - loss: 5.346080  \n",
      "Train Epoch[2] Step[2621 / 19085] - loss: 11.327270  \n",
      "Train Epoch[2] Step[2641 / 19085] - loss: 11.966273  \n",
      "Train Epoch[2] Step[2661 / 19085] - loss: 12.471947  \n",
      "Train Epoch[2] Step[2681 / 19085] - loss: 16.498432  \n",
      "Train Epoch[2] Step[2701 / 19085] - loss: 13.128443  \n",
      "Train Epoch[2] Step[2721 / 19085] - loss: 10.226931  \n",
      "Train Epoch[2] Step[2741 / 19085] - loss: 6.541457  \n",
      "Train Epoch[2] Step[2761 / 19085] - loss: 12.318744  \n",
      "Train Epoch[2] Step[2781 / 19085] - loss: 6.652214  \n",
      "Train Epoch[2] Step[2801 / 19085] - loss: 10.853622  \n",
      "Train Epoch[2] Step[2821 / 19085] - loss: 19.272398  \n",
      "Train Epoch[2] Step[2841 / 19085] - loss: 17.212521  \n",
      "Train Epoch[2] Step[2861 / 19085] - loss: 17.699215  \n",
      "Train Epoch[2] Step[2881 / 19085] - loss: 19.669655  \n",
      "Train Epoch[2] Step[2901 / 19085] - loss: 10.410032  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:14<00:00, 10.99it/s]\n",
      "Dev Loss: 10.408980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6307    0.2847    0.3923     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.4229    0.2708    0.3302     22839\n",
      "           T     0.7009    0.4253    0.5294     22956\n",
      "\n",
      "   micro avg     0.5796    0.3166    0.4095     73869\n",
      "   macro avg     0.4386    0.2452    0.3130     73869\n",
      "weighted avg     0.5716    0.3166    0.4053     73869\n",
      "\n",
      "best f1: 0.40, current f1: 0.41\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[2921 / 19085] - loss: 11.164137  \n",
      "Train Epoch[2] Step[2941 / 19085] - loss: 11.207533  \n",
      "Train Epoch[2] Step[2961 / 19085] - loss: 8.384049  \n",
      "Train Epoch[2] Step[2981 / 19085] - loss: 8.422470  \n",
      "Train Epoch[2] Step[3001 / 19085] - loss: 27.908539  \n",
      "Train Epoch[2] Step[3021 / 19085] - loss: 10.317566  \n",
      "Train Epoch[2] Step[3041 / 19085] - loss: 24.479183  \n",
      "Train Epoch[2] Step[3061 / 19085] - loss: 10.398546  \n",
      "Train Epoch[2] Step[3081 / 19085] - loss: 13.260527  \n",
      "Train Epoch[2] Step[3101 / 19085] - loss: 13.285701  \n",
      "Train Epoch[2] Step[3121 / 19085] - loss: 5.776524  \n",
      "Train Epoch[2] Step[3141 / 19085] - loss: 11.495834  \n",
      "Train Epoch[2] Step[3161 / 19085] - loss: 6.160656  \n",
      "Train Epoch[2] Step[3181 / 19085] - loss: 10.684688  \n",
      "Train Epoch[2] Step[3201 / 19085] - loss: 10.036753  \n",
      "Train Epoch[2] Step[3221 / 19085] - loss: 8.384773  \n",
      "Train Epoch[2] Step[3241 / 19085] - loss: 12.246547  \n",
      "Train Epoch[2] Step[3261 / 19085] - loss: 12.325629  \n",
      "Train Epoch[2] Step[3281 / 19085] - loss: 5.935148  \n",
      "Train Epoch[2] Step[3301 / 19085] - loss: 8.235378  \n",
      "Train Epoch[2] Step[3321 / 19085] - loss: 10.693416  \n",
      "Train Epoch[2] Step[3341 / 19085] - loss: 11.082975  \n",
      "Train Epoch[2] Step[3361 / 19085] - loss: 18.281628  \n",
      "Train Epoch[2] Step[3381 / 19085] - loss: 8.399847  \n",
      "Train Epoch[2] Step[3401 / 19085] - loss: 6.492914  \n",
      "Train Epoch[2] Step[3421 / 19085] - loss: 11.308017  \n",
      "Train Epoch[2] Step[3441 / 19085] - loss: 12.801628  \n",
      "Train Epoch[2] Step[3461 / 19085] - loss: 9.447405  \n",
      "Train Epoch[2] Step[3481 / 19085] - loss: 7.417068  \n",
      "Train Epoch[2] Step[3501 / 19085] - loss: 11.780159  \n",
      "Train Epoch[2] Step[3521 / 19085] - loss: 4.832537  \n",
      "Train Epoch[2] Step[3541 / 19085] - loss: 8.447771  \n",
      "Train Epoch[2] Step[3561 / 19085] - loss: 8.397364  \n",
      "Train Epoch[2] Step[3581 / 19085] - loss: 7.571094  \n",
      "Train Epoch[2] Step[3601 / 19085] - loss: 11.935191  \n",
      "Train Epoch[2] Step[3621 / 19085] - loss: 20.706810  \n",
      "Train Epoch[2] Step[3641 / 19085] - loss: 9.797983  \n",
      "Train Epoch[2] Step[3661 / 19085] - loss: 11.288577  \n",
      "Train Epoch[2] Step[3681 / 19085] - loss: 6.704147  \n",
      "Train Epoch[2] Step[3701 / 19085] - loss: 12.544505  \n",
      "Train Epoch[2] Step[3721 / 19085] - loss: 5.544403  \n",
      "Train Epoch[2] Step[3741 / 19085] - loss: 13.425909  \n",
      "Train Epoch[2] Step[3761 / 19085] - loss: 12.230147  \n",
      "Train Epoch[2] Step[3781 / 19085] - loss: 9.508676  \n",
      "Train Epoch[2] Step[3801 / 19085] - loss: 8.004673  \n",
      "Train Epoch[2] Step[3821 / 19085] - loss: 8.555270  \n",
      "Train Epoch[2] Step[3841 / 19085] - loss: 11.686026  \n",
      "Train Epoch[2] Step[3861 / 19085] - loss: 13.330887  \n",
      "Train Epoch[2] Step[3881 / 19085] - loss: 7.372921  \n",
      "Train Epoch[2] Step[3901 / 19085] - loss: 13.211853  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:53<00:00, 11.52it/s]\n",
      "Dev Loss: 10.082512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6361    0.2872    0.3958     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.4356    0.2898    0.3480     22839\n",
      "           T     0.7102    0.4469    0.5486     22956\n",
      "\n",
      "   micro avg     0.5884    0.3300    0.4229     73869\n",
      "   macro avg     0.4455    0.2560    0.3231     73869\n",
      "weighted avg     0.5803    0.3300    0.4180     73869\n",
      "\n",
      "best f1: 0.41, current f1: 0.42\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[3921 / 19085] - loss: 8.355773  \n",
      "Train Epoch[2] Step[3941 / 19085] - loss: 22.114731  \n",
      "Train Epoch[2] Step[3961 / 19085] - loss: 11.286304  \n",
      "Train Epoch[2] Step[3981 / 19085] - loss: 8.564049  \n",
      "Train Epoch[2] Step[4001 / 19085] - loss: 3.793949  \n",
      "Train Epoch[2] Step[4021 / 19085] - loss: 4.098525  \n",
      "Train Epoch[2] Step[4041 / 19085] - loss: 16.834391  \n",
      "Train Epoch[2] Step[4061 / 19085] - loss: 5.764032  \n",
      "Train Epoch[2] Step[4081 / 19085] - loss: 7.608535  \n",
      "Train Epoch[2] Step[4101 / 19085] - loss: 5.469440  \n",
      "Train Epoch[2] Step[4121 / 19085] - loss: 8.385820  \n",
      "Train Epoch[2] Step[4141 / 19085] - loss: 9.612661  \n",
      "Train Epoch[2] Step[4161 / 19085] - loss: 12.741795  \n",
      "Train Epoch[2] Step[4181 / 19085] - loss: 7.090353  \n",
      "Train Epoch[2] Step[4201 / 19085] - loss: 14.853830  \n",
      "Train Epoch[2] Step[4221 / 19085] - loss: 9.609345  \n",
      "Train Epoch[2] Step[4241 / 19085] - loss: 11.524450  \n",
      "Train Epoch[2] Step[4261 / 19085] - loss: 8.513859  \n",
      "Train Epoch[2] Step[4281 / 19085] - loss: 8.618505  \n",
      "Train Epoch[2] Step[4301 / 19085] - loss: 12.354546  \n",
      "Train Epoch[2] Step[4321 / 19085] - loss: 11.568342  \n",
      "Train Epoch[2] Step[4341 / 19085] - loss: 11.566441  \n",
      "Train Epoch[2] Step[4361 / 19085] - loss: 9.701574  \n",
      "Train Epoch[2] Step[4381 / 19085] - loss: 6.231129  \n",
      "Train Epoch[2] Step[4401 / 19085] - loss: 16.576508  \n",
      "Train Epoch[2] Step[4421 / 19085] - loss: 10.030296  \n",
      "Train Epoch[2] Step[4441 / 19085] - loss: 4.510985  \n",
      "Train Epoch[2] Step[4461 / 19085] - loss: 4.779319  \n",
      "Train Epoch[2] Step[4481 / 19085] - loss: 9.960433  \n",
      "Train Epoch[2] Step[4501 / 19085] - loss: 9.955374  \n",
      "Train Epoch[2] Step[4521 / 19085] - loss: 9.894472  \n",
      "Train Epoch[2] Step[4541 / 19085] - loss: 13.887856  \n",
      "Train Epoch[2] Step[4561 / 19085] - loss: 10.095500  \n",
      "Train Epoch[2] Step[4581 / 19085] - loss: 9.305866  \n",
      "Train Epoch[2] Step[4601 / 19085] - loss: 7.757341  \n",
      "Train Epoch[2] Step[4621 / 19085] - loss: 7.705328  \n",
      "Train Epoch[2] Step[4641 / 19085] - loss: 6.172545  \n",
      "Train Epoch[2] Step[4661 / 19085] - loss: 12.159008  \n",
      "Train Epoch[2] Step[4681 / 19085] - loss: 13.430423  \n",
      "Train Epoch[2] Step[4701 / 19085] - loss: 6.453392  \n",
      "Train Epoch[2] Step[4721 / 19085] - loss: 6.311869  \n",
      "Train Epoch[2] Step[4741 / 19085] - loss: 9.710799  \n",
      "Train Epoch[2] Step[4761 / 19085] - loss: 7.878191  \n",
      "Train Epoch[2] Step[4781 / 19085] - loss: 10.387173  \n",
      "Train Epoch[2] Step[4801 / 19085] - loss: 9.495348  \n",
      "Train Epoch[2] Step[4821 / 19085] - loss: 15.128489  \n",
      "Train Epoch[2] Step[4841 / 19085] - loss: 13.686317  \n",
      "Train Epoch[2] Step[4861 / 19085] - loss: 9.270838  \n",
      "Train Epoch[2] Step[4881 / 19085] - loss: 8.186586  \n",
      "Train Epoch[2] Step[4901 / 19085] - loss: 14.438965  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:19<00:00, 10.85it/s]\n",
      "Dev Loss: 9.804278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6458    0.2851    0.3955     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.4581    0.3054    0.3665     22839\n",
      "           T     0.7115    0.4176    0.5263     22956\n",
      "\n",
      "   micro avg     0.5967    0.3250    0.4208     73869\n",
      "   macro avg     0.4538    0.2520    0.3221     73869\n",
      "weighted avg     0.5911    0.3250    0.4167     73869\n",
      "\n",
      "best f1: 0.42, current f1: 0.42\n",
      "\n",
      "Train Epoch[2] Step[4921 / 19085] - loss: 3.253968  \n",
      "Train Epoch[2] Step[4941 / 19085] - loss: 4.812182  \n",
      "Train Epoch[2] Step[4961 / 19085] - loss: 13.434097  \n",
      "Train Epoch[2] Step[4981 / 19085] - loss: 8.741641  \n",
      "Train Epoch[2] Step[5001 / 19085] - loss: 7.733544  \n",
      "Train Epoch[2] Step[5021 / 19085] - loss: 10.886779  \n",
      "Train Epoch[2] Step[5041 / 19085] - loss: 7.475776  \n",
      "Train Epoch[2] Step[5061 / 19085] - loss: 6.529323  \n",
      "Train Epoch[2] Step[5081 / 19085] - loss: 7.225228  \n",
      "Train Epoch[2] Step[5101 / 19085] - loss: 12.658072  \n",
      "Train Epoch[2] Step[5121 / 19085] - loss: 10.804305  \n",
      "Train Epoch[2] Step[5141 / 19085] - loss: 11.406013  \n",
      "Train Epoch[2] Step[5161 / 19085] - loss: 5.545845  \n",
      "Train Epoch[2] Step[5181 / 19085] - loss: 14.226130  \n",
      "Train Epoch[2] Step[5201 / 19085] - loss: 14.299685  \n",
      "Train Epoch[2] Step[5221 / 19085] - loss: 9.698195  \n",
      "Train Epoch[2] Step[5241 / 19085] - loss: 7.163988  \n",
      "Train Epoch[2] Step[5261 / 19085] - loss: 11.876230  \n",
      "Train Epoch[2] Step[5281 / 19085] - loss: 10.842441  \n",
      "Train Epoch[2] Step[5301 / 19085] - loss: 15.489094  \n",
      "Train Epoch[2] Step[5321 / 19085] - loss: 7.274427  \n",
      "Train Epoch[2] Step[5341 / 19085] - loss: 6.748550  \n",
      "Train Epoch[2] Step[5361 / 19085] - loss: 11.597548  \n",
      "Train Epoch[2] Step[5381 / 19085] - loss: 6.029768  \n",
      "Train Epoch[2] Step[5401 / 19085] - loss: 10.690761  \n",
      "Train Epoch[2] Step[5421 / 19085] - loss: 9.257807  \n",
      "Train Epoch[2] Step[5441 / 19085] - loss: 10.618459  \n",
      "Train Epoch[2] Step[5461 / 19085] - loss: 8.348663  \n",
      "Train Epoch[2] Step[5481 / 19085] - loss: 14.975848  \n",
      "Train Epoch[2] Step[5501 / 19085] - loss: 19.459291  \n",
      "Train Epoch[2] Step[5521 / 19085] - loss: 11.578086  \n",
      "Train Epoch[2] Step[5541 / 19085] - loss: 10.893237  \n",
      "Train Epoch[2] Step[5561 / 19085] - loss: 13.468588  \n",
      "Train Epoch[2] Step[5581 / 19085] - loss: 6.719456  \n",
      "Train Epoch[2] Step[5601 / 19085] - loss: 5.735429  \n",
      "Train Epoch[2] Step[5621 / 19085] - loss: 11.014293  \n",
      "Train Epoch[2] Step[5641 / 19085] - loss: 7.411523  \n",
      "Train Epoch[2] Step[5661 / 19085] - loss: 5.935810  \n",
      "Train Epoch[2] Step[5681 / 19085] - loss: 13.642773  \n",
      "Train Epoch[2] Step[5701 / 19085] - loss: 9.510081  \n",
      "Train Epoch[2] Step[5721 / 19085] - loss: 5.691405  \n",
      "Train Epoch[2] Step[5741 / 19085] - loss: 11.727823  \n",
      "Train Epoch[2] Step[5761 / 19085] - loss: 9.292341  \n",
      "Train Epoch[2] Step[5781 / 19085] - loss: 10.715805  \n",
      "Train Epoch[2] Step[5801 / 19085] - loss: 6.226345  \n",
      "Train Epoch[2] Step[5821 / 19085] - loss: 13.288126  \n",
      "Train Epoch[2] Step[5841 / 19085] - loss: 10.095135  \n",
      "Train Epoch[2] Step[5861 / 19085] - loss: 9.140856  \n",
      "Train Epoch[2] Step[5881 / 19085] - loss: 6.628366  \n",
      "Train Epoch[2] Step[5901 / 19085] - loss: 11.569542  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:12<00:00, 11.03it/s]\n",
      "Dev Loss: 9.542351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6498    0.2810    0.3923     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.4933    0.3131    0.3830     22839\n",
      "           T     0.7165    0.4296    0.5372     22956\n",
      "\n",
      "   micro avg     0.6157    0.3297    0.4294     73869\n",
      "   macro avg     0.4649    0.2559    0.3281     73869\n",
      "weighted avg     0.6049    0.3297    0.4241     73869\n",
      "\n",
      "best f1: 0.42, current f1: 0.43\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[5921 / 19085] - loss: 9.415007  \n",
      "Train Epoch[2] Step[5941 / 19085] - loss: 13.587753  \n",
      "Train Epoch[2] Step[5961 / 19085] - loss: 12.448505  \n",
      "Train Epoch[2] Step[5981 / 19085] - loss: 13.744411  \n",
      "Train Epoch[2] Step[6001 / 19085] - loss: 10.980689  \n",
      "Train Epoch[2] Step[6021 / 19085] - loss: 16.558727  \n",
      "Train Epoch[2] Step[6041 / 19085] - loss: 5.633364  \n",
      "Train Epoch[2] Step[6061 / 19085] - loss: 12.829138  \n",
      "Train Epoch[2] Step[6081 / 19085] - loss: 13.863857  \n",
      "Train Epoch[2] Step[6101 / 19085] - loss: 12.776169  \n",
      "Train Epoch[2] Step[6121 / 19085] - loss: 11.378394  \n",
      "Train Epoch[2] Step[6141 / 19085] - loss: 7.091347  \n",
      "Train Epoch[2] Step[6161 / 19085] - loss: 11.744963  \n",
      "Train Epoch[2] Step[6181 / 19085] - loss: 11.559196  \n",
      "Train Epoch[2] Step[6201 / 19085] - loss: 8.841812  \n",
      "Train Epoch[2] Step[6221 / 19085] - loss: 16.769819  \n",
      "Train Epoch[2] Step[6241 / 19085] - loss: 14.092410  \n",
      "Train Epoch[2] Step[6261 / 19085] - loss: 5.996120  \n",
      "Train Epoch[2] Step[6281 / 19085] - loss: 6.250392  \n",
      "Train Epoch[2] Step[6301 / 19085] - loss: 4.766729  \n",
      "Train Epoch[2] Step[6321 / 19085] - loss: 9.396866  \n",
      "Train Epoch[2] Step[6341 / 19085] - loss: 6.502208  \n",
      "Train Epoch[2] Step[6361 / 19085] - loss: 7.034165  \n",
      "Train Epoch[2] Step[6381 / 19085] - loss: 7.153589  \n",
      "Train Epoch[2] Step[6401 / 19085] - loss: 14.679993  \n",
      "Train Epoch[2] Step[6421 / 19085] - loss: 3.303124  \n",
      "Train Epoch[2] Step[6441 / 19085] - loss: 9.191942  \n",
      "Train Epoch[2] Step[6461 / 19085] - loss: 9.470532  \n",
      "Train Epoch[2] Step[6481 / 19085] - loss: 7.829832  \n",
      "Train Epoch[2] Step[6501 / 19085] - loss: 10.364394  \n",
      "Train Epoch[2] Step[6521 / 19085] - loss: 11.531313  \n",
      "Train Epoch[2] Step[6541 / 19085] - loss: 12.184076  \n",
      "Train Epoch[2] Step[6561 / 19085] - loss: 5.577402  \n",
      "Train Epoch[2] Step[6581 / 19085] - loss: 9.087484  \n",
      "Train Epoch[2] Step[6601 / 19085] - loss: 7.972692  \n",
      "Train Epoch[2] Step[6621 / 19085] - loss: 5.057218  \n",
      "Train Epoch[2] Step[6641 / 19085] - loss: 7.485081  \n",
      "Train Epoch[2] Step[6661 / 19085] - loss: 9.789124  \n",
      "Train Epoch[2] Step[6681 / 19085] - loss: 17.774921  \n",
      "Train Epoch[2] Step[6701 / 19085] - loss: 9.143661  \n",
      "Train Epoch[2] Step[6721 / 19085] - loss: 18.076038  \n",
      "Train Epoch[2] Step[6741 / 19085] - loss: 5.853771  \n",
      "Train Epoch[2] Step[6761 / 19085] - loss: 11.625349  \n",
      "Train Epoch[2] Step[6781 / 19085] - loss: 14.201382  \n",
      "Train Epoch[2] Step[6801 / 19085] - loss: 9.610308  \n",
      "Train Epoch[2] Step[6821 / 19085] - loss: 9.712048  \n",
      "Train Epoch[2] Step[6841 / 19085] - loss: 7.361987  \n",
      "Train Epoch[2] Step[6861 / 19085] - loss: 13.402840  \n",
      "Train Epoch[2] Step[6881 / 19085] - loss: 8.812628  \n",
      "Train Epoch[2] Step[6901 / 19085] - loss: 6.689021  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:07<00:00, 11.17it/s]\n",
      "Dev Loss: 9.243398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6580    0.3246    0.4347     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.4959    0.3284    0.3951     22839\n",
      "           T     0.7264    0.4814    0.5791     22956\n",
      "\n",
      "   micro avg     0.6254    0.3659    0.4617     73869\n",
      "   macro avg     0.4701    0.2836    0.3522     73869\n",
      "weighted avg     0.6117    0.3659    0.4558     73869\n",
      "\n",
      "best f1: 0.43, current f1: 0.46\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[6921 / 19085] - loss: 7.026078  \n",
      "Train Epoch[2] Step[6941 / 19085] - loss: 4.910849  \n",
      "Train Epoch[2] Step[6961 / 19085] - loss: 5.805088  \n",
      "Train Epoch[2] Step[6981 / 19085] - loss: 12.199747  \n",
      "Train Epoch[2] Step[7001 / 19085] - loss: 10.757846  \n",
      "Train Epoch[2] Step[7021 / 19085] - loss: 11.075416  \n",
      "Train Epoch[2] Step[7041 / 19085] - loss: 7.154326  \n",
      "Train Epoch[2] Step[7061 / 19085] - loss: 19.307224  \n",
      "Train Epoch[2] Step[7081 / 19085] - loss: 9.347887  \n",
      "Train Epoch[2] Step[7101 / 19085] - loss: 11.169134  \n",
      "Train Epoch[2] Step[7121 / 19085] - loss: 7.490291  \n",
      "Train Epoch[2] Step[7141 / 19085] - loss: 4.499664  \n",
      "Train Epoch[2] Step[7161 / 19085] - loss: 15.122051  \n",
      "Train Epoch[2] Step[7181 / 19085] - loss: 6.865668  \n",
      "Train Epoch[2] Step[7201 / 19085] - loss: 12.286383  \n",
      "Train Epoch[2] Step[7221 / 19085] - loss: 12.464588  \n",
      "Train Epoch[2] Step[7241 / 19085] - loss: 10.419102  \n",
      "Train Epoch[2] Step[7261 / 19085] - loss: 5.526614  \n",
      "Train Epoch[2] Step[7281 / 19085] - loss: 13.953583  \n",
      "Train Epoch[2] Step[7301 / 19085] - loss: 7.628067  \n",
      "Train Epoch[2] Step[7321 / 19085] - loss: 11.734431  \n",
      "Train Epoch[2] Step[7341 / 19085] - loss: 10.279454  \n",
      "Train Epoch[2] Step[7361 / 19085] - loss: 11.864012  \n",
      "Train Epoch[2] Step[7381 / 19085] - loss: 9.462915  \n",
      "Train Epoch[2] Step[7401 / 19085] - loss: 3.262419  \n",
      "Train Epoch[2] Step[7421 / 19085] - loss: 4.699340  \n",
      "Train Epoch[2] Step[7441 / 19085] - loss: 5.383390  \n",
      "Train Epoch[2] Step[7461 / 19085] - loss: 5.655312  \n",
      "Train Epoch[2] Step[7481 / 19085] - loss: 8.080957  \n",
      "Train Epoch[2] Step[7501 / 19085] - loss: 9.328182  \n",
      "Train Epoch[2] Step[7521 / 19085] - loss: 8.841648  \n",
      "Train Epoch[2] Step[7541 / 19085] - loss: 11.428024  \n",
      "Train Epoch[2] Step[7561 / 19085] - loss: 6.102073  \n",
      "Train Epoch[2] Step[7581 / 19085] - loss: 3.519850  \n",
      "Train Epoch[2] Step[7601 / 19085] - loss: 8.726616  \n",
      "Train Epoch[2] Step[7621 / 19085] - loss: 7.263511  \n",
      "Train Epoch[2] Step[7641 / 19085] - loss: 6.157609  \n",
      "Train Epoch[2] Step[7661 / 19085] - loss: 11.391352  \n",
      "Train Epoch[2] Step[7681 / 19085] - loss: 4.712586  \n",
      "Train Epoch[2] Step[7701 / 19085] - loss: 9.054077  \n",
      "Train Epoch[2] Step[7721 / 19085] - loss: 5.749770  \n",
      "Train Epoch[2] Step[7741 / 19085] - loss: 14.629283  \n",
      "Train Epoch[2] Step[7761 / 19085] - loss: 6.787179  \n",
      "Train Epoch[2] Step[7781 / 19085] - loss: 8.048573  \n",
      "Train Epoch[2] Step[7801 / 19085] - loss: 10.662408  \n",
      "Train Epoch[2] Step[7821 / 19085] - loss: 8.569741  \n",
      "Train Epoch[2] Step[7841 / 19085] - loss: 4.924365  \n",
      "Train Epoch[2] Step[7861 / 19085] - loss: 13.002092  \n",
      "Train Epoch[2] Step[7881 / 19085] - loss: 8.196109  \n",
      "Train Epoch[2] Step[7901 / 19085] - loss: 8.562087  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:05<00:00, 11.21it/s]\n",
      "Dev Loss: 9.011139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6714    0.3197    0.4331     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.5200    0.3569    0.4233     22839\n",
      "           T     0.7195    0.4355    0.5426     22956\n",
      "\n",
      "   micro avg     0.6308    0.3587    0.4574     73869\n",
      "   macro avg     0.4777    0.2780    0.3498     73869\n",
      "weighted avg     0.6218    0.3587    0.4526     73869\n",
      "\n",
      "best f1: 0.46, current f1: 0.46\n",
      "\n",
      "Train Epoch[2] Step[7921 / 19085] - loss: 12.086363  \n",
      "Train Epoch[2] Step[7941 / 19085] - loss: 4.235839  \n",
      "Train Epoch[2] Step[7961 / 19085] - loss: 2.608978  \n",
      "Train Epoch[2] Step[7981 / 19085] - loss: 8.924610  \n",
      "Train Epoch[2] Step[8001 / 19085] - loss: 6.254903  \n",
      "Train Epoch[2] Step[8021 / 19085] - loss: 10.561819  \n",
      "Train Epoch[2] Step[8041 / 19085] - loss: 7.062593  \n",
      "Train Epoch[2] Step[8061 / 19085] - loss: 6.905169  \n",
      "Train Epoch[2] Step[8081 / 19085] - loss: 6.558538  \n",
      "Train Epoch[2] Step[8101 / 19085] - loss: 7.848907  \n",
      "Train Epoch[2] Step[8121 / 19085] - loss: 13.808619  \n",
      "Train Epoch[2] Step[8141 / 19085] - loss: 9.925863  \n",
      "Train Epoch[2] Step[8161 / 19085] - loss: 9.552375  \n",
      "Train Epoch[2] Step[8181 / 19085] - loss: 6.059940  \n",
      "Train Epoch[2] Step[8201 / 19085] - loss: 12.538124  \n",
      "Train Epoch[2] Step[8221 / 19085] - loss: 3.142517  \n",
      "Train Epoch[2] Step[8241 / 19085] - loss: 8.042165  \n",
      "Train Epoch[2] Step[8261 / 19085] - loss: 15.487029  \n",
      "Train Epoch[2] Step[8281 / 19085] - loss: 8.533508  \n",
      "Train Epoch[2] Step[8301 / 19085] - loss: 12.352692  \n",
      "Train Epoch[2] Step[8321 / 19085] - loss: 11.556076  \n",
      "Train Epoch[2] Step[8341 / 19085] - loss: 8.230577  \n",
      "Train Epoch[2] Step[8361 / 19085] - loss: 16.584141  \n",
      "Train Epoch[2] Step[8381 / 19085] - loss: 8.116900  \n",
      "Train Epoch[2] Step[8401 / 19085] - loss: 19.558010  \n",
      "Train Epoch[2] Step[8421 / 19085] - loss: 7.218040  \n",
      "Train Epoch[2] Step[8441 / 19085] - loss: 14.475637  \n",
      "Train Epoch[2] Step[8461 / 19085] - loss: 9.639838  \n",
      "Train Epoch[2] Step[8481 / 19085] - loss: 6.683014  \n",
      "Train Epoch[2] Step[8501 / 19085] - loss: 7.376673  \n",
      "Train Epoch[2] Step[8521 / 19085] - loss: 8.493050  \n",
      "Train Epoch[2] Step[8541 / 19085] - loss: 11.453598  \n",
      "Train Epoch[2] Step[8561 / 19085] - loss: 10.841202  \n",
      "Train Epoch[2] Step[8581 / 19085] - loss: 8.286827  \n",
      "Train Epoch[2] Step[8601 / 19085] - loss: 10.974243  \n",
      "Train Epoch[2] Step[8621 / 19085] - loss: 13.900180  \n",
      "Train Epoch[2] Step[8641 / 19085] - loss: 4.040533  \n",
      "Train Epoch[2] Step[8661 / 19085] - loss: 10.288222  \n",
      "Train Epoch[2] Step[8681 / 19085] - loss: 5.372339  \n",
      "Train Epoch[2] Step[8701 / 19085] - loss: 11.936258  \n",
      "Train Epoch[2] Step[8721 / 19085] - loss: 9.547450  \n",
      "Train Epoch[2] Step[8741 / 19085] - loss: 7.134061  \n",
      "Train Epoch[2] Step[8761 / 19085] - loss: 8.871697  \n",
      "Train Epoch[2] Step[8781 / 19085] - loss: 7.123746  \n",
      "Train Epoch[2] Step[8801 / 19085] - loss: 7.988706  \n",
      "Train Epoch[2] Step[8821 / 19085] - loss: 8.805118  \n",
      "Train Epoch[2] Step[8841 / 19085] - loss: 16.489222  \n",
      "Train Epoch[2] Step[8861 / 19085] - loss: 8.638062  \n",
      "Train Epoch[2] Step[8881 / 19085] - loss: 8.431139  \n",
      "Train Epoch[2] Step[8901 / 19085] - loss: 9.229038  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:20<00:00, 10.82it/s]\n",
      "Dev Loss: 8.738921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6773    0.3863    0.4920     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.5317    0.3709    0.4370     22839\n",
      "           T     0.7285    0.4656    0.5681     22956\n",
      "\n",
      "   micro avg     0.6428    0.3960    0.4901     73869\n",
      "   macro avg     0.4844    0.3057    0.3743     73869\n",
      "weighted avg     0.6302    0.3960    0.4856     73869\n",
      "\n",
      "best f1: 0.46, current f1: 0.49\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[8921 / 19085] - loss: 3.576932  \n",
      "Train Epoch[2] Step[8941 / 19085] - loss: 11.946831  \n",
      "Train Epoch[2] Step[8961 / 19085] - loss: 6.139873  \n",
      "Train Epoch[2] Step[8981 / 19085] - loss: 12.109320  \n",
      "Train Epoch[2] Step[9001 / 19085] - loss: 7.424169  \n",
      "Train Epoch[2] Step[9021 / 19085] - loss: 8.204424  \n",
      "Train Epoch[2] Step[9041 / 19085] - loss: 9.493158  \n",
      "Train Epoch[2] Step[9061 / 19085] - loss: 7.240791  \n",
      "Train Epoch[2] Step[9081 / 19085] - loss: 7.569527  \n",
      "Train Epoch[2] Step[9101 / 19085] - loss: 11.438993  \n",
      "Train Epoch[2] Step[9121 / 19085] - loss: 5.605488  \n",
      "Train Epoch[2] Step[9141 / 19085] - loss: 8.732088  \n",
      "Train Epoch[2] Step[9161 / 19085] - loss: 7.589216  \n",
      "Train Epoch[2] Step[9181 / 19085] - loss: 6.288866  \n",
      "Train Epoch[2] Step[9201 / 19085] - loss: 6.390297  \n",
      "Train Epoch[2] Step[9221 / 19085] - loss: 12.090101  \n",
      "Train Epoch[2] Step[9241 / 19085] - loss: 10.613304  \n",
      "Train Epoch[2] Step[9261 / 19085] - loss: 9.439072  \n",
      "Train Epoch[2] Step[9281 / 19085] - loss: 8.508465  \n",
      "Train Epoch[2] Step[9301 / 19085] - loss: 11.674449  \n",
      "Train Epoch[2] Step[9321 / 19085] - loss: 13.307442  \n",
      "Train Epoch[2] Step[9341 / 19085] - loss: 8.842859  \n",
      "Train Epoch[2] Step[9361 / 19085] - loss: 7.090555  \n",
      "Train Epoch[2] Step[9381 / 19085] - loss: 6.781127  \n",
      "Train Epoch[2] Step[9401 / 19085] - loss: 5.624390  \n",
      "Train Epoch[2] Step[9421 / 19085] - loss: 12.441199  \n",
      "Train Epoch[2] Step[9441 / 19085] - loss: 8.932585  \n",
      "Train Epoch[2] Step[9461 / 19085] - loss: 12.362521  \n",
      "Train Epoch[2] Step[9481 / 19085] - loss: 13.029944  \n",
      "Train Epoch[2] Step[9501 / 19085] - loss: 8.811810  \n",
      "Train Epoch[2] Step[9521 / 19085] - loss: 6.321157  \n",
      "Train Epoch[2] Step[9541 / 19085] - loss: 10.822291  \n",
      "Train Epoch[2] Step[9561 / 19085] - loss: 11.234329  \n",
      "Train Epoch[2] Step[9581 / 19085] - loss: 7.303404  \n",
      "Train Epoch[2] Step[9601 / 19085] - loss: 11.196132  \n",
      "Train Epoch[2] Step[9621 / 19085] - loss: 10.670913  \n",
      "Train Epoch[2] Step[9641 / 19085] - loss: 12.705515  \n",
      "Train Epoch[2] Step[9661 / 19085] - loss: 10.034400  \n",
      "Train Epoch[2] Step[9681 / 19085] - loss: 11.340145  \n",
      "Train Epoch[2] Step[9701 / 19085] - loss: 5.754577  \n",
      "Train Epoch[2] Step[9721 / 19085] - loss: 6.652215  \n",
      "Train Epoch[2] Step[9741 / 19085] - loss: 7.145406  \n",
      "Train Epoch[2] Step[9761 / 19085] - loss: 6.385080  \n",
      "Train Epoch[2] Step[9781 / 19085] - loss: 8.281240  \n",
      "Train Epoch[2] Step[9801 / 19085] - loss: 5.257431  \n",
      "Train Epoch[2] Step[9821 / 19085] - loss: 5.596981  \n",
      "Train Epoch[2] Step[9841 / 19085] - loss: 8.134781  \n",
      "Train Epoch[2] Step[9861 / 19085] - loss: 6.782402  \n",
      "Train Epoch[2] Step[9881 / 19085] - loss: 12.311218  \n",
      "Train Epoch[2] Step[9901 / 19085] - loss: 5.642920  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [07:12<00:00, 11.03it/s]\n",
      "Dev Loss: 8.570154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6825    0.3330    0.4476     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.5558    0.3745    0.4475     22839\n",
      "           T     0.7368    0.4817    0.5825     22956\n",
      "\n",
      "   micro avg     0.6562    0.3832    0.4838     73869\n",
      "   macro avg     0.4938    0.2973    0.3694     73869\n",
      "weighted avg     0.6421    0.3832    0.4776     73869\n",
      "\n",
      "best f1: 0.49, current f1: 0.48\n",
      "\n",
      "Train Epoch[2] Step[9921 / 19085] - loss: 9.490475  \n",
      "Train Epoch[2] Step[9941 / 19085] - loss: 4.379597  \n",
      "Train Epoch[2] Step[9961 / 19085] - loss: 4.843547  \n",
      "Train Epoch[2] Step[9981 / 19085] - loss: 11.288904  \n",
      "Train Epoch[2] Step[10001 / 19085] - loss: 10.321348  \n",
      "Train Epoch[2] Step[10021 / 19085] - loss: 5.553085  \n",
      "Train Epoch[2] Step[10041 / 19085] - loss: 9.112323  \n",
      "Train Epoch[2] Step[10061 / 19085] - loss: 5.147272  \n",
      "Train Epoch[2] Step[10081 / 19085] - loss: 11.228470  \n",
      "Train Epoch[2] Step[10101 / 19085] - loss: 13.842371  \n",
      "Train Epoch[2] Step[10121 / 19085] - loss: 9.461363  \n",
      "Train Epoch[2] Step[10141 / 19085] - loss: 8.802896  \n",
      "Train Epoch[2] Step[10161 / 19085] - loss: 10.758705  \n",
      "Train Epoch[2] Step[10181 / 19085] - loss: 7.673933  \n",
      "Train Epoch[2] Step[10201 / 19085] - loss: 6.492807  \n",
      "Train Epoch[2] Step[10221 / 19085] - loss: 5.812149  \n",
      "Train Epoch[2] Step[10241 / 19085] - loss: 14.094330  \n",
      "Train Epoch[2] Step[10261 / 19085] - loss: 8.364871  \n",
      "Train Epoch[2] Step[10281 / 19085] - loss: 8.783750  \n",
      "Train Epoch[2] Step[10301 / 19085] - loss: 13.145536  \n",
      "Train Epoch[2] Step[10321 / 19085] - loss: 11.969910  \n",
      "Train Epoch[2] Step[10341 / 19085] - loss: 6.692725  \n",
      "Train Epoch[2] Step[10361 / 19085] - loss: 10.912672  \n",
      "Train Epoch[2] Step[10381 / 19085] - loss: 7.358888  \n",
      "Train Epoch[2] Step[10401 / 19085] - loss: 5.636233  \n",
      "Train Epoch[2] Step[10421 / 19085] - loss: 9.190489  \n",
      "Train Epoch[2] Step[10441 / 19085] - loss: 5.411593  \n",
      "Train Epoch[2] Step[10461 / 19085] - loss: 6.519485  \n",
      "Train Epoch[2] Step[10481 / 19085] - loss: 6.545425  \n",
      "Train Epoch[2] Step[10501 / 19085] - loss: 12.488920  \n",
      "Train Epoch[2] Step[10521 / 19085] - loss: 7.839528  \n",
      "Train Epoch[2] Step[10541 / 19085] - loss: 7.150217  \n",
      "Train Epoch[2] Step[10561 / 19085] - loss: 9.587684  \n",
      "Train Epoch[2] Step[10581 / 19085] - loss: 10.553366  \n",
      "Train Epoch[2] Step[10601 / 19085] - loss: 8.687344  \n",
      "Train Epoch[2] Step[10621 / 19085] - loss: 6.748426  \n",
      "Train Epoch[2] Step[10641 / 19085] - loss: 9.843950  \n",
      "Train Epoch[2] Step[10661 / 19085] - loss: 9.990617  \n",
      "Train Epoch[2] Step[10681 / 19085] - loss: 6.092365  \n",
      "Train Epoch[2] Step[10701 / 19085] - loss: 6.613152  \n",
      "Train Epoch[2] Step[10721 / 19085] - loss: 8.323307  \n",
      "Train Epoch[2] Step[10741 / 19085] - loss: 11.516939  \n",
      "Train Epoch[2] Step[10761 / 19085] - loss: 11.058622  \n",
      "Train Epoch[2] Step[10781 / 19085] - loss: 6.864231  \n",
      "Train Epoch[2] Step[10801 / 19085] - loss: 5.494401  \n",
      "Train Epoch[2] Step[10821 / 19085] - loss: 9.106192  \n",
      "Train Epoch[2] Step[10841 / 19085] - loss: 12.787150  \n",
      "Train Epoch[2] Step[10861 / 19085] - loss: 10.734747  \n",
      "Train Epoch[2] Step[10881 / 19085] - loss: 5.591447  \n",
      "Train Epoch[2] Step[10901 / 19085] - loss: 10.642574  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:13<00:00, 12.77it/s]\n",
      "Dev Loss: 8.345714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6810    0.3741    0.4829     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.5662    0.3688    0.4466     22839\n",
      "           T     0.7441    0.5111    0.6060     22956\n",
      "\n",
      "   micro avg     0.6651    0.4051    0.5035     73869\n",
      "   macro avg     0.4978    0.3135    0.3839     73869\n",
      "weighted avg     0.6471    0.4051    0.4972     73869\n",
      "\n",
      "best f1: 0.49, current f1: 0.50\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[10921 / 19085] - loss: 5.014216  \n",
      "Train Epoch[2] Step[10941 / 19085] - loss: 5.761760  \n",
      "Train Epoch[2] Step[10961 / 19085] - loss: 9.014023  \n",
      "Train Epoch[2] Step[10981 / 19085] - loss: 4.977342  \n",
      "Train Epoch[2] Step[11001 / 19085] - loss: 7.973873  \n",
      "Train Epoch[2] Step[11021 / 19085] - loss: 12.273635  \n",
      "Train Epoch[2] Step[11041 / 19085] - loss: 10.964885  \n",
      "Train Epoch[2] Step[11061 / 19085] - loss: 8.260430  \n",
      "Train Epoch[2] Step[11081 / 19085] - loss: 8.558119  \n",
      "Train Epoch[2] Step[11101 / 19085] - loss: 5.112959  \n",
      "Train Epoch[2] Step[11121 / 19085] - loss: 7.447007  \n",
      "Train Epoch[2] Step[11141 / 19085] - loss: 9.731507  \n",
      "Train Epoch[2] Step[11161 / 19085] - loss: 10.484283  \n",
      "Train Epoch[2] Step[11181 / 19085] - loss: 12.338430  \n",
      "Train Epoch[2] Step[11201 / 19085] - loss: 9.133830  \n",
      "Train Epoch[2] Step[11221 / 19085] - loss: 6.063995  \n",
      "Train Epoch[2] Step[11241 / 19085] - loss: 4.959478  \n",
      "Train Epoch[2] Step[11261 / 19085] - loss: 10.882655  \n",
      "Train Epoch[2] Step[11281 / 19085] - loss: 6.372085  \n",
      "Train Epoch[2] Step[11301 / 19085] - loss: 7.252075  \n",
      "Train Epoch[2] Step[11321 / 19085] - loss: 7.662986  \n",
      "Train Epoch[2] Step[11341 / 19085] - loss: 12.523513  \n",
      "Train Epoch[2] Step[11361 / 19085] - loss: 5.696988  \n",
      "Train Epoch[2] Step[11381 / 19085] - loss: 5.306424  \n",
      "Train Epoch[2] Step[11401 / 19085] - loss: 11.766088  \n",
      "Train Epoch[2] Step[11421 / 19085] - loss: 7.495978  \n",
      "Train Epoch[2] Step[11441 / 19085] - loss: 5.737216  \n",
      "Train Epoch[2] Step[11461 / 19085] - loss: 6.753023  \n",
      "Train Epoch[2] Step[11481 / 19085] - loss: 5.145310  \n",
      "Train Epoch[2] Step[11501 / 19085] - loss: 12.325989  \n",
      "Train Epoch[2] Step[11521 / 19085] - loss: 7.718809  \n",
      "Train Epoch[2] Step[11541 / 19085] - loss: 12.728418  \n",
      "Train Epoch[2] Step[11561 / 19085] - loss: 4.933948  \n",
      "Train Epoch[2] Step[11581 / 19085] - loss: 9.011470  \n",
      "Train Epoch[2] Step[11601 / 19085] - loss: 11.490723  \n",
      "Train Epoch[2] Step[11621 / 19085] - loss: 4.988082  \n",
      "Train Epoch[2] Step[11641 / 19085] - loss: 4.381415  \n",
      "Train Epoch[2] Step[11661 / 19085] - loss: 8.357660  \n",
      "Train Epoch[2] Step[11681 / 19085] - loss: 10.344434  \n",
      "Train Epoch[2] Step[11701 / 19085] - loss: 13.769760  \n",
      "Train Epoch[2] Step[11721 / 19085] - loss: 10.825695  \n",
      "Train Epoch[2] Step[11741 / 19085] - loss: 6.133317  \n",
      "Train Epoch[2] Step[11761 / 19085] - loss: 10.054645  \n",
      "Train Epoch[2] Step[11781 / 19085] - loss: 4.933930  \n",
      "Train Epoch[2] Step[11801 / 19085] - loss: 5.008462  \n",
      "Train Epoch[2] Step[11821 / 19085] - loss: 8.232857  \n",
      "Train Epoch[2] Step[11841 / 19085] - loss: 8.658415  \n",
      "Train Epoch[2] Step[11861 / 19085] - loss: 9.381962  \n",
      "Train Epoch[2] Step[11881 / 19085] - loss: 4.196187  \n",
      "Train Epoch[2] Step[11901 / 19085] - loss: 7.416769  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:09<00:00, 12.91it/s]\n",
      "Dev Loss: 8.178599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6897    0.3471    0.4618     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.5734    0.3975    0.4695     22839\n",
      "           T     0.7512    0.5085    0.6065     22956\n",
      "\n",
      "   micro avg     0.6697    0.4036    0.5037     73869\n",
      "   macro avg     0.5036    0.3133    0.3844     73869\n",
      "weighted avg     0.6546    0.4036    0.4969     73869\n",
      "\n",
      "best f1: 0.50, current f1: 0.50\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[11921 / 19085] - loss: 10.019042  \n",
      "Train Epoch[2] Step[11941 / 19085] - loss: 5.544628  \n",
      "Train Epoch[2] Step[11961 / 19085] - loss: 8.462745  \n",
      "Train Epoch[2] Step[11981 / 19085] - loss: 6.437053  \n",
      "Train Epoch[2] Step[12001 / 19085] - loss: 7.620126  \n",
      "Train Epoch[2] Step[12021 / 19085] - loss: 13.204983  \n",
      "Train Epoch[2] Step[12041 / 19085] - loss: 8.459918  \n",
      "Train Epoch[2] Step[12061 / 19085] - loss: 7.142772  \n",
      "Train Epoch[2] Step[12081 / 19085] - loss: 6.438515  \n",
      "Train Epoch[2] Step[12101 / 19085] - loss: 10.331907  \n",
      "Train Epoch[2] Step[12121 / 19085] - loss: 4.744714  \n",
      "Train Epoch[2] Step[12141 / 19085] - loss: 9.366877  \n",
      "Train Epoch[2] Step[12161 / 19085] - loss: 13.481764  \n",
      "Train Epoch[2] Step[12181 / 19085] - loss: 10.592387  \n",
      "Train Epoch[2] Step[12201 / 19085] - loss: 11.344618  \n",
      "Train Epoch[2] Step[12221 / 19085] - loss: 5.233639  \n",
      "Train Epoch[2] Step[12241 / 19085] - loss: 7.237852  \n",
      "Train Epoch[2] Step[12261 / 19085] - loss: 9.886574  \n",
      "Train Epoch[2] Step[12281 / 19085] - loss: 7.735174  \n",
      "Train Epoch[2] Step[12301 / 19085] - loss: 6.769144  \n",
      "Train Epoch[2] Step[12321 / 19085] - loss: 4.646420  \n",
      "Train Epoch[2] Step[12341 / 19085] - loss: 5.266188  \n",
      "Train Epoch[2] Step[12361 / 19085] - loss: 8.765935  \n",
      "Train Epoch[2] Step[12381 / 19085] - loss: 9.424781  \n",
      "Train Epoch[2] Step[12401 / 19085] - loss: 4.696970  \n",
      "Train Epoch[2] Step[12421 / 19085] - loss: 12.222784  \n",
      "Train Epoch[2] Step[12441 / 19085] - loss: 6.314312  \n",
      "Train Epoch[2] Step[12461 / 19085] - loss: 9.832283  \n",
      "Train Epoch[2] Step[12481 / 19085] - loss: 5.877860  \n",
      "Train Epoch[2] Step[12501 / 19085] - loss: 8.227256  \n",
      "Train Epoch[2] Step[12521 / 19085] - loss: 15.302466  \n",
      "Train Epoch[2] Step[12541 / 19085] - loss: 7.774351  \n",
      "Train Epoch[2] Step[12561 / 19085] - loss: 5.287261  \n",
      "Train Epoch[2] Step[12581 / 19085] - loss: 10.950550  \n",
      "Train Epoch[2] Step[12601 / 19085] - loss: 5.108874  \n",
      "Train Epoch[2] Step[12621 / 19085] - loss: 7.947528  \n",
      "Train Epoch[2] Step[12641 / 19085] - loss: 7.593334  \n",
      "Train Epoch[2] Step[12661 / 19085] - loss: 6.016088  \n",
      "Train Epoch[2] Step[12681 / 19085] - loss: 9.435694  \n",
      "Train Epoch[2] Step[12701 / 19085] - loss: 8.272251  \n",
      "Train Epoch[2] Step[12721 / 19085] - loss: 7.104000  \n",
      "Train Epoch[2] Step[12741 / 19085] - loss: 9.619608  \n",
      "Train Epoch[2] Step[12761 / 19085] - loss: 8.504051  \n",
      "Train Epoch[2] Step[12781 / 19085] - loss: 5.004586  \n",
      "Train Epoch[2] Step[12801 / 19085] - loss: 6.161972  \n",
      "Train Epoch[2] Step[12821 / 19085] - loss: 9.871296  \n",
      "Train Epoch[2] Step[12841 / 19085] - loss: 12.757864  \n",
      "Train Epoch[2] Step[12861 / 19085] - loss: 10.862559  \n",
      "Train Epoch[2] Step[12881 / 19085] - loss: 5.188483  \n",
      "Train Epoch[2] Step[12901 / 19085] - loss: 7.794794  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:53<00:00, 13.48it/s]\n",
      "Dev Loss: 7.953270\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6869    0.4012    0.5065     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.5861    0.4120    0.4839     22839\n",
      "           T     0.7485    0.5078    0.6051     22956\n",
      "\n",
      "   micro avg     0.6727    0.4270    0.5224     73869\n",
      "   macro avg     0.5054    0.3302    0.3989     73869\n",
      "weighted avg     0.6567    0.4270    0.5167     73869\n",
      "\n",
      "best f1: 0.50, current f1: 0.52\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[12921 / 19085] - loss: 7.481399  \n",
      "Train Epoch[2] Step[12941 / 19085] - loss: 9.706530  \n",
      "Train Epoch[2] Step[12961 / 19085] - loss: 11.763981  \n",
      "Train Epoch[2] Step[12981 / 19085] - loss: 7.347137  \n",
      "Train Epoch[2] Step[13001 / 19085] - loss: 7.625967  \n",
      "Train Epoch[2] Step[13021 / 19085] - loss: 9.211708  \n",
      "Train Epoch[2] Step[13041 / 19085] - loss: 12.987803  \n",
      "Train Epoch[2] Step[13061 / 19085] - loss: 6.170670  \n",
      "Train Epoch[2] Step[13081 / 19085] - loss: 9.613360  \n",
      "Train Epoch[2] Step[13101 / 19085] - loss: 7.575887  \n",
      "Train Epoch[2] Step[13121 / 19085] - loss: 7.889248  \n",
      "Train Epoch[2] Step[13141 / 19085] - loss: 12.859271  \n",
      "Train Epoch[2] Step[13161 / 19085] - loss: 8.974604  \n",
      "Train Epoch[2] Step[13181 / 19085] - loss: 5.818357  \n",
      "Train Epoch[2] Step[13201 / 19085] - loss: 7.603635  \n",
      "Train Epoch[2] Step[13221 / 19085] - loss: 8.841307  \n",
      "Train Epoch[2] Step[13241 / 19085] - loss: 9.590260  \n",
      "Train Epoch[2] Step[13261 / 19085] - loss: 3.536180  \n",
      "Train Epoch[2] Step[13281 / 19085] - loss: 3.617116  \n",
      "Train Epoch[2] Step[13301 / 19085] - loss: 10.739783  \n",
      "Train Epoch[2] Step[13321 / 19085] - loss: 8.820789  \n",
      "Train Epoch[2] Step[13341 / 19085] - loss: 10.278410  \n",
      "Train Epoch[2] Step[13361 / 19085] - loss: 9.107313  \n",
      "Train Epoch[2] Step[13381 / 19085] - loss: 7.079427  \n",
      "Train Epoch[2] Step[13401 / 19085] - loss: 7.312355  \n",
      "Train Epoch[2] Step[13421 / 19085] - loss: 8.149624  \n",
      "Train Epoch[2] Step[13441 / 19085] - loss: 14.475135  \n",
      "Train Epoch[2] Step[13461 / 19085] - loss: 8.113384  \n",
      "Train Epoch[2] Step[13481 / 19085] - loss: 5.696658  \n",
      "Train Epoch[2] Step[13501 / 19085] - loss: 7.668017  \n",
      "Train Epoch[2] Step[13521 / 19085] - loss: 4.177037  \n",
      "Train Epoch[2] Step[13541 / 19085] - loss: 10.658915  \n",
      "Train Epoch[2] Step[13561 / 19085] - loss: 14.962371  \n",
      "Train Epoch[2] Step[13581 / 19085] - loss: 6.604147  \n",
      "Train Epoch[2] Step[13601 / 19085] - loss: 5.567144  \n",
      "Train Epoch[2] Step[13621 / 19085] - loss: 6.429877  \n",
      "Train Epoch[2] Step[13641 / 19085] - loss: 4.472438  \n",
      "Train Epoch[2] Step[13661 / 19085] - loss: 7.624664  \n",
      "Train Epoch[2] Step[13681 / 19085] - loss: 5.010878  \n",
      "Train Epoch[2] Step[13701 / 19085] - loss: 8.429078  \n",
      "Train Epoch[2] Step[13721 / 19085] - loss: 9.893148  \n",
      "Train Epoch[2] Step[13741 / 19085] - loss: 8.909505  \n",
      "Train Epoch[2] Step[13761 / 19085] - loss: 9.804935  \n",
      "Train Epoch[2] Step[13781 / 19085] - loss: 5.140539  \n",
      "Train Epoch[2] Step[13801 / 19085] - loss: 4.946470  \n",
      "Train Epoch[2] Step[13821 / 19085] - loss: 5.809328  \n",
      "Train Epoch[2] Step[13841 / 19085] - loss: 8.293278  \n",
      "Train Epoch[2] Step[13861 / 19085] - loss: 5.290866  \n",
      "Train Epoch[2] Step[13881 / 19085] - loss: 6.105796  \n",
      "Train Epoch[2] Step[13901 / 19085] - loss: 7.342807  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:02<00:00, 13.16it/s]\n",
      "Dev Loss: 7.761334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6906    0.3786    0.4890     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.5990    0.4471    0.5120     22839\n",
      "           T     0.7566    0.5351    0.6269     22956\n",
      "\n",
      "   micro avg     0.6801    0.4384    0.5331     73869\n",
      "   macro avg     0.5115    0.3402    0.4070     73869\n",
      "weighted avg     0.6645    0.4384    0.5260     73869\n",
      "\n",
      "best f1: 0.52, current f1: 0.53\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[13921 / 19085] - loss: 8.666336  \n",
      "Train Epoch[2] Step[13941 / 19085] - loss: 6.750066  \n",
      "Train Epoch[2] Step[13961 / 19085] - loss: 10.071759  \n",
      "Train Epoch[2] Step[13981 / 19085] - loss: 10.768672  \n",
      "Train Epoch[2] Step[14001 / 19085] - loss: 6.094385  \n",
      "Train Epoch[2] Step[14021 / 19085] - loss: 13.467792  \n",
      "Train Epoch[2] Step[14041 / 19085] - loss: 7.099196  \n",
      "Train Epoch[2] Step[14061 / 19085] - loss: 6.658319  \n",
      "Train Epoch[2] Step[14081 / 19085] - loss: 9.104918  \n",
      "Train Epoch[2] Step[14101 / 19085] - loss: 3.977346  \n",
      "Train Epoch[2] Step[14121 / 19085] - loss: 7.161672  \n",
      "Train Epoch[2] Step[14141 / 19085] - loss: 4.209250  \n",
      "Train Epoch[2] Step[14161 / 19085] - loss: 6.535058  \n",
      "Train Epoch[2] Step[14181 / 19085] - loss: 6.236807  \n",
      "Train Epoch[2] Step[14201 / 19085] - loss: 13.705217  \n",
      "Train Epoch[2] Step[14221 / 19085] - loss: 10.119962  \n",
      "Train Epoch[2] Step[14241 / 19085] - loss: 7.441959  \n",
      "Train Epoch[2] Step[14261 / 19085] - loss: 6.466821  \n",
      "Train Epoch[2] Step[14281 / 19085] - loss: 6.571624  \n",
      "Train Epoch[2] Step[14301 / 19085] - loss: 10.485035  \n",
      "Train Epoch[2] Step[14321 / 19085] - loss: 10.258106  \n",
      "Train Epoch[2] Step[14341 / 19085] - loss: 5.829976  \n",
      "Train Epoch[2] Step[14361 / 19085] - loss: 5.478376  \n",
      "Train Epoch[2] Step[14381 / 19085] - loss: 6.729482  \n",
      "Train Epoch[2] Step[14401 / 19085] - loss: 9.540775  \n",
      "Train Epoch[2] Step[14421 / 19085] - loss: 5.678218  \n",
      "Train Epoch[2] Step[14441 / 19085] - loss: 9.294628  \n",
      "Train Epoch[2] Step[14461 / 19085] - loss: 5.545129  \n",
      "Train Epoch[2] Step[14481 / 19085] - loss: 4.841465  \n",
      "Train Epoch[2] Step[14501 / 19085] - loss: 9.381644  \n",
      "Train Epoch[2] Step[14521 / 19085] - loss: 3.773907  \n",
      "Train Epoch[2] Step[14541 / 19085] - loss: 11.453270  \n",
      "Train Epoch[2] Step[14561 / 19085] - loss: 8.171569  \n",
      "Train Epoch[2] Step[14581 / 19085] - loss: 9.986308  \n",
      "Train Epoch[2] Step[14601 / 19085] - loss: 3.826085  \n",
      "Train Epoch[2] Step[14621 / 19085] - loss: 9.357931  \n",
      "Train Epoch[2] Step[14641 / 19085] - loss: 8.765558  \n",
      "Train Epoch[2] Step[14661 / 19085] - loss: 3.995156  \n",
      "Train Epoch[2] Step[14681 / 19085] - loss: 13.749371  \n",
      "Train Epoch[2] Step[14701 / 19085] - loss: 12.745789  \n",
      "Train Epoch[2] Step[14721 / 19085] - loss: 8.367208  \n",
      "Train Epoch[2] Step[14741 / 19085] - loss: 3.957745  \n",
      "Train Epoch[2] Step[14761 / 19085] - loss: 6.250668  \n",
      "Train Epoch[2] Step[14781 / 19085] - loss: 7.932986  \n",
      "Train Epoch[2] Step[14801 / 19085] - loss: 8.340040  \n",
      "Train Epoch[2] Step[14821 / 19085] - loss: 13.062691  \n",
      "Train Epoch[2] Step[14841 / 19085] - loss: 8.841860  \n",
      "Train Epoch[2] Step[14861 / 19085] - loss: 5.685140  \n",
      "Train Epoch[2] Step[14881 / 19085] - loss: 12.519096  \n",
      "Train Epoch[2] Step[14901 / 19085] - loss: 5.384370  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:42<00:00, 13.92it/s]\n",
      "Dev Loss: 7.664059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6874    0.3801    0.4895     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.6053    0.4067    0.4865     22839\n",
      "           T     0.7655    0.5349    0.6298     22956\n",
      "\n",
      "   micro avg     0.6871    0.4264    0.5262     73869\n",
      "   macro avg     0.5145    0.3304    0.4015     73869\n",
      "weighted avg     0.6681    0.4264    0.5192     73869\n",
      "\n",
      "best f1: 0.53, current f1: 0.53\n",
      "\n",
      "Train Epoch[2] Step[14921 / 19085] - loss: 11.279959  \n",
      "Train Epoch[2] Step[14941 / 19085] - loss: 7.060948  \n",
      "Train Epoch[2] Step[14961 / 19085] - loss: 5.641687  \n",
      "Train Epoch[2] Step[14981 / 19085] - loss: 3.460826  \n",
      "Train Epoch[2] Step[15001 / 19085] - loss: 8.648535  \n",
      "Train Epoch[2] Step[15021 / 19085] - loss: 4.635489  \n",
      "Train Epoch[2] Step[15041 / 19085] - loss: 5.372240  \n",
      "Train Epoch[2] Step[15061 / 19085] - loss: 16.547482  \n",
      "Train Epoch[2] Step[15081 / 19085] - loss: 5.157235  \n",
      "Train Epoch[2] Step[15101 / 19085] - loss: 10.218596  \n",
      "Train Epoch[2] Step[15121 / 19085] - loss: 4.854514  \n",
      "Train Epoch[2] Step[15141 / 19085] - loss: 6.984160  \n",
      "Train Epoch[2] Step[15161 / 19085] - loss: 8.566774  \n",
      "Train Epoch[2] Step[15181 / 19085] - loss: 5.705427  \n",
      "Train Epoch[2] Step[15201 / 19085] - loss: 2.721278  \n",
      "Train Epoch[2] Step[15221 / 19085] - loss: 6.677907  \n",
      "Train Epoch[2] Step[15241 / 19085] - loss: 6.588609  \n",
      "Train Epoch[2] Step[15261 / 19085] - loss: 6.812130  \n",
      "Train Epoch[2] Step[15281 / 19085] - loss: 7.031322  \n",
      "Train Epoch[2] Step[15301 / 19085] - loss: 12.954084  \n",
      "Train Epoch[2] Step[15321 / 19085] - loss: 5.913265  \n",
      "Train Epoch[2] Step[15341 / 19085] - loss: 6.946332  \n",
      "Train Epoch[2] Step[15361 / 19085] - loss: 6.177699  \n",
      "Train Epoch[2] Step[15381 / 19085] - loss: 6.755346  \n",
      "Train Epoch[2] Step[15401 / 19085] - loss: 6.754217  \n",
      "Train Epoch[2] Step[15421 / 19085] - loss: 11.704291  \n",
      "Train Epoch[2] Step[15441 / 19085] - loss: 10.646682  \n",
      "Train Epoch[2] Step[15461 / 19085] - loss: 11.218982  \n",
      "Train Epoch[2] Step[15481 / 19085] - loss: 7.980246  \n",
      "Train Epoch[2] Step[15501 / 19085] - loss: 6.332958  \n",
      "Train Epoch[2] Step[15521 / 19085] - loss: 6.335529  \n",
      "Train Epoch[2] Step[15541 / 19085] - loss: 8.775900  \n",
      "Train Epoch[2] Step[15561 / 19085] - loss: 9.720416  \n",
      "Train Epoch[2] Step[15581 / 19085] - loss: 5.755853  \n",
      "Train Epoch[2] Step[15601 / 19085] - loss: 7.785740  \n",
      "Train Epoch[2] Step[15621 / 19085] - loss: 4.159254  \n",
      "Train Epoch[2] Step[15641 / 19085] - loss: 4.799629  \n",
      "Train Epoch[2] Step[15661 / 19085] - loss: 12.656246  \n",
      "Train Epoch[2] Step[15681 / 19085] - loss: 5.826992  \n",
      "Train Epoch[2] Step[15701 / 19085] - loss: 7.332078  \n",
      "Train Epoch[2] Step[15721 / 19085] - loss: 5.585655  \n",
      "Train Epoch[2] Step[15741 / 19085] - loss: 8.178975  \n",
      "Train Epoch[2] Step[15761 / 19085] - loss: 6.630479  \n",
      "Train Epoch[2] Step[15781 / 19085] - loss: 8.019238  \n",
      "Train Epoch[2] Step[15801 / 19085] - loss: 9.178173  \n",
      "Train Epoch[2] Step[15821 / 19085] - loss: 3.839473  \n",
      "Train Epoch[2] Step[15841 / 19085] - loss: 7.548110  \n",
      "Train Epoch[2] Step[15861 / 19085] - loss: 8.346934  \n",
      "Train Epoch[2] Step[15881 / 19085] - loss: 5.132822  \n",
      "Train Epoch[2] Step[15901 / 19085] - loss: 6.359848  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:30<00:00, 14.42it/s]\n",
      "Dev Loss: 7.496817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7007    0.3993    0.5087     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.6157    0.4397    0.5130     22839\n",
      "           T     0.7659    0.5263    0.6239     22956\n",
      "\n",
      "   micro avg     0.6929    0.4407    0.5387     73869\n",
      "   macro avg     0.5206    0.3413    0.4114     73869\n",
      "weighted avg     0.6761    0.4407    0.5323     73869\n",
      "\n",
      "best f1: 0.53, current f1: 0.54\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[15921 / 19085] - loss: 8.734253  \n",
      "Train Epoch[2] Step[15941 / 19085] - loss: 8.244869  \n",
      "Train Epoch[2] Step[15961 / 19085] - loss: 6.261799  \n",
      "Train Epoch[2] Step[15981 / 19085] - loss: 7.957199  \n",
      "Train Epoch[2] Step[16001 / 19085] - loss: 11.877556  \n",
      "Train Epoch[2] Step[16021 / 19085] - loss: 9.110198  \n",
      "Train Epoch[2] Step[16041 / 19085] - loss: 4.069055  \n",
      "Train Epoch[2] Step[16061 / 19085] - loss: 6.696041  \n",
      "Train Epoch[2] Step[16081 / 19085] - loss: 8.073959  \n",
      "Train Epoch[2] Step[16101 / 19085] - loss: 6.971048  \n",
      "Train Epoch[2] Step[16121 / 19085] - loss: 7.926211  \n",
      "Train Epoch[2] Step[16141 / 19085] - loss: 5.910937  \n",
      "Train Epoch[2] Step[16161 / 19085] - loss: 7.473428  \n",
      "Train Epoch[2] Step[16181 / 19085] - loss: 5.597122  \n",
      "Train Epoch[2] Step[16201 / 19085] - loss: 5.982633  \n",
      "Train Epoch[2] Step[16221 / 19085] - loss: 4.450391  \n",
      "Train Epoch[2] Step[16241 / 19085] - loss: 9.055646  \n",
      "Train Epoch[2] Step[16261 / 19085] - loss: 7.051338  \n",
      "Train Epoch[2] Step[16281 / 19085] - loss: 4.671095  \n",
      "Train Epoch[2] Step[16301 / 19085] - loss: 7.593071  \n",
      "Train Epoch[2] Step[16321 / 19085] - loss: 8.064896  \n",
      "Train Epoch[2] Step[16341 / 19085] - loss: 7.171983  \n",
      "Train Epoch[2] Step[16361 / 19085] - loss: 4.291221  \n",
      "Train Epoch[2] Step[16381 / 19085] - loss: 3.312753  \n",
      "Train Epoch[2] Step[16401 / 19085] - loss: 10.836826  \n",
      "Train Epoch[2] Step[16421 / 19085] - loss: 4.315833  \n",
      "Train Epoch[2] Step[16441 / 19085] - loss: 5.338260  \n",
      "Train Epoch[2] Step[16461 / 19085] - loss: 7.755852  \n",
      "Train Epoch[2] Step[16481 / 19085] - loss: 7.489421  \n",
      "Train Epoch[2] Step[16501 / 19085] - loss: 10.483919  \n",
      "Train Epoch[2] Step[16521 / 19085] - loss: 8.522303  \n",
      "Train Epoch[2] Step[16541 / 19085] - loss: 5.006198  \n",
      "Train Epoch[2] Step[16561 / 19085] - loss: 4.910507  \n",
      "Train Epoch[2] Step[16581 / 19085] - loss: 6.519605  \n",
      "Train Epoch[2] Step[16601 / 19085] - loss: 3.907182  \n",
      "Train Epoch[2] Step[16621 / 19085] - loss: 8.553784  \n",
      "Train Epoch[2] Step[16641 / 19085] - loss: 7.637281  \n",
      "Train Epoch[2] Step[16661 / 19085] - loss: 7.982810  \n",
      "Train Epoch[2] Step[16681 / 19085] - loss: 7.374151  \n",
      "Train Epoch[2] Step[16701 / 19085] - loss: 9.982288  \n",
      "Train Epoch[2] Step[16721 / 19085] - loss: 4.119965  \n",
      "Train Epoch[2] Step[16741 / 19085] - loss: 5.827087  \n",
      "Train Epoch[2] Step[16761 / 19085] - loss: 9.786325  \n",
      "Train Epoch[2] Step[16781 / 19085] - loss: 7.186418  \n",
      "Train Epoch[2] Step[16801 / 19085] - loss: 6.315593  \n",
      "Train Epoch[2] Step[16821 / 19085] - loss: 6.646820  \n",
      "Train Epoch[2] Step[16841 / 19085] - loss: 6.439312  \n",
      "Train Epoch[2] Step[16861 / 19085] - loss: 4.823661  \n",
      "Train Epoch[2] Step[16881 / 19085] - loss: 13.534758  \n",
      "Train Epoch[2] Step[16901 / 19085] - loss: 7.763011  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:34<00:00, 14.25it/s]\n",
      "Dev Loss: 7.371737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.6979    0.4043    0.5120     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.6145    0.4293    0.5055     22839\n",
      "           T     0.7703    0.5478    0.6403     22956\n",
      "\n",
      "   micro avg     0.6946    0.4459    0.5431     73869\n",
      "   macro avg     0.5207    0.3453    0.4144     73869\n",
      "weighted avg     0.6762    0.4459    0.5363     73869\n",
      "\n",
      "best f1: 0.54, current f1: 0.54\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[16921 / 19085] - loss: 4.769804  \n",
      "Train Epoch[2] Step[16941 / 19085] - loss: 7.720899  \n",
      "Train Epoch[2] Step[16961 / 19085] - loss: 4.828377  \n",
      "Train Epoch[2] Step[16981 / 19085] - loss: 6.676874  \n",
      "Train Epoch[2] Step[17001 / 19085] - loss: 5.976811  \n",
      "Train Epoch[2] Step[17021 / 19085] - loss: 7.982974  \n",
      "Train Epoch[2] Step[17041 / 19085] - loss: 6.527735  \n",
      "Train Epoch[2] Step[17061 / 19085] - loss: 6.487109  \n",
      "Train Epoch[2] Step[17081 / 19085] - loss: 7.075745  \n",
      "Train Epoch[2] Step[17101 / 19085] - loss: 9.188193  \n",
      "Train Epoch[2] Step[17121 / 19085] - loss: 6.924664  \n",
      "Train Epoch[2] Step[17141 / 19085] - loss: 13.751369  \n",
      "Train Epoch[2] Step[17161 / 19085] - loss: 3.320629  \n",
      "Train Epoch[2] Step[17181 / 19085] - loss: 6.748659  \n",
      "Train Epoch[2] Step[17201 / 19085] - loss: 5.192290  \n",
      "Train Epoch[2] Step[17221 / 19085] - loss: 7.118886  \n",
      "Train Epoch[2] Step[17241 / 19085] - loss: 7.363705  \n",
      "Train Epoch[2] Step[17261 / 19085] - loss: 5.911785  \n",
      "Train Epoch[2] Step[17281 / 19085] - loss: 5.426089  \n",
      "Train Epoch[2] Step[17301 / 19085] - loss: 7.424754  \n",
      "Train Epoch[2] Step[17321 / 19085] - loss: 10.872761  \n",
      "Train Epoch[2] Step[17341 / 19085] - loss: 9.135143  \n",
      "Train Epoch[2] Step[17361 / 19085] - loss: 10.898234  \n",
      "Train Epoch[2] Step[17381 / 19085] - loss: 7.015112  \n",
      "Train Epoch[2] Step[17401 / 19085] - loss: 9.292401  \n",
      "Train Epoch[2] Step[17421 / 19085] - loss: 9.021006  \n",
      "Train Epoch[2] Step[17441 / 19085] - loss: 5.394427  \n",
      "Train Epoch[2] Step[17461 / 19085] - loss: 4.049069  \n",
      "Train Epoch[2] Step[17481 / 19085] - loss: 7.141513  \n",
      "Train Epoch[2] Step[17501 / 19085] - loss: 2.330457  \n",
      "Train Epoch[2] Step[17521 / 19085] - loss: 13.477118  \n",
      "Train Epoch[2] Step[17541 / 19085] - loss: 6.345469  \n",
      "Train Epoch[2] Step[17561 / 19085] - loss: 5.802725  \n",
      "Train Epoch[2] Step[17581 / 19085] - loss: 8.070720  \n",
      "Train Epoch[2] Step[17601 / 19085] - loss: 5.843233  \n",
      "Train Epoch[2] Step[17621 / 19085] - loss: 5.580813  \n",
      "Train Epoch[2] Step[17641 / 19085] - loss: 6.067474  \n",
      "Train Epoch[2] Step[17661 / 19085] - loss: 7.611360  \n",
      "Train Epoch[2] Step[17681 / 19085] - loss: 10.504152  \n",
      "Train Epoch[2] Step[17701 / 19085] - loss: 5.652602  \n",
      "Train Epoch[2] Step[17721 / 19085] - loss: 10.883163  \n",
      "Train Epoch[2] Step[17741 / 19085] - loss: 11.921054  \n",
      "Train Epoch[2] Step[17761 / 19085] - loss: 3.972266  \n",
      "Train Epoch[2] Step[17781 / 19085] - loss: 5.323275  \n",
      "Train Epoch[2] Step[17801 / 19085] - loss: 3.944316  \n",
      "Train Epoch[2] Step[17821 / 19085] - loss: 6.321249  \n",
      "Train Epoch[2] Step[17841 / 19085] - loss: 5.286741  \n",
      "Train Epoch[2] Step[17861 / 19085] - loss: 5.243164  \n",
      "Train Epoch[2] Step[17881 / 19085] - loss: 5.121383  \n",
      "Train Epoch[2] Step[17901 / 19085] - loss: 8.528663  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:39<00:00, 14.07it/s]\n",
      "Dev Loss: 7.178372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7056    0.4916    0.5795     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.6253    0.4574    0.5283     22839\n",
      "           T     0.7729    0.5447    0.6391     22956\n",
      "\n",
      "   micro avg     0.7005    0.4845    0.5728     73869\n",
      "   macro avg     0.5260    0.3734    0.4367     73869\n",
      "weighted avg     0.6830    0.4845    0.5668     73869\n",
      "\n",
      "best f1: 0.54, current f1: 0.57\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[2] Step[17921 / 19085] - loss: 5.562768  \n",
      "Train Epoch[2] Step[17941 / 19085] - loss: 3.351394  \n",
      "Train Epoch[2] Step[17961 / 19085] - loss: 6.265943  \n",
      "Train Epoch[2] Step[17981 / 19085] - loss: 6.296130  \n",
      "Train Epoch[2] Step[18001 / 19085] - loss: 9.908472  \n",
      "Train Epoch[2] Step[18021 / 19085] - loss: 11.088308  \n",
      "Train Epoch[2] Step[18041 / 19085] - loss: 4.893962  \n",
      "Train Epoch[2] Step[18061 / 19085] - loss: 7.791292  \n",
      "Train Epoch[2] Step[18081 / 19085] - loss: 9.021746  \n",
      "Train Epoch[2] Step[18101 / 19085] - loss: 9.847490  \n",
      "Train Epoch[2] Step[18121 / 19085] - loss: 6.827236  \n",
      "Train Epoch[2] Step[18141 / 19085] - loss: 7.923020  \n",
      "Train Epoch[2] Step[18161 / 19085] - loss: 6.297065  \n",
      "Train Epoch[2] Step[18181 / 19085] - loss: 2.944425  \n",
      "Train Epoch[2] Step[18201 / 19085] - loss: 4.580117  \n",
      "Train Epoch[2] Step[18221 / 19085] - loss: 10.610404  \n",
      "Train Epoch[2] Step[18241 / 19085] - loss: 7.136355  \n",
      "Train Epoch[2] Step[18261 / 19085] - loss: 6.962560  \n",
      "Train Epoch[2] Step[18281 / 19085] - loss: 10.647017  \n",
      "Train Epoch[2] Step[18301 / 19085] - loss: 3.406466  \n",
      "Train Epoch[2] Step[18321 / 19085] - loss: 6.959538  \n",
      "Train Epoch[2] Step[18341 / 19085] - loss: 10.282742  \n",
      "Train Epoch[2] Step[18361 / 19085] - loss: 9.714048  \n",
      "Train Epoch[2] Step[18381 / 19085] - loss: 11.770704  \n",
      "Train Epoch[2] Step[18401 / 19085] - loss: 3.470464  \n",
      "Train Epoch[2] Step[18421 / 19085] - loss: 5.262320  \n",
      "Train Epoch[2] Step[18441 / 19085] - loss: 4.158111  \n",
      "Train Epoch[2] Step[18461 / 19085] - loss: 7.122066  \n",
      "Train Epoch[2] Step[18481 / 19085] - loss: 5.714939  \n",
      "Train Epoch[2] Step[18501 / 19085] - loss: 4.960871  \n",
      "Train Epoch[2] Step[18521 / 19085] - loss: 9.112247  \n",
      "Train Epoch[2] Step[18541 / 19085] - loss: 11.003833  \n",
      "Train Epoch[2] Step[18561 / 19085] - loss: 7.238149  \n",
      "Train Epoch[2] Step[18581 / 19085] - loss: 5.143599  \n",
      "Train Epoch[2] Step[18601 / 19085] - loss: 7.933482  \n",
      "Train Epoch[2] Step[18621 / 19085] - loss: 5.046688  \n",
      "Train Epoch[2] Step[18641 / 19085] - loss: 5.084372  \n",
      "Train Epoch[2] Step[18661 / 19085] - loss: 7.694553  \n",
      "Train Epoch[2] Step[18681 / 19085] - loss: 5.592990  \n",
      "Train Epoch[2] Step[18701 / 19085] - loss: 4.802450  \n",
      "Train Epoch[2] Step[18721 / 19085] - loss: 4.363463  \n",
      "Train Epoch[2] Step[18741 / 19085] - loss: 13.778358  \n",
      "Train Epoch[2] Step[18761 / 19085] - loss: 6.436488  \n",
      "Train Epoch[2] Step[18781 / 19085] - loss: 10.618744  \n",
      "Train Epoch[2] Step[18801 / 19085] - loss: 7.044230  \n",
      "Train Epoch[2] Step[18821 / 19085] - loss: 8.550128  \n",
      "Train Epoch[2] Step[18841 / 19085] - loss: 9.078891  \n",
      "Train Epoch[2] Step[18861 / 19085] - loss: 7.314495  \n",
      "Train Epoch[2] Step[18881 / 19085] - loss: 5.564017  \n",
      "Train Epoch[2] Step[18901 / 19085] - loss: 9.473874  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:32<00:00, 14.35it/s]\n",
      "Dev Loss: 7.110743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7027    0.4734    0.5657     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.6324    0.4479    0.5244     22839\n",
      "           T     0.7704    0.5046    0.6098     22956\n",
      "\n",
      "   micro avg     0.7001    0.4627    0.5571     73869\n",
      "   macro avg     0.5264    0.3565    0.4250     73869\n",
      "weighted avg     0.6834    0.4627    0.5517     73869\n",
      "\n",
      "best f1: 0.57, current f1: 0.56\n",
      "\n",
      "Train Epoch[2] Step[18921 / 19085] - loss: 7.099830  \n",
      "Train Epoch[2] Step[18941 / 19085] - loss: 7.870142  \n",
      "Train Epoch[2] Step[18961 / 19085] - loss: 6.081495  \n",
      "Train Epoch[2] Step[18981 / 19085] - loss: 5.557043  \n",
      "Train Epoch[2] Step[19001 / 19085] - loss: 5.789339  \n",
      "Train Epoch[2] Step[19021 / 19085] - loss: 4.310308  \n",
      "Train Epoch[2] Step[19041 / 19085] - loss: 6.529500  \n",
      "Train Epoch[2] Step[19061 / 19085] - loss: 6.266714  \n",
      "Train Epoch[2] Step[19081 / 19085] - loss: 9.246522  \n",
      "Train Epoch[3] Step[1 / 19085] - loss: 5.858152  \n",
      "Train Epoch[3] Step[21 / 19085] - loss: 4.855872  \n",
      "Train Epoch[3] Step[41 / 19085] - loss: 8.835609  \n",
      "Train Epoch[3] Step[61 / 19085] - loss: 6.398551  \n",
      "Train Epoch[3] Step[81 / 19085] - loss: 9.289566  \n",
      "Train Epoch[3] Step[101 / 19085] - loss: 3.634667  \n",
      "Train Epoch[3] Step[121 / 19085] - loss: 5.959778  \n",
      "Train Epoch[3] Step[141 / 19085] - loss: 5.287148  \n",
      "Train Epoch[3] Step[161 / 19085] - loss: 10.828566  \n",
      "Train Epoch[3] Step[181 / 19085] - loss: 5.317733  \n",
      "Train Epoch[3] Step[201 / 19085] - loss: 9.190161  \n",
      "Train Epoch[3] Step[221 / 19085] - loss: 7.322460  \n",
      "Train Epoch[3] Step[241 / 19085] - loss: 4.556689  \n",
      "Train Epoch[3] Step[261 / 19085] - loss: 3.063633  \n",
      "Train Epoch[3] Step[281 / 19085] - loss: 7.830865  \n",
      "Train Epoch[3] Step[301 / 19085] - loss: 8.811381  \n",
      "Train Epoch[3] Step[321 / 19085] - loss: 4.707682  \n",
      "Train Epoch[3] Step[341 / 19085] - loss: 12.187152  \n",
      "Train Epoch[3] Step[361 / 19085] - loss: 3.884659  \n",
      "Train Epoch[3] Step[381 / 19085] - loss: 2.339912  \n",
      "Train Epoch[3] Step[401 / 19085] - loss: 8.911303  \n",
      "Train Epoch[3] Step[421 / 19085] - loss: 3.681005  \n",
      "Train Epoch[3] Step[441 / 19085] - loss: 12.945465  \n",
      "Train Epoch[3] Step[461 / 19085] - loss: 4.255046  \n",
      "Train Epoch[3] Step[481 / 19085] - loss: 6.334866  \n",
      "Train Epoch[3] Step[501 / 19085] - loss: 7.766780  \n",
      "Train Epoch[3] Step[521 / 19085] - loss: 9.483456  \n",
      "Train Epoch[3] Step[541 / 19085] - loss: 7.276713  \n",
      "Train Epoch[3] Step[561 / 19085] - loss: 8.937535  \n",
      "Train Epoch[3] Step[581 / 19085] - loss: 5.426266  \n",
      "Train Epoch[3] Step[601 / 19085] - loss: 8.092459  \n",
      "Train Epoch[3] Step[621 / 19085] - loss: 7.884472  \n",
      "Train Epoch[3] Step[641 / 19085] - loss: 6.489213  \n",
      "Train Epoch[3] Step[661 / 19085] - loss: 3.603369  \n",
      "Train Epoch[3] Step[681 / 19085] - loss: 5.344954  \n",
      "Train Epoch[3] Step[701 / 19085] - loss: 3.926587  \n",
      "Train Epoch[3] Step[721 / 19085] - loss: 8.657766  \n",
      "Train Epoch[3] Step[741 / 19085] - loss: 3.158349  \n",
      "Train Epoch[3] Step[761 / 19085] - loss: 10.322178  \n",
      "Train Epoch[3] Step[781 / 19085] - loss: 6.299755  \n",
      "Train Epoch[3] Step[801 / 19085] - loss: 4.961564  \n",
      "Train Epoch[3] Step[821 / 19085] - loss: 9.827418  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:34<00:00, 14.25it/s]\n",
      "Dev Loss: 6.945976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7116    0.4816    0.5744     26118\n",
      "         ORG     0.0000    0.0000    0.0000      1956\n",
      "         PER     0.6389    0.4921    0.5560     22839\n",
      "           T     0.7756    0.5487    0.6427     22956\n",
      "\n",
      "   micro avg     0.7068    0.4930    0.5808     73869\n",
      "   macro avg     0.5315    0.3806    0.4433     73869\n",
      "weighted avg     0.6902    0.4930    0.5748     73869\n",
      "\n",
      "best f1: 0.57, current f1: 0.58\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[841 / 19085] - loss: 6.088193  \n",
      "Train Epoch[3] Step[861 / 19085] - loss: 6.196551  \n",
      "Train Epoch[3] Step[881 / 19085] - loss: 8.416035  \n",
      "Train Epoch[3] Step[901 / 19085] - loss: 7.784933  \n",
      "Train Epoch[3] Step[921 / 19085] - loss: 5.575295  \n",
      "Train Epoch[3] Step[941 / 19085] - loss: 4.284141  \n",
      "Train Epoch[3] Step[961 / 19085] - loss: 4.508683  \n",
      "Train Epoch[3] Step[981 / 19085] - loss: 6.955812  \n",
      "Train Epoch[3] Step[1001 / 19085] - loss: 7.252387  \n",
      "Train Epoch[3] Step[1021 / 19085] - loss: 8.291569  \n",
      "Train Epoch[3] Step[1041 / 19085] - loss: 6.145792  \n",
      "Train Epoch[3] Step[1061 / 19085] - loss: 8.003565  \n",
      "Train Epoch[3] Step[1081 / 19085] - loss: 7.180888  \n",
      "Train Epoch[3] Step[1101 / 19085] - loss: 5.932144  \n",
      "Train Epoch[3] Step[1121 / 19085] - loss: 6.175007  \n",
      "Train Epoch[3] Step[1141 / 19085] - loss: 9.634780  \n",
      "Train Epoch[3] Step[1161 / 19085] - loss: 3.970172  \n",
      "Train Epoch[3] Step[1181 / 19085] - loss: 2.843869  \n",
      "Train Epoch[3] Step[1201 / 19085] - loss: 6.995791  \n",
      "Train Epoch[3] Step[1221 / 19085] - loss: 11.227133  \n",
      "Train Epoch[3] Step[1241 / 19085] - loss: 5.820627  \n",
      "Train Epoch[3] Step[1261 / 19085] - loss: 5.077250  \n",
      "Train Epoch[3] Step[1281 / 19085] - loss: 9.473511  \n",
      "Train Epoch[3] Step[1301 / 19085] - loss: 5.705341  \n",
      "Train Epoch[3] Step[1321 / 19085] - loss: 7.855646  \n",
      "Train Epoch[3] Step[1341 / 19085] - loss: 3.895836  \n",
      "Train Epoch[3] Step[1361 / 19085] - loss: 4.085481  \n",
      "Train Epoch[3] Step[1381 / 19085] - loss: 9.502443  \n",
      "Train Epoch[3] Step[1401 / 19085] - loss: 6.211757  \n",
      "Train Epoch[3] Step[1421 / 19085] - loss: 6.805641  \n",
      "Train Epoch[3] Step[1441 / 19085] - loss: 6.934578  \n",
      "Train Epoch[3] Step[1461 / 19085] - loss: 7.382782  \n",
      "Train Epoch[3] Step[1481 / 19085] - loss: 5.019644  \n",
      "Train Epoch[3] Step[1501 / 19085] - loss: 5.123284  \n",
      "Train Epoch[3] Step[1521 / 19085] - loss: 4.621192  \n",
      "Train Epoch[3] Step[1541 / 19085] - loss: 8.421469  \n",
      "Train Epoch[3] Step[1561 / 19085] - loss: 5.561626  \n",
      "Train Epoch[3] Step[1581 / 19085] - loss: 9.067516  \n",
      "Train Epoch[3] Step[1601 / 19085] - loss: 9.501887  \n",
      "Train Epoch[3] Step[1621 / 19085] - loss: 7.001457  \n",
      "Train Epoch[3] Step[1641 / 19085] - loss: 5.280195  \n",
      "Train Epoch[3] Step[1661 / 19085] - loss: 6.854796  \n",
      "Train Epoch[3] Step[1681 / 19085] - loss: 8.962973  \n",
      "Train Epoch[3] Step[1701 / 19085] - loss: 7.502046  \n",
      "Train Epoch[3] Step[1721 / 19085] - loss: 4.046181  \n",
      "Train Epoch[3] Step[1741 / 19085] - loss: 4.304489  \n",
      "Train Epoch[3] Step[1761 / 19085] - loss: 6.678461  \n",
      "Train Epoch[3] Step[1781 / 19085] - loss: 5.580114  \n",
      "Train Epoch[3] Step[1801 / 19085] - loss: 6.895184  \n",
      "Train Epoch[3] Step[1821 / 19085] - loss: 5.381016  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:34<00:00, 14.27it/s]\n",
      "Dev Loss: 6.802013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7046    0.5291    0.6044     26118\n",
      "         ORG     0.0435    0.0005    0.0010      1956\n",
      "         PER     0.6459    0.4985    0.5627     22839\n",
      "           T     0.7732    0.5523    0.6443     22956\n",
      "\n",
      "   micro avg     0.7060    0.5128    0.5941     73869\n",
      "   macro avg     0.5418    0.3951    0.4531     73869\n",
      "weighted avg     0.6903    0.5128    0.5879     73869\n",
      "\n",
      "best f1: 0.58, current f1: 0.59\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[1841 / 19085] - loss: 7.179441  \n",
      "Train Epoch[3] Step[1861 / 19085] - loss: 7.906450  \n",
      "Train Epoch[3] Step[1881 / 19085] - loss: 4.156158  \n",
      "Train Epoch[3] Step[1901 / 19085] - loss: 7.722156  \n",
      "Train Epoch[3] Step[1921 / 19085] - loss: 9.609005  \n",
      "Train Epoch[3] Step[1941 / 19085] - loss: 4.515278  \n",
      "Train Epoch[3] Step[1961 / 19085] - loss: 5.809525  \n",
      "Train Epoch[3] Step[1981 / 19085] - loss: 8.184624  \n",
      "Train Epoch[3] Step[2001 / 19085] - loss: 8.123516  \n",
      "Train Epoch[3] Step[2021 / 19085] - loss: 9.629436  \n",
      "Train Epoch[3] Step[2041 / 19085] - loss: 5.107236  \n",
      "Train Epoch[3] Step[2061 / 19085] - loss: 5.020583  \n",
      "Train Epoch[3] Step[2081 / 19085] - loss: 9.601543  \n",
      "Train Epoch[3] Step[2101 / 19085] - loss: 6.354032  \n",
      "Train Epoch[3] Step[2121 / 19085] - loss: 7.240841  \n",
      "Train Epoch[3] Step[2141 / 19085] - loss: 7.127116  \n",
      "Train Epoch[3] Step[2161 / 19085] - loss: 6.760068  \n",
      "Train Epoch[3] Step[2181 / 19085] - loss: 2.851095  \n",
      "Train Epoch[3] Step[2201 / 19085] - loss: 2.199357  \n",
      "Train Epoch[3] Step[2221 / 19085] - loss: 7.527210  \n",
      "Train Epoch[3] Step[2241 / 19085] - loss: 9.912601  \n",
      "Train Epoch[3] Step[2261 / 19085] - loss: 8.399869  \n",
      "Train Epoch[3] Step[2281 / 19085] - loss: 8.155516  \n",
      "Train Epoch[3] Step[2301 / 19085] - loss: 8.469264  \n",
      "Train Epoch[3] Step[2321 / 19085] - loss: 5.052358  \n",
      "Train Epoch[3] Step[2341 / 19085] - loss: 4.404326  \n",
      "Train Epoch[3] Step[2361 / 19085] - loss: 4.895923  \n",
      "Train Epoch[3] Step[2381 / 19085] - loss: 3.862586  \n",
      "Train Epoch[3] Step[2401 / 19085] - loss: 6.583107  \n",
      "Train Epoch[3] Step[2421 / 19085] - loss: 7.173938  \n",
      "Train Epoch[3] Step[2441 / 19085] - loss: 6.239732  \n",
      "Train Epoch[3] Step[2461 / 19085] - loss: 10.814919  \n",
      "Train Epoch[3] Step[2481 / 19085] - loss: 8.577383  \n",
      "Train Epoch[3] Step[2501 / 19085] - loss: 3.608844  \n",
      "Train Epoch[3] Step[2521 / 19085] - loss: 6.189078  \n",
      "Train Epoch[3] Step[2541 / 19085] - loss: 9.809805  \n",
      "Train Epoch[3] Step[2561 / 19085] - loss: 5.120961  \n",
      "Train Epoch[3] Step[2581 / 19085] - loss: 4.789666  \n",
      "Train Epoch[3] Step[2601 / 19085] - loss: 4.280258  \n",
      "Train Epoch[3] Step[2621 / 19085] - loss: 6.518064  \n",
      "Train Epoch[3] Step[2641 / 19085] - loss: 7.143789  \n",
      "Train Epoch[3] Step[2661 / 19085] - loss: 3.404811  \n",
      "Train Epoch[3] Step[2681 / 19085] - loss: 6.319007  \n",
      "Train Epoch[3] Step[2701 / 19085] - loss: 7.343904  \n",
      "Train Epoch[3] Step[2721 / 19085] - loss: 6.421474  \n",
      "Train Epoch[3] Step[2741 / 19085] - loss: 3.161651  \n",
      "Train Epoch[3] Step[2761 / 19085] - loss: 6.023917  \n",
      "Train Epoch[3] Step[2781 / 19085] - loss: 6.948135  \n",
      "Train Epoch[3] Step[2801 / 19085] - loss: 5.269581  \n",
      "Train Epoch[3] Step[2821 / 19085] - loss: 5.578978  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:32<00:00, 14.36it/s]\n",
      "Dev Loss: 6.704202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7101    0.5217    0.6015     26118\n",
      "         ORG     0.0435    0.0005    0.0010      1956\n",
      "         PER     0.6528    0.4903    0.5600     22839\n",
      "           T     0.7692    0.5988    0.6734     22956\n",
      "\n",
      "   micro avg     0.7112    0.5222    0.6022     73869\n",
      "   macro avg     0.5439    0.4029    0.4590     73869\n",
      "weighted avg     0.6931    0.5222    0.5951     73869\n",
      "\n",
      "best f1: 0.59, current f1: 0.60\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[2841 / 19085] - loss: 4.122612  \n",
      "Train Epoch[3] Step[2861 / 19085] - loss: 6.595396  \n",
      "Train Epoch[3] Step[2881 / 19085] - loss: 5.283717  \n",
      "Train Epoch[3] Step[2901 / 19085] - loss: 8.346878  \n",
      "Train Epoch[3] Step[2921 / 19085] - loss: 4.658142  \n",
      "Train Epoch[3] Step[2941 / 19085] - loss: 8.651768  \n",
      "Train Epoch[3] Step[2961 / 19085] - loss: 6.955228  \n",
      "Train Epoch[3] Step[2981 / 19085] - loss: 3.766349  \n",
      "Train Epoch[3] Step[3001 / 19085] - loss: 4.284512  \n",
      "Train Epoch[3] Step[3021 / 19085] - loss: 8.084666  \n",
      "Train Epoch[3] Step[3041 / 19085] - loss: 8.775519  \n",
      "Train Epoch[3] Step[3061 / 19085] - loss: 7.691429  \n",
      "Train Epoch[3] Step[3081 / 19085] - loss: 5.466875  \n",
      "Train Epoch[3] Step[3101 / 19085] - loss: 5.459213  \n",
      "Train Epoch[3] Step[3121 / 19085] - loss: 3.694773  \n",
      "Train Epoch[3] Step[3141 / 19085] - loss: 4.688727  \n",
      "Train Epoch[3] Step[3161 / 19085] - loss: 9.079298  \n",
      "Train Epoch[3] Step[3181 / 19085] - loss: 5.300838  \n",
      "Train Epoch[3] Step[3201 / 19085] - loss: 3.316455  \n",
      "Train Epoch[3] Step[3221 / 19085] - loss: 8.008446  \n",
      "Train Epoch[3] Step[3241 / 19085] - loss: 7.347564  \n",
      "Train Epoch[3] Step[3261 / 19085] - loss: 10.030610  \n",
      "Train Epoch[3] Step[3281 / 19085] - loss: 5.186255  \n",
      "Train Epoch[3] Step[3301 / 19085] - loss: 9.876192  \n",
      "Train Epoch[3] Step[3321 / 19085] - loss: 4.786887  \n",
      "Train Epoch[3] Step[3341 / 19085] - loss: 5.316756  \n",
      "Train Epoch[3] Step[3361 / 19085] - loss: 4.341456  \n",
      "Train Epoch[3] Step[3381 / 19085] - loss: 7.163391  \n",
      "Train Epoch[3] Step[3401 / 19085] - loss: 5.498518  \n",
      "Train Epoch[3] Step[3421 / 19085] - loss: 5.809722  \n",
      "Train Epoch[3] Step[3441 / 19085] - loss: 5.395423  \n",
      "Train Epoch[3] Step[3461 / 19085] - loss: 3.644972  \n",
      "Train Epoch[3] Step[3481 / 19085] - loss: 12.353233  \n",
      "Train Epoch[3] Step[3501 / 19085] - loss: 3.894290  \n",
      "Train Epoch[3] Step[3521 / 19085] - loss: 7.341423  \n",
      "Train Epoch[3] Step[3541 / 19085] - loss: 14.227832  \n",
      "Train Epoch[3] Step[3561 / 19085] - loss: 10.457375  \n",
      "Train Epoch[3] Step[3581 / 19085] - loss: 2.781335  \n",
      "Train Epoch[3] Step[3601 / 19085] - loss: 5.884807  \n",
      "Train Epoch[3] Step[3621 / 19085] - loss: 7.869551  \n",
      "Train Epoch[3] Step[3641 / 19085] - loss: 6.564815  \n",
      "Train Epoch[3] Step[3661 / 19085] - loss: 8.496913  \n",
      "Train Epoch[3] Step[3681 / 19085] - loss: 3.618179  \n",
      "Train Epoch[3] Step[3701 / 19085] - loss: 10.831059  \n",
      "Train Epoch[3] Step[3721 / 19085] - loss: 8.030214  \n",
      "Train Epoch[3] Step[3741 / 19085] - loss: 7.676645  \n",
      "Train Epoch[3] Step[3761 / 19085] - loss: 5.158175  \n",
      "Train Epoch[3] Step[3781 / 19085] - loss: 1.706968  \n",
      "Train Epoch[3] Step[3801 / 19085] - loss: 12.032427  \n",
      "Train Epoch[3] Step[3821 / 19085] - loss: 11.266609  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:25<00:00, 14.64it/s]\n",
      "Dev Loss: 6.617798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7107    0.5215    0.6016     26118\n",
      "         ORG     0.0323    0.0005    0.0010      1956\n",
      "         PER     0.6613    0.4974    0.5677     22839\n",
      "           T     0.7810    0.5602    0.6525     22956\n",
      "\n",
      "   micro avg     0.7162    0.5123    0.5973     73869\n",
      "   macro avg     0.5463    0.3949    0.4557     73869\n",
      "weighted avg     0.6993    0.5123    0.5910     73869\n",
      "\n",
      "best f1: 0.60, current f1: 0.60\n",
      "\n",
      "Train Epoch[3] Step[3841 / 19085] - loss: 9.600115  \n",
      "Train Epoch[3] Step[3861 / 19085] - loss: 8.716606  \n",
      "Train Epoch[3] Step[3881 / 19085] - loss: 6.400409  \n",
      "Train Epoch[3] Step[3901 / 19085] - loss: 9.525381  \n",
      "Train Epoch[3] Step[3921 / 19085] - loss: 6.791161  \n",
      "Train Epoch[3] Step[3941 / 19085] - loss: 5.855271  \n",
      "Train Epoch[3] Step[3961 / 19085] - loss: 6.763492  \n",
      "Train Epoch[3] Step[3981 / 19085] - loss: 6.910791  \n",
      "Train Epoch[3] Step[4001 / 19085] - loss: 9.594000  \n",
      "Train Epoch[3] Step[4021 / 19085] - loss: 6.434339  \n",
      "Train Epoch[3] Step[4041 / 19085] - loss: 1.701867  \n",
      "Train Epoch[3] Step[4061 / 19085] - loss: 7.031757  \n",
      "Train Epoch[3] Step[4081 / 19085] - loss: 5.399074  \n",
      "Train Epoch[3] Step[4101 / 19085] - loss: 5.389428  \n",
      "Train Epoch[3] Step[4121 / 19085] - loss: 7.276820  \n",
      "Train Epoch[3] Step[4141 / 19085] - loss: 8.990620  \n",
      "Train Epoch[3] Step[4161 / 19085] - loss: 9.124327  \n",
      "Train Epoch[3] Step[4181 / 19085] - loss: 9.187750  \n",
      "Train Epoch[3] Step[4201 / 19085] - loss: 6.925703  \n",
      "Train Epoch[3] Step[4221 / 19085] - loss: 4.243865  \n",
      "Train Epoch[3] Step[4241 / 19085] - loss: 8.036724  \n",
      "Train Epoch[3] Step[4261 / 19085] - loss: 5.450622  \n",
      "Train Epoch[3] Step[4281 / 19085] - loss: 3.802295  \n",
      "Train Epoch[3] Step[4301 / 19085] - loss: 7.831827  \n",
      "Train Epoch[3] Step[4321 / 19085] - loss: 14.298103  \n",
      "Train Epoch[3] Step[4341 / 19085] - loss: 8.460985  \n",
      "Train Epoch[3] Step[4361 / 19085] - loss: 7.334666  \n",
      "Train Epoch[3] Step[4381 / 19085] - loss: 6.636980  \n",
      "Train Epoch[3] Step[4401 / 19085] - loss: 7.639990  \n",
      "Train Epoch[3] Step[4421 / 19085] - loss: 4.575733  \n",
      "Train Epoch[3] Step[4441 / 19085] - loss: 8.876562  \n",
      "Train Epoch[3] Step[4461 / 19085] - loss: 4.886469  \n",
      "Train Epoch[3] Step[4481 / 19085] - loss: 6.156872  \n",
      "Train Epoch[3] Step[4501 / 19085] - loss: 6.664442  \n",
      "Train Epoch[3] Step[4521 / 19085] - loss: 4.608768  \n",
      "Train Epoch[3] Step[4541 / 19085] - loss: 10.705791  \n",
      "Train Epoch[3] Step[4561 / 19085] - loss: 8.228186  \n",
      "Train Epoch[3] Step[4581 / 19085] - loss: 5.813541  \n",
      "Train Epoch[3] Step[4601 / 19085] - loss: 8.274080  \n",
      "Train Epoch[3] Step[4621 / 19085] - loss: 5.073082  \n",
      "Train Epoch[3] Step[4641 / 19085] - loss: 6.737850  \n",
      "Train Epoch[3] Step[4661 / 19085] - loss: 3.851078  \n",
      "Train Epoch[3] Step[4681 / 19085] - loss: 11.475055  \n",
      "Train Epoch[3] Step[4701 / 19085] - loss: 5.671394  \n",
      "Train Epoch[3] Step[4721 / 19085] - loss: 8.011035  \n",
      "Train Epoch[3] Step[4741 / 19085] - loss: 4.867721  \n",
      "Train Epoch[3] Step[4761 / 19085] - loss: 5.428466  \n",
      "Train Epoch[3] Step[4781 / 19085] - loss: 10.032631  \n",
      "Train Epoch[3] Step[4801 / 19085] - loss: 9.482958  \n",
      "Train Epoch[3] Step[4821 / 19085] - loss: 9.760008  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:42<00:00, 13.93it/s]\n",
      "Dev Loss: 6.566330\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7171    0.4878    0.5806     26118\n",
      "         ORG     0.0172    0.0005    0.0010      1956\n",
      "         PER     0.6803    0.4819    0.5641     22839\n",
      "           T     0.7867    0.5784    0.6666     22956\n",
      "\n",
      "   micro avg     0.7277    0.5012    0.5936     73869\n",
      "   macro avg     0.5503    0.3871    0.4531     73869\n",
      "weighted avg     0.7088    0.5012    0.5869     73869\n",
      "\n",
      "best f1: 0.60, current f1: 0.59\n",
      "\n",
      "Train Epoch[3] Step[4841 / 19085] - loss: 9.283186  \n",
      "Train Epoch[3] Step[4861 / 19085] - loss: 4.353952  \n",
      "Train Epoch[3] Step[4881 / 19085] - loss: 10.163409  \n",
      "Train Epoch[3] Step[4901 / 19085] - loss: 8.427091  \n",
      "Train Epoch[3] Step[4921 / 19085] - loss: 5.789687  \n",
      "Train Epoch[3] Step[4941 / 19085] - loss: 8.993235  \n",
      "Train Epoch[3] Step[4961 / 19085] - loss: 4.920016  \n",
      "Train Epoch[3] Step[4981 / 19085] - loss: 4.750394  \n",
      "Train Epoch[3] Step[5001 / 19085] - loss: 9.119081  \n",
      "Train Epoch[3] Step[5021 / 19085] - loss: 7.011816  \n",
      "Train Epoch[3] Step[5041 / 19085] - loss: 3.864883  \n",
      "Train Epoch[3] Step[5061 / 19085] - loss: 9.605367  \n",
      "Train Epoch[3] Step[5081 / 19085] - loss: 6.526460  \n",
      "Train Epoch[3] Step[5101 / 19085] - loss: 6.965436  \n",
      "Train Epoch[3] Step[5121 / 19085] - loss: 2.949292  \n",
      "Train Epoch[3] Step[5141 / 19085] - loss: 8.668574  \n",
      "Train Epoch[3] Step[5161 / 19085] - loss: 4.820709  \n",
      "Train Epoch[3] Step[5181 / 19085] - loss: 6.387043  \n",
      "Train Epoch[3] Step[5201 / 19085] - loss: 3.726621  \n",
      "Train Epoch[3] Step[5221 / 19085] - loss: 7.920849  \n",
      "Train Epoch[3] Step[5241 / 19085] - loss: 2.448678  \n",
      "Train Epoch[3] Step[5261 / 19085] - loss: 6.709315  \n",
      "Train Epoch[3] Step[5281 / 19085] - loss: 6.889743  \n",
      "Train Epoch[3] Step[5301 / 19085] - loss: 8.353607  \n",
      "Train Epoch[3] Step[5321 / 19085] - loss: 8.874477  \n",
      "Train Epoch[3] Step[5341 / 19085] - loss: 7.214272  \n",
      "Train Epoch[3] Step[5361 / 19085] - loss: 7.393728  \n",
      "Train Epoch[3] Step[5381 / 19085] - loss: 5.596139  \n",
      "Train Epoch[3] Step[5401 / 19085] - loss: 3.367019  \n",
      "Train Epoch[3] Step[5421 / 19085] - loss: 4.553926  \n",
      "Train Epoch[3] Step[5441 / 19085] - loss: 6.249786  \n",
      "Train Epoch[3] Step[5461 / 19085] - loss: 4.362347  \n",
      "Train Epoch[3] Step[5481 / 19085] - loss: 4.790007  \n",
      "Train Epoch[3] Step[5501 / 19085] - loss: 10.221645  \n",
      "Train Epoch[3] Step[5521 / 19085] - loss: 11.147571  \n",
      "Train Epoch[3] Step[5541 / 19085] - loss: 9.978539  \n",
      "Train Epoch[3] Step[5561 / 19085] - loss: 7.211904  \n",
      "Train Epoch[3] Step[5581 / 19085] - loss: 5.920389  \n",
      "Train Epoch[3] Step[5601 / 19085] - loss: 6.352545  \n",
      "Train Epoch[3] Step[5621 / 19085] - loss: 8.228973  \n",
      "Train Epoch[3] Step[5641 / 19085] - loss: 8.522279  \n",
      "Train Epoch[3] Step[5661 / 19085] - loss: 9.200593  \n",
      "Train Epoch[3] Step[5681 / 19085] - loss: 4.029367  \n",
      "Train Epoch[3] Step[5701 / 19085] - loss: 6.539212  \n",
      "Train Epoch[3] Step[5721 / 19085] - loss: 4.785813  \n",
      "Train Epoch[3] Step[5741 / 19085] - loss: 7.314934  \n",
      "Train Epoch[3] Step[5761 / 19085] - loss: 4.369048  \n",
      "Train Epoch[3] Step[5781 / 19085] - loss: 9.373472  \n",
      "Train Epoch[3] Step[5801 / 19085] - loss: 5.662937  \n",
      "Train Epoch[3] Step[5821 / 19085] - loss: 4.035054  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:31<00:00, 14.41it/s]\n",
      "Dev Loss: 6.476145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7134    0.5258    0.6054     26118\n",
      "         ORG     0.0303    0.0005    0.0010      1956\n",
      "         PER     0.6853    0.4920    0.5728     22839\n",
      "           T     0.7848    0.5359    0.6368     22956\n",
      "\n",
      "   micro avg     0.7258    0.5046    0.5953     73869\n",
      "   macro avg     0.5534    0.3885    0.4540     73869\n",
      "weighted avg     0.7088    0.5046    0.5891     73869\n",
      "\n",
      "best f1: 0.60, current f1: 0.60\n",
      "\n",
      "Train Epoch[3] Step[5841 / 19085] - loss: 9.995889  \n",
      "Train Epoch[3] Step[5861 / 19085] - loss: 5.447942  \n",
      "Train Epoch[3] Step[5881 / 19085] - loss: 2.759918  \n",
      "Train Epoch[3] Step[5901 / 19085] - loss: 4.173994  \n",
      "Train Epoch[3] Step[5921 / 19085] - loss: 8.126761  \n",
      "Train Epoch[3] Step[5941 / 19085] - loss: 4.827926  \n",
      "Train Epoch[3] Step[5961 / 19085] - loss: 6.024637  \n",
      "Train Epoch[3] Step[5981 / 19085] - loss: 5.613990  \n",
      "Train Epoch[3] Step[6001 / 19085] - loss: 4.984771  \n",
      "Train Epoch[3] Step[6021 / 19085] - loss: 10.271353  \n",
      "Train Epoch[3] Step[6041 / 19085] - loss: 4.913243  \n",
      "Train Epoch[3] Step[6061 / 19085] - loss: 5.444726  \n",
      "Train Epoch[3] Step[6081 / 19085] - loss: 11.367626  \n",
      "Train Epoch[3] Step[6101 / 19085] - loss: 5.341070  \n",
      "Train Epoch[3] Step[6121 / 19085] - loss: 3.526965  \n",
      "Train Epoch[3] Step[6141 / 19085] - loss: 6.775122  \n",
      "Train Epoch[3] Step[6161 / 19085] - loss: 5.585521  \n",
      "Train Epoch[3] Step[6181 / 19085] - loss: 4.655622  \n",
      "Train Epoch[3] Step[6201 / 19085] - loss: 3.752650  \n",
      "Train Epoch[3] Step[6221 / 19085] - loss: 6.182878  \n",
      "Train Epoch[3] Step[6241 / 19085] - loss: 7.991508  \n",
      "Train Epoch[3] Step[6261 / 19085] - loss: 3.480597  \n",
      "Train Epoch[3] Step[6281 / 19085] - loss: 5.227139  \n",
      "Train Epoch[3] Step[6301 / 19085] - loss: 7.461704  \n",
      "Train Epoch[3] Step[6321 / 19085] - loss: 7.226465  \n",
      "Train Epoch[3] Step[6341 / 19085] - loss: 6.909336  \n",
      "Train Epoch[3] Step[6361 / 19085] - loss: 4.377229  \n",
      "Train Epoch[3] Step[6381 / 19085] - loss: 6.746863  \n",
      "Train Epoch[3] Step[6401 / 19085] - loss: 7.594999  \n",
      "Train Epoch[3] Step[6421 / 19085] - loss: 14.254246  \n",
      "Train Epoch[3] Step[6441 / 19085] - loss: 7.918933  \n",
      "Train Epoch[3] Step[6461 / 19085] - loss: 4.676689  \n",
      "Train Epoch[3] Step[6481 / 19085] - loss: 7.476969  \n",
      "Train Epoch[3] Step[6501 / 19085] - loss: 6.481352  \n",
      "Train Epoch[3] Step[6521 / 19085] - loss: 6.513265  \n",
      "Train Epoch[3] Step[6541 / 19085] - loss: 8.057240  \n",
      "Train Epoch[3] Step[6561 / 19085] - loss: 7.349031  \n",
      "Train Epoch[3] Step[6581 / 19085] - loss: 5.988061  \n",
      "Train Epoch[3] Step[6601 / 19085] - loss: 6.431919  \n",
      "Train Epoch[3] Step[6621 / 19085] - loss: 6.150842  \n",
      "Train Epoch[3] Step[6641 / 19085] - loss: 6.874921  \n",
      "Train Epoch[3] Step[6661 / 19085] - loss: 4.063604  \n",
      "Train Epoch[3] Step[6681 / 19085] - loss: 3.832916  \n",
      "Train Epoch[3] Step[6701 / 19085] - loss: 5.406891  \n",
      "Train Epoch[3] Step[6721 / 19085] - loss: 6.489110  \n",
      "Train Epoch[3] Step[6741 / 19085] - loss: 11.707487  \n",
      "Train Epoch[3] Step[6761 / 19085] - loss: 5.178562  \n",
      "Train Epoch[3] Step[6781 / 19085] - loss: 3.960081  \n",
      "Train Epoch[3] Step[6801 / 19085] - loss: 3.802391  \n",
      "Train Epoch[3] Step[6821 / 19085] - loss: 5.585699  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:24<00:00, 14.71it/s]\n",
      "Dev Loss: 6.379680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7188    0.5183    0.6023     26118\n",
      "         ORG     0.0513    0.0010    0.0020      1956\n",
      "         PER     0.6811    0.4991    0.5761     22839\n",
      "           T     0.7897    0.5756    0.6659     22956\n",
      "\n",
      "   micro avg     0.7289    0.5165    0.6046     73869\n",
      "   macro avg     0.5602    0.3985    0.4616     73869\n",
      "weighted avg     0.7115    0.5165    0.5981     73869\n",
      "\n",
      "best f1: 0.60, current f1: 0.60\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[6841 / 19085] - loss: 6.261794  \n",
      "Train Epoch[3] Step[6861 / 19085] - loss: 5.143978  \n",
      "Train Epoch[3] Step[6881 / 19085] - loss: 8.379149  \n",
      "Train Epoch[3] Step[6901 / 19085] - loss: 10.037419  \n",
      "Train Epoch[3] Step[6921 / 19085] - loss: 6.811365  \n",
      "Train Epoch[3] Step[6941 / 19085] - loss: 4.038213  \n",
      "Train Epoch[3] Step[6961 / 19085] - loss: 6.653184  \n",
      "Train Epoch[3] Step[6981 / 19085] - loss: 6.756272  \n",
      "Train Epoch[3] Step[7001 / 19085] - loss: 10.087514  \n",
      "Train Epoch[3] Step[7021 / 19085] - loss: 4.918175  \n",
      "Train Epoch[3] Step[7041 / 19085] - loss: 4.540279  \n",
      "Train Epoch[3] Step[7061 / 19085] - loss: 6.246778  \n",
      "Train Epoch[3] Step[7081 / 19085] - loss: 9.920002  \n",
      "Train Epoch[3] Step[7101 / 19085] - loss: 7.420042  \n",
      "Train Epoch[3] Step[7121 / 19085] - loss: 6.386830  \n",
      "Train Epoch[3] Step[7141 / 19085] - loss: 7.120965  \n",
      "Train Epoch[3] Step[7161 / 19085] - loss: 4.709725  \n",
      "Train Epoch[3] Step[7181 / 19085] - loss: 6.820579  \n",
      "Train Epoch[3] Step[7201 / 19085] - loss: 3.895298  \n",
      "Train Epoch[3] Step[7221 / 19085] - loss: 3.476551  \n",
      "Train Epoch[3] Step[7241 / 19085] - loss: 5.804840  \n",
      "Train Epoch[3] Step[7261 / 19085] - loss: 8.491779  \n",
      "Train Epoch[3] Step[7281 / 19085] - loss: 5.769062  \n",
      "Train Epoch[3] Step[7301 / 19085] - loss: 3.618704  \n",
      "Train Epoch[3] Step[7321 / 19085] - loss: 7.619504  \n",
      "Train Epoch[3] Step[7341 / 19085] - loss: 4.517174  \n",
      "Train Epoch[3] Step[7361 / 19085] - loss: 8.330339  \n",
      "Train Epoch[3] Step[7381 / 19085] - loss: 6.290441  \n",
      "Train Epoch[3] Step[7401 / 19085] - loss: 14.493949  \n",
      "Train Epoch[3] Step[7421 / 19085] - loss: 4.585151  \n",
      "Train Epoch[3] Step[7441 / 19085] - loss: 4.839686  \n",
      "Train Epoch[3] Step[7461 / 19085] - loss: 5.824237  \n",
      "Train Epoch[3] Step[7481 / 19085] - loss: 4.277300  \n",
      "Train Epoch[3] Step[7501 / 19085] - loss: 5.219430  \n",
      "Train Epoch[3] Step[7521 / 19085] - loss: 4.805640  \n",
      "Train Epoch[3] Step[7541 / 19085] - loss: 5.705668  \n",
      "Train Epoch[3] Step[7561 / 19085] - loss: 2.532019  \n",
      "Train Epoch[3] Step[7581 / 19085] - loss: 9.859612  \n",
      "Train Epoch[3] Step[7601 / 19085] - loss: 8.408443  \n",
      "Train Epoch[3] Step[7621 / 19085] - loss: 6.403220  \n",
      "Train Epoch[3] Step[7641 / 19085] - loss: 7.761482  \n",
      "Train Epoch[3] Step[7661 / 19085] - loss: 6.282468  \n",
      "Train Epoch[3] Step[7681 / 19085] - loss: 5.418018  \n",
      "Train Epoch[3] Step[7701 / 19085] - loss: 3.754327  \n",
      "Train Epoch[3] Step[7721 / 19085] - loss: 7.971929  \n",
      "Train Epoch[3] Step[7741 / 19085] - loss: 5.074666  \n",
      "Train Epoch[3] Step[7761 / 19085] - loss: 9.335728  \n",
      "Train Epoch[3] Step[7781 / 19085] - loss: 6.866764  \n",
      "Train Epoch[3] Step[7801 / 19085] - loss: 6.664388  \n",
      "Train Epoch[3] Step[7821 / 19085] - loss: 13.807261  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:22<00:00, 14.81it/s]\n",
      "Dev Loss: 6.283743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7075    0.5378    0.6111     26118\n",
      "         ORG     0.0476    0.0010    0.0020      1956\n",
      "         PER     0.6933    0.4962    0.5784     22839\n",
      "           T     0.7903    0.5818    0.6702     22956\n",
      "\n",
      "   micro avg     0.7289    0.5244    0.6100     73869\n",
      "   macro avg     0.5597    0.4042    0.4654     73869\n",
      "weighted avg     0.7114    0.5244    0.6032     73869\n",
      "\n",
      "best f1: 0.60, current f1: 0.61\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[7841 / 19085] - loss: 7.377762  \n",
      "Train Epoch[3] Step[7861 / 19085] - loss: 6.364933  \n",
      "Train Epoch[3] Step[7881 / 19085] - loss: 1.905783  \n",
      "Train Epoch[3] Step[7901 / 19085] - loss: 6.201973  \n",
      "Train Epoch[3] Step[7921 / 19085] - loss: 6.189404  \n",
      "Train Epoch[3] Step[7941 / 19085] - loss: 3.446465  \n",
      "Train Epoch[3] Step[7961 / 19085] - loss: 6.460982  \n",
      "Train Epoch[3] Step[7981 / 19085] - loss: 7.161827  \n",
      "Train Epoch[3] Step[8001 / 19085] - loss: 5.714700  \n",
      "Train Epoch[3] Step[8021 / 19085] - loss: 4.059915  \n",
      "Train Epoch[3] Step[8041 / 19085] - loss: 10.669031  \n",
      "Train Epoch[3] Step[8061 / 19085] - loss: 5.173002  \n",
      "Train Epoch[3] Step[8081 / 19085] - loss: 8.983742  \n",
      "Train Epoch[3] Step[8101 / 19085] - loss: 5.360436  \n",
      "Train Epoch[3] Step[8121 / 19085] - loss: 4.713260  \n",
      "Train Epoch[3] Step[8141 / 19085] - loss: 4.124542  \n",
      "Train Epoch[3] Step[8161 / 19085] - loss: 4.405123  \n",
      "Train Epoch[3] Step[8181 / 19085] - loss: 5.842494  \n",
      "Train Epoch[3] Step[8201 / 19085] - loss: 4.613543  \n",
      "Train Epoch[3] Step[8221 / 19085] - loss: 6.621917  \n",
      "Train Epoch[3] Step[8241 / 19085] - loss: 9.672564  \n",
      "Train Epoch[3] Step[8261 / 19085] - loss: 8.276757  \n",
      "Train Epoch[3] Step[8281 / 19085] - loss: 7.104981  \n",
      "Train Epoch[3] Step[8301 / 19085] - loss: 8.885693  \n",
      "Train Epoch[3] Step[8321 / 19085] - loss: 5.542779  \n",
      "Train Epoch[3] Step[8341 / 19085] - loss: 2.650112  \n",
      "Train Epoch[3] Step[8361 / 19085] - loss: 5.757589  \n",
      "Train Epoch[3] Step[8381 / 19085] - loss: 3.493312  \n",
      "Train Epoch[3] Step[8401 / 19085] - loss: 6.891435  \n",
      "Train Epoch[3] Step[8421 / 19085] - loss: 9.669239  \n",
      "Train Epoch[3] Step[8441 / 19085] - loss: 6.092971  \n",
      "Train Epoch[3] Step[8461 / 19085] - loss: 5.196450  \n",
      "Train Epoch[3] Step[8481 / 19085] - loss: 2.921224  \n",
      "Train Epoch[3] Step[8501 / 19085] - loss: 6.510941  \n",
      "Train Epoch[3] Step[8521 / 19085] - loss: 4.219291  \n",
      "Train Epoch[3] Step[8541 / 19085] - loss: 6.734789  \n",
      "Train Epoch[3] Step[8561 / 19085] - loss: 3.456385  \n",
      "Train Epoch[3] Step[8581 / 19085] - loss: 7.281475  \n",
      "Train Epoch[3] Step[8601 / 19085] - loss: 3.888754  \n",
      "Train Epoch[3] Step[8621 / 19085] - loss: 7.572761  \n",
      "Train Epoch[3] Step[8641 / 19085] - loss: 4.326885  \n",
      "Train Epoch[3] Step[8661 / 19085] - loss: 7.181858  \n",
      "Train Epoch[3] Step[8681 / 19085] - loss: 3.761230  \n",
      "Train Epoch[3] Step[8701 / 19085] - loss: 4.766143  \n",
      "Train Epoch[3] Step[8721 / 19085] - loss: 8.025854  \n",
      "Train Epoch[3] Step[8741 / 19085] - loss: 8.622695  \n",
      "Train Epoch[3] Step[8761 / 19085] - loss: 5.159538  \n",
      "Train Epoch[3] Step[8781 / 19085] - loss: 7.502884  \n",
      "Train Epoch[3] Step[8801 / 19085] - loss: 7.493546  \n",
      "Train Epoch[3] Step[8821 / 19085] - loss: 5.285112  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:20<00:00, 14.90it/s]\n",
      "Dev Loss: 6.189749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7069    0.5501    0.6187     26118\n",
      "         ORG     0.0714    0.0010    0.0020      1956\n",
      "         PER     0.6809    0.5282    0.5949     22839\n",
      "           T     0.7937    0.5777    0.6687     22956\n",
      "\n",
      "   micro avg     0.7246    0.5374    0.6171     73869\n",
      "   macro avg     0.5632    0.4142    0.4711     73869\n",
      "weighted avg     0.7090    0.5374    0.6105     73869\n",
      "\n",
      "best f1: 0.61, current f1: 0.62\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[8841 / 19085] - loss: 5.994319  \n",
      "Train Epoch[3] Step[8861 / 19085] - loss: 5.388192  \n",
      "Train Epoch[3] Step[8881 / 19085] - loss: 10.374519  \n",
      "Train Epoch[3] Step[8901 / 19085] - loss: 7.487226  \n",
      "Train Epoch[3] Step[8921 / 19085] - loss: 6.517095  \n",
      "Train Epoch[3] Step[8941 / 19085] - loss: 6.899464  \n",
      "Train Epoch[3] Step[8961 / 19085] - loss: 3.551812  \n",
      "Train Epoch[3] Step[8981 / 19085] - loss: 7.154408  \n",
      "Train Epoch[3] Step[9001 / 19085] - loss: 5.671349  \n",
      "Train Epoch[3] Step[9021 / 19085] - loss: 8.658566  \n",
      "Train Epoch[3] Step[9041 / 19085] - loss: 5.231591  \n",
      "Train Epoch[3] Step[9061 / 19085] - loss: 7.632198  \n",
      "Train Epoch[3] Step[9081 / 19085] - loss: 5.392276  \n",
      "Train Epoch[3] Step[9101 / 19085] - loss: 6.725403  \n",
      "Train Epoch[3] Step[9121 / 19085] - loss: 3.620347  \n",
      "Train Epoch[3] Step[9141 / 19085] - loss: 7.114250  \n",
      "Train Epoch[3] Step[9161 / 19085] - loss: 7.617102  \n",
      "Train Epoch[3] Step[9181 / 19085] - loss: 7.821736  \n",
      "Train Epoch[3] Step[9201 / 19085] - loss: 3.704950  \n",
      "Train Epoch[3] Step[9221 / 19085] - loss: 3.704096  \n",
      "Train Epoch[3] Step[9241 / 19085] - loss: 5.442312  \n",
      "Train Epoch[3] Step[9261 / 19085] - loss: 5.391378  \n",
      "Train Epoch[3] Step[9281 / 19085] - loss: 5.925019  \n",
      "Train Epoch[3] Step[9301 / 19085] - loss: 4.710645  \n",
      "Train Epoch[3] Step[9321 / 19085] - loss: 5.386043  \n",
      "Train Epoch[3] Step[9341 / 19085] - loss: 7.330778  \n",
      "Train Epoch[3] Step[9361 / 19085] - loss: 4.462207  \n",
      "Train Epoch[3] Step[9381 / 19085] - loss: 7.048257  \n",
      "Train Epoch[3] Step[9401 / 19085] - loss: 9.936452  \n",
      "Train Epoch[3] Step[9421 / 19085] - loss: 4.507552  \n",
      "Train Epoch[3] Step[9441 / 19085] - loss: 4.159293  \n",
      "Train Epoch[3] Step[9461 / 19085] - loss: 6.719169  \n",
      "Train Epoch[3] Step[9481 / 19085] - loss: 5.103548  \n",
      "Train Epoch[3] Step[9501 / 19085] - loss: 10.244860  \n",
      "Train Epoch[3] Step[9521 / 19085] - loss: 3.424908  \n",
      "Train Epoch[3] Step[9541 / 19085] - loss: 4.274586  \n",
      "Train Epoch[3] Step[9561 / 19085] - loss: 3.217063  \n",
      "Train Epoch[3] Step[9581 / 19085] - loss: 5.549860  \n",
      "Train Epoch[3] Step[9601 / 19085] - loss: 3.266553  \n",
      "Train Epoch[3] Step[9621 / 19085] - loss: 7.616001  \n",
      "Train Epoch[3] Step[9641 / 19085] - loss: 4.224156  \n",
      "Train Epoch[3] Step[9661 / 19085] - loss: 7.289411  \n",
      "Train Epoch[3] Step[9681 / 19085] - loss: 4.262247  \n",
      "Train Epoch[3] Step[9701 / 19085] - loss: 7.124036  \n",
      "Train Epoch[3] Step[9721 / 19085] - loss: 7.412094  \n",
      "Train Epoch[3] Step[9741 / 19085] - loss: 9.806368  \n",
      "Train Epoch[3] Step[9761 / 19085] - loss: 6.365776  \n",
      "Train Epoch[3] Step[9781 / 19085] - loss: 10.283344  \n",
      "Train Epoch[3] Step[9801 / 19085] - loss: 7.097820  \n",
      "Train Epoch[3] Step[9821 / 19085] - loss: 7.534437  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:21<00:00, 14.82it/s]\n",
      "Dev Loss: 6.155992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7216    0.5228    0.6063     26118\n",
      "         ORG     0.1481    0.0041    0.0080      1956\n",
      "         PER     0.6987    0.5104    0.5898     22839\n",
      "           T     0.7935    0.5889    0.6761     22956\n",
      "\n",
      "   micro avg     0.7370    0.5258    0.6137     73869\n",
      "   macro avg     0.5905    0.4065    0.4700     73869\n",
      "weighted avg     0.7217    0.5258    0.6070     73869\n",
      "\n",
      "best f1: 0.62, current f1: 0.61\n",
      "\n",
      "Train Epoch[3] Step[9841 / 19085] - loss: 3.356336  \n",
      "Train Epoch[3] Step[9861 / 19085] - loss: 4.100308  \n",
      "Train Epoch[3] Step[9881 / 19085] - loss: 4.942352  \n",
      "Train Epoch[3] Step[9901 / 19085] - loss: 7.275420  \n",
      "Train Epoch[3] Step[9921 / 19085] - loss: 6.787708  \n",
      "Train Epoch[3] Step[9941 / 19085] - loss: 7.309267  \n",
      "Train Epoch[3] Step[9961 / 19085] - loss: 4.689307  \n",
      "Train Epoch[3] Step[9981 / 19085] - loss: 8.183619  \n",
      "Train Epoch[3] Step[10001 / 19085] - loss: 7.434105  \n",
      "Train Epoch[3] Step[10021 / 19085] - loss: 10.709366  \n",
      "Train Epoch[3] Step[10041 / 19085] - loss: 3.255753  \n",
      "Train Epoch[3] Step[10061 / 19085] - loss: 10.322394  \n",
      "Train Epoch[3] Step[10081 / 19085] - loss: 7.591301  \n",
      "Train Epoch[3] Step[10101 / 19085] - loss: 6.710194  \n",
      "Train Epoch[3] Step[10121 / 19085] - loss: 6.003273  \n",
      "Train Epoch[3] Step[10141 / 19085] - loss: 3.449225  \n",
      "Train Epoch[3] Step[10161 / 19085] - loss: 4.264501  \n",
      "Train Epoch[3] Step[10181 / 19085] - loss: 3.828347  \n",
      "Train Epoch[3] Step[10201 / 19085] - loss: 4.118956  \n",
      "Train Epoch[3] Step[10221 / 19085] - loss: 4.454868  \n",
      "Train Epoch[3] Step[10241 / 19085] - loss: 7.426401  \n",
      "Train Epoch[3] Step[10261 / 19085] - loss: 5.908318  \n",
      "Train Epoch[3] Step[10281 / 19085] - loss: 5.820193  \n",
      "Train Epoch[3] Step[10301 / 19085] - loss: 4.704885  \n",
      "Train Epoch[3] Step[10321 / 19085] - loss: 13.368498  \n",
      "Train Epoch[3] Step[10341 / 19085] - loss: 6.429956  \n",
      "Train Epoch[3] Step[10361 / 19085] - loss: 5.247857  \n",
      "Train Epoch[3] Step[10381 / 19085] - loss: 7.033443  \n",
      "Train Epoch[3] Step[10401 / 19085] - loss: 5.343576  \n",
      "Train Epoch[3] Step[10421 / 19085] - loss: 4.065963  \n",
      "Train Epoch[3] Step[10441 / 19085] - loss: 3.807494  \n",
      "Train Epoch[3] Step[10461 / 19085] - loss: 6.837483  \n",
      "Train Epoch[3] Step[10481 / 19085] - loss: 3.064928  \n",
      "Train Epoch[3] Step[10501 / 19085] - loss: 6.727666  \n",
      "Train Epoch[3] Step[10521 / 19085] - loss: 11.454741  \n",
      "Train Epoch[3] Step[10541 / 19085] - loss: 8.240601  \n",
      "Train Epoch[3] Step[10561 / 19085] - loss: 5.611103  \n",
      "Train Epoch[3] Step[10581 / 19085] - loss: 5.703979  \n",
      "Train Epoch[3] Step[10601 / 19085] - loss: 6.683223  \n",
      "Train Epoch[3] Step[10621 / 19085] - loss: 5.321754  \n",
      "Train Epoch[3] Step[10641 / 19085] - loss: 7.420483  \n",
      "Train Epoch[3] Step[10661 / 19085] - loss: 5.812030  \n",
      "Train Epoch[3] Step[10681 / 19085] - loss: 6.388103  \n",
      "Train Epoch[3] Step[10701 / 19085] - loss: 6.147161  \n",
      "Train Epoch[3] Step[10721 / 19085] - loss: 3.348247  \n",
      "Train Epoch[3] Step[10741 / 19085] - loss: 5.049877  \n",
      "Train Epoch[3] Step[10761 / 19085] - loss: 4.900448  \n",
      "Train Epoch[3] Step[10781 / 19085] - loss: 8.349922  \n",
      "Train Epoch[3] Step[10801 / 19085] - loss: 5.809693  \n",
      "Train Epoch[3] Step[10821 / 19085] - loss: 8.234341  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:17<00:00, 15.02it/s]\n",
      "Dev Loss: 6.037687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7162    0.5430    0.6177     26118\n",
      "         ORG     0.1746    0.0056    0.0109      1956\n",
      "         PER     0.6924    0.5458    0.6104     22839\n",
      "           T     0.7906    0.6038    0.6846     22956\n",
      "\n",
      "   micro avg     0.7314    0.5485    0.6269     73869\n",
      "   macro avg     0.5934    0.4245    0.4809     73869\n",
      "weighted avg     0.7176    0.5485    0.6202     73869\n",
      "\n",
      "best f1: 0.62, current f1: 0.63\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[10841 / 19085] - loss: 7.444733  \n",
      "Train Epoch[3] Step[10861 / 19085] - loss: 4.922160  \n",
      "Train Epoch[3] Step[10881 / 19085] - loss: 4.016861  \n",
      "Train Epoch[3] Step[10901 / 19085] - loss: 2.673350  \n",
      "Train Epoch[3] Step[10921 / 19085] - loss: 4.855798  \n",
      "Train Epoch[3] Step[10941 / 19085] - loss: 3.974581  \n",
      "Train Epoch[3] Step[10961 / 19085] - loss: 4.960706  \n",
      "Train Epoch[3] Step[10981 / 19085] - loss: 8.917831  \n",
      "Train Epoch[3] Step[11001 / 19085] - loss: 3.254978  \n",
      "Train Epoch[3] Step[11021 / 19085] - loss: 7.018774  \n",
      "Train Epoch[3] Step[11041 / 19085] - loss: 6.219982  \n",
      "Train Epoch[3] Step[11061 / 19085] - loss: 7.691232  \n",
      "Train Epoch[3] Step[11081 / 19085] - loss: 9.346413  \n",
      "Train Epoch[3] Step[11101 / 19085] - loss: 5.656486  \n",
      "Train Epoch[3] Step[11121 / 19085] - loss: 5.496499  \n",
      "Train Epoch[3] Step[11141 / 19085] - loss: 3.376508  \n",
      "Train Epoch[3] Step[11161 / 19085] - loss: 5.655886  \n",
      "Train Epoch[3] Step[11181 / 19085] - loss: 5.543698  \n",
      "Train Epoch[3] Step[11201 / 19085] - loss: 2.605063  \n",
      "Train Epoch[3] Step[11221 / 19085] - loss: 4.104961  \n",
      "Train Epoch[3] Step[11241 / 19085] - loss: 6.894463  \n",
      "Train Epoch[3] Step[11261 / 19085] - loss: 5.299686  \n",
      "Train Epoch[3] Step[11281 / 19085] - loss: 6.826012  \n",
      "Train Epoch[3] Step[11301 / 19085] - loss: 6.123977  \n",
      "Train Epoch[3] Step[11321 / 19085] - loss: 4.447009  \n",
      "Train Epoch[3] Step[11341 / 19085] - loss: 2.870571  \n",
      "Train Epoch[3] Step[11361 / 19085] - loss: 6.185937  \n",
      "Train Epoch[3] Step[11381 / 19085] - loss: 3.427011  \n",
      "Train Epoch[3] Step[11401 / 19085] - loss: 5.740128  \n",
      "Train Epoch[3] Step[11421 / 19085] - loss: 2.339051  \n",
      "Train Epoch[3] Step[11441 / 19085] - loss: 3.401564  \n",
      "Train Epoch[3] Step[11461 / 19085] - loss: 4.739881  \n",
      "Train Epoch[3] Step[11481 / 19085] - loss: 9.018517  \n",
      "Train Epoch[3] Step[11501 / 19085] - loss: 4.347733  \n",
      "Train Epoch[3] Step[11521 / 19085] - loss: 5.727569  \n",
      "Train Epoch[3] Step[11541 / 19085] - loss: 7.511396  \n",
      "Train Epoch[3] Step[11561 / 19085] - loss: 6.956089  \n",
      "Train Epoch[3] Step[11581 / 19085] - loss: 5.459037  \n",
      "Train Epoch[3] Step[11601 / 19085] - loss: 13.586637  \n",
      "Train Epoch[3] Step[11621 / 19085] - loss: 4.227091  \n",
      "Train Epoch[3] Step[11641 / 19085] - loss: 7.699621  \n",
      "Train Epoch[3] Step[11661 / 19085] - loss: 6.708764  \n",
      "Train Epoch[3] Step[11681 / 19085] - loss: 11.114933  \n",
      "Train Epoch[3] Step[11701 / 19085] - loss: 12.044725  \n",
      "Train Epoch[3] Step[11721 / 19085] - loss: 9.863063  \n",
      "Train Epoch[3] Step[11741 / 19085] - loss: 6.534262  \n",
      "Train Epoch[3] Step[11761 / 19085] - loss: 9.610592  \n",
      "Train Epoch[3] Step[11781 / 19085] - loss: 8.481021  \n",
      "Train Epoch[3] Step[11801 / 19085] - loss: 4.682673  \n",
      "Train Epoch[3] Step[11821 / 19085] - loss: 6.298988  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:20<00:00, 14.88it/s]\n",
      "Dev Loss: 6.049249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7151    0.5362    0.6129     26118\n",
      "         ORG     0.1579    0.0031    0.0060      1956\n",
      "         PER     0.7117    0.5008    0.5879     22839\n",
      "           T     0.7967    0.5846    0.6744     22956\n",
      "\n",
      "   micro avg     0.7398    0.5262    0.6150     73869\n",
      "   macro avg     0.5953    0.4062    0.4703     73869\n",
      "weighted avg     0.7246    0.5262    0.6082     73869\n",
      "\n",
      "best f1: 0.63, current f1: 0.61\n",
      "\n",
      "Train Epoch[3] Step[11841 / 19085] - loss: 7.429521  \n",
      "Train Epoch[3] Step[11861 / 19085] - loss: 3.948680  \n",
      "Train Epoch[3] Step[11881 / 19085] - loss: 2.017993  \n",
      "Train Epoch[3] Step[11901 / 19085] - loss: 4.566566  \n",
      "Train Epoch[3] Step[11921 / 19085] - loss: 7.444468  \n",
      "Train Epoch[3] Step[11941 / 19085] - loss: 5.068274  \n",
      "Train Epoch[3] Step[11961 / 19085] - loss: 5.337659  \n",
      "Train Epoch[3] Step[11981 / 19085] - loss: 5.176629  \n",
      "Train Epoch[3] Step[12001 / 19085] - loss: 7.037359  \n",
      "Train Epoch[3] Step[12021 / 19085] - loss: 7.472440  \n",
      "Train Epoch[3] Step[12041 / 19085] - loss: 3.456057  \n",
      "Train Epoch[3] Step[12061 / 19085] - loss: 4.687585  \n",
      "Train Epoch[3] Step[12081 / 19085] - loss: 5.575912  \n",
      "Train Epoch[3] Step[12101 / 19085] - loss: 7.075724  \n",
      "Train Epoch[3] Step[12121 / 19085] - loss: 8.861251  \n",
      "Train Epoch[3] Step[12141 / 19085] - loss: 2.653887  \n",
      "Train Epoch[3] Step[12161 / 19085] - loss: 7.503446  \n",
      "Train Epoch[3] Step[12181 / 19085] - loss: 3.663661  \n",
      "Train Epoch[3] Step[12201 / 19085] - loss: 2.283304  \n",
      "Train Epoch[3] Step[12221 / 19085] - loss: 4.121441  \n",
      "Train Epoch[3] Step[12241 / 19085] - loss: 3.974477  \n",
      "Train Epoch[3] Step[12261 / 19085] - loss: 4.275617  \n",
      "Train Epoch[3] Step[12281 / 19085] - loss: 6.944009  \n",
      "Train Epoch[3] Step[12301 / 19085] - loss: 6.174127  \n",
      "Train Epoch[3] Step[12321 / 19085] - loss: 5.821994  \n",
      "Train Epoch[3] Step[12341 / 19085] - loss: 4.219735  \n",
      "Train Epoch[3] Step[12361 / 19085] - loss: 6.527630  \n",
      "Train Epoch[3] Step[12381 / 19085] - loss: 2.913723  \n",
      "Train Epoch[3] Step[12401 / 19085] - loss: 4.766039  \n",
      "Train Epoch[3] Step[12421 / 19085] - loss: 3.539866  \n",
      "Train Epoch[3] Step[12441 / 19085] - loss: 4.559408  \n",
      "Train Epoch[3] Step[12461 / 19085] - loss: 3.963841  \n",
      "Train Epoch[3] Step[12481 / 19085] - loss: 5.276459  \n",
      "Train Epoch[3] Step[12501 / 19085] - loss: 3.906832  \n",
      "Train Epoch[3] Step[12521 / 19085] - loss: 9.827321  \n",
      "Train Epoch[3] Step[12541 / 19085] - loss: 9.546341  \n",
      "Train Epoch[3] Step[12561 / 19085] - loss: 8.708758  \n",
      "Train Epoch[3] Step[12581 / 19085] - loss: 5.097819  \n",
      "Train Epoch[3] Step[12601 / 19085] - loss: 6.810668  \n",
      "Train Epoch[3] Step[12621 / 19085] - loss: 5.852138  \n",
      "Train Epoch[3] Step[12641 / 19085] - loss: 9.338989  \n",
      "Train Epoch[3] Step[12661 / 19085] - loss: 4.653949  \n",
      "Train Epoch[3] Step[12681 / 19085] - loss: 5.415382  \n",
      "Train Epoch[3] Step[12701 / 19085] - loss: 9.935453  \n",
      "Train Epoch[3] Step[12721 / 19085] - loss: 3.243535  \n",
      "Train Epoch[3] Step[12741 / 19085] - loss: 6.177341  \n",
      "Train Epoch[3] Step[12761 / 19085] - loss: 8.786922  \n",
      "Train Epoch[3] Step[12781 / 19085] - loss: 5.471212  \n",
      "Train Epoch[3] Step[12801 / 19085] - loss: 4.028086  \n",
      "Train Epoch[3] Step[12821 / 19085] - loss: 4.490792  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:22<00:00, 14.78it/s]\n",
      "Dev Loss: 5.961941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7193    0.5407    0.6174     26118\n",
      "         ORG     0.1800    0.0046    0.0090      1956\n",
      "         PER     0.7039    0.5324    0.6062     22839\n",
      "           T     0.7971    0.5738    0.6673     22956\n",
      "\n",
      "   micro avg     0.7379    0.5342    0.6197     73869\n",
      "   macro avg     0.6001    0.4129    0.4750     73869\n",
      "weighted avg     0.7244    0.5342    0.6133     73869\n",
      "\n",
      "best f1: 0.63, current f1: 0.62\n",
      "\n",
      "Train Epoch[3] Step[12841 / 19085] - loss: 4.813238  \n",
      "Train Epoch[3] Step[12861 / 19085] - loss: 6.259162  \n",
      "Train Epoch[3] Step[12881 / 19085] - loss: 4.940638  \n",
      "Train Epoch[3] Step[12901 / 19085] - loss: 5.808964  \n",
      "Train Epoch[3] Step[12921 / 19085] - loss: 1.581287  \n",
      "Train Epoch[3] Step[12941 / 19085] - loss: 5.633900  \n",
      "Train Epoch[3] Step[12961 / 19085] - loss: 5.897560  \n",
      "Train Epoch[3] Step[12981 / 19085] - loss: 8.143877  \n",
      "Train Epoch[3] Step[13001 / 19085] - loss: 6.798334  \n",
      "Train Epoch[3] Step[13021 / 19085] - loss: 8.844897  \n",
      "Train Epoch[3] Step[13041 / 19085] - loss: 7.851596  \n",
      "Train Epoch[3] Step[13061 / 19085] - loss: 7.247785  \n",
      "Train Epoch[3] Step[13081 / 19085] - loss: 5.973804  \n",
      "Train Epoch[3] Step[13101 / 19085] - loss: 6.285587  \n",
      "Train Epoch[3] Step[13121 / 19085] - loss: 7.892996  \n",
      "Train Epoch[3] Step[13141 / 19085] - loss: 4.825272  \n",
      "Train Epoch[3] Step[13161 / 19085] - loss: 5.419656  \n",
      "Train Epoch[3] Step[13181 / 19085] - loss: 7.708149  \n",
      "Train Epoch[3] Step[13201 / 19085] - loss: 5.503539  \n",
      "Train Epoch[3] Step[13221 / 19085] - loss: 2.936751  \n",
      "Train Epoch[3] Step[13241 / 19085] - loss: 3.114913  \n",
      "Train Epoch[3] Step[13261 / 19085] - loss: 10.930542  \n",
      "Train Epoch[3] Step[13281 / 19085] - loss: 7.224105  \n",
      "Train Epoch[3] Step[13301 / 19085] - loss: 5.668239  \n",
      "Train Epoch[3] Step[13321 / 19085] - loss: 11.436579  \n",
      "Train Epoch[3] Step[13341 / 19085] - loss: 4.216833  \n",
      "Train Epoch[3] Step[13361 / 19085] - loss: 3.988299  \n",
      "Train Epoch[3] Step[13381 / 19085] - loss: 5.829403  \n",
      "Train Epoch[3] Step[13401 / 19085] - loss: 5.611141  \n",
      "Train Epoch[3] Step[13421 / 19085] - loss: 12.506769  \n",
      "Train Epoch[3] Step[13441 / 19085] - loss: 6.875770  \n",
      "Train Epoch[3] Step[13461 / 19085] - loss: 7.655122  \n",
      "Train Epoch[3] Step[13481 / 19085] - loss: 6.226560  \n",
      "Train Epoch[3] Step[13501 / 19085] - loss: 5.085277  \n",
      "Train Epoch[3] Step[13521 / 19085] - loss: 7.278534  \n",
      "Train Epoch[3] Step[13541 / 19085] - loss: 7.968949  \n",
      "Train Epoch[3] Step[13561 / 19085] - loss: 6.216788  \n",
      "Train Epoch[3] Step[13581 / 19085] - loss: 8.089369  \n",
      "Train Epoch[3] Step[13601 / 19085] - loss: 5.156868  \n",
      "Train Epoch[3] Step[13621 / 19085] - loss: 4.567226  \n",
      "Train Epoch[3] Step[13641 / 19085] - loss: 2.186059  \n",
      "Train Epoch[3] Step[13661 / 19085] - loss: 3.227591  \n",
      "Train Epoch[3] Step[13681 / 19085] - loss: 5.300954  \n",
      "Train Epoch[3] Step[13701 / 19085] - loss: 8.310283  \n",
      "Train Epoch[3] Step[13721 / 19085] - loss: 2.842399  \n",
      "Train Epoch[3] Step[13741 / 19085] - loss: 5.684733  \n",
      "Train Epoch[3] Step[13761 / 19085] - loss: 2.619825  \n",
      "Train Epoch[3] Step[13781 / 19085] - loss: 5.736085  \n",
      "Train Epoch[3] Step[13801 / 19085] - loss: 5.355314  \n",
      "Train Epoch[3] Step[13821 / 19085] - loss: 4.429870  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:18<00:00, 14.96it/s]\n",
      "Dev Loss: 5.897860\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7212    0.5407    0.6181     26118\n",
      "         ORG     0.1923    0.0051    0.0100      1956\n",
      "         PER     0.7067    0.5348    0.6088     22839\n",
      "           T     0.8012    0.6022    0.6876     22956\n",
      "\n",
      "   micro avg     0.7416    0.5438    0.6275     73869\n",
      "   macro avg     0.6054    0.4207    0.4811     73869\n",
      "weighted avg     0.7276    0.5438    0.6207     73869\n",
      "\n",
      "best f1: 0.63, current f1: 0.63\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[13841 / 19085] - loss: 6.185225  \n",
      "Train Epoch[3] Step[13861 / 19085] - loss: 8.799075  \n",
      "Train Epoch[3] Step[13881 / 19085] - loss: 4.509772  \n",
      "Train Epoch[3] Step[13901 / 19085] - loss: 3.496444  \n",
      "Train Epoch[3] Step[13921 / 19085] - loss: 8.725032  \n",
      "Train Epoch[3] Step[13941 / 19085] - loss: 6.814359  \n",
      "Train Epoch[3] Step[13961 / 19085] - loss: 12.989428  \n",
      "Train Epoch[3] Step[13981 / 19085] - loss: 5.590107  \n",
      "Train Epoch[3] Step[14001 / 19085] - loss: 2.042856  \n",
      "Train Epoch[3] Step[14021 / 19085] - loss: 7.193857  \n",
      "Train Epoch[3] Step[14041 / 19085] - loss: 8.875370  \n",
      "Train Epoch[3] Step[14061 / 19085] - loss: 9.819510  \n",
      "Train Epoch[3] Step[14081 / 19085] - loss: 8.001493  \n",
      "Train Epoch[3] Step[14101 / 19085] - loss: 4.007175  \n",
      "Train Epoch[3] Step[14121 / 19085] - loss: 4.417586  \n",
      "Train Epoch[3] Step[14141 / 19085] - loss: 7.459848  \n",
      "Train Epoch[3] Step[14161 / 19085] - loss: 5.800308  \n",
      "Train Epoch[3] Step[14181 / 19085] - loss: 4.747907  \n",
      "Train Epoch[3] Step[14201 / 19085] - loss: 4.525259  \n",
      "Train Epoch[3] Step[14221 / 19085] - loss: 6.218261  \n",
      "Train Epoch[3] Step[14241 / 19085] - loss: 4.203786  \n",
      "Train Epoch[3] Step[14261 / 19085] - loss: 10.814646  \n",
      "Train Epoch[3] Step[14281 / 19085] - loss: 6.770782  \n",
      "Train Epoch[3] Step[14301 / 19085] - loss: 7.839573  \n",
      "Train Epoch[3] Step[14321 / 19085] - loss: 3.361503  \n",
      "Train Epoch[3] Step[14341 / 19085] - loss: 5.705188  \n",
      "Train Epoch[3] Step[14361 / 19085] - loss: 3.356879  \n",
      "Train Epoch[3] Step[14381 / 19085] - loss: 4.013443  \n",
      "Train Epoch[3] Step[14401 / 19085] - loss: 7.772496  \n",
      "Train Epoch[3] Step[14421 / 19085] - loss: 7.789585  \n",
      "Train Epoch[3] Step[14441 / 19085] - loss: 3.637423  \n",
      "Train Epoch[3] Step[14461 / 19085] - loss: 3.417941  \n",
      "Train Epoch[3] Step[14481 / 19085] - loss: 3.501200  \n",
      "Train Epoch[3] Step[14501 / 19085] - loss: 6.072441  \n",
      "Train Epoch[3] Step[14521 / 19085] - loss: 4.621781  \n",
      "Train Epoch[3] Step[14541 / 19085] - loss: 2.097348  \n",
      "Train Epoch[3] Step[14561 / 19085] - loss: 4.141818  \n",
      "Train Epoch[3] Step[14581 / 19085] - loss: 6.684614  \n",
      "Train Epoch[3] Step[14601 / 19085] - loss: 4.014133  \n",
      "Train Epoch[3] Step[14621 / 19085] - loss: 2.618971  \n",
      "Train Epoch[3] Step[14641 / 19085] - loss: 6.451193  \n",
      "Train Epoch[3] Step[14661 / 19085] - loss: 8.141882  \n",
      "Train Epoch[3] Step[14681 / 19085] - loss: 1.177010  \n",
      "Train Epoch[3] Step[14701 / 19085] - loss: 6.371524  \n",
      "Train Epoch[3] Step[14721 / 19085] - loss: 9.293226  \n",
      "Train Epoch[3] Step[14741 / 19085] - loss: 12.248007  \n",
      "Train Epoch[3] Step[14761 / 19085] - loss: 10.614589  \n",
      "Train Epoch[3] Step[14781 / 19085] - loss: 7.408639  \n",
      "Train Epoch[3] Step[14801 / 19085] - loss: 5.845489  \n",
      "Train Epoch[3] Step[14821 / 19085] - loss: 13.222025  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:20<00:00, 14.90it/s]\n",
      "Dev Loss: 5.830726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7132    0.5559    0.6248     26118\n",
      "         ORG     0.2683    0.0056    0.0110      1956\n",
      "         PER     0.7199    0.5326    0.6123     22839\n",
      "           T     0.7984    0.6008    0.6857     22956\n",
      "\n",
      "   micro avg     0.7419    0.5481    0.6304     73869\n",
      "   macro avg     0.6250    0.4237    0.4834     73869\n",
      "weighted avg     0.7300    0.5481    0.6236     73869\n",
      "\n",
      "best f1: 0.63, current f1: 0.63\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[14841 / 19085] - loss: 7.607317  \n",
      "Train Epoch[3] Step[14861 / 19085] - loss: 12.159948  \n",
      "Train Epoch[3] Step[14881 / 19085] - loss: 3.727992  \n",
      "Train Epoch[3] Step[14901 / 19085] - loss: 6.157639  \n",
      "Train Epoch[3] Step[14921 / 19085] - loss: 6.791823  \n",
      "Train Epoch[3] Step[14941 / 19085] - loss: 6.242694  \n",
      "Train Epoch[3] Step[14961 / 19085] - loss: 2.692500  \n",
      "Train Epoch[3] Step[14981 / 19085] - loss: 4.488625  \n",
      "Train Epoch[3] Step[15001 / 19085] - loss: 5.732575  \n",
      "Train Epoch[3] Step[15021 / 19085] - loss: 3.929999  \n",
      "Train Epoch[3] Step[15041 / 19085] - loss: 6.013764  \n",
      "Train Epoch[3] Step[15061 / 19085] - loss: 3.780881  \n",
      "Train Epoch[3] Step[15081 / 19085] - loss: 4.715066  \n",
      "Train Epoch[3] Step[15101 / 19085] - loss: 6.718928  \n",
      "Train Epoch[3] Step[15121 / 19085] - loss: 5.971741  \n",
      "Train Epoch[3] Step[15141 / 19085] - loss: 5.784906  \n",
      "Train Epoch[3] Step[15161 / 19085] - loss: 7.530738  \n",
      "Train Epoch[3] Step[15181 / 19085] - loss: 4.092276  \n",
      "Train Epoch[3] Step[15201 / 19085] - loss: 4.834341  \n",
      "Train Epoch[3] Step[15221 / 19085] - loss: 8.777400  \n",
      "Train Epoch[3] Step[15241 / 19085] - loss: 9.152396  \n",
      "Train Epoch[3] Step[15261 / 19085] - loss: 5.357628  \n",
      "Train Epoch[3] Step[15281 / 19085] - loss: 4.671239  \n",
      "Train Epoch[3] Step[15301 / 19085] - loss: 5.385624  \n",
      "Train Epoch[3] Step[15321 / 19085] - loss: 3.817196  \n",
      "Train Epoch[3] Step[15341 / 19085] - loss: 4.875505  \n",
      "Train Epoch[3] Step[15361 / 19085] - loss: 5.685879  \n",
      "Train Epoch[3] Step[15381 / 19085] - loss: 7.760934  \n",
      "Train Epoch[3] Step[15401 / 19085] - loss: 4.739552  \n",
      "Train Epoch[3] Step[15421 / 19085] - loss: 4.717949  \n",
      "Train Epoch[3] Step[15441 / 19085] - loss: 3.849655  \n",
      "Train Epoch[3] Step[15461 / 19085] - loss: 3.967725  \n",
      "Train Epoch[3] Step[15481 / 19085] - loss: 6.000913  \n",
      "Train Epoch[3] Step[15501 / 19085] - loss: 4.436502  \n",
      "Train Epoch[3] Step[15521 / 19085] - loss: 3.701683  \n",
      "Train Epoch[3] Step[15541 / 19085] - loss: 6.796075  \n",
      "Train Epoch[3] Step[15561 / 19085] - loss: 7.472275  \n",
      "Train Epoch[3] Step[15581 / 19085] - loss: 1.999499  \n",
      "Train Epoch[3] Step[15601 / 19085] - loss: 4.950627  \n",
      "Train Epoch[3] Step[15621 / 19085] - loss: 4.861032  \n",
      "Train Epoch[3] Step[15641 / 19085] - loss: 4.177971  \n",
      "Train Epoch[3] Step[15661 / 19085] - loss: 8.809673  \n",
      "Train Epoch[3] Step[15681 / 19085] - loss: 5.720318  \n",
      "Train Epoch[3] Step[15701 / 19085] - loss: 6.660203  \n",
      "Train Epoch[3] Step[15721 / 19085] - loss: 3.368979  \n",
      "Train Epoch[3] Step[15741 / 19085] - loss: 2.442667  \n",
      "Train Epoch[3] Step[15761 / 19085] - loss: 6.494141  \n",
      "Train Epoch[3] Step[15781 / 19085] - loss: 5.606966  \n",
      "Train Epoch[3] Step[15801 / 19085] - loss: 8.880886  \n",
      "Train Epoch[3] Step[15821 / 19085] - loss: 6.630666  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:20<00:00, 14.90it/s]\n",
      "Dev Loss: 5.775069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7175    0.5558    0.6264     26118\n",
      "         ORG     0.2381    0.0051    0.0100      1956\n",
      "         PER     0.7141    0.5557    0.6250     22839\n",
      "           T     0.8015    0.5936    0.6820     22956\n",
      "\n",
      "   micro avg     0.7420    0.5529    0.6337     73869\n",
      "   macro avg     0.6178    0.4276    0.4859     73869\n",
      "weighted avg     0.7299    0.5529    0.6269     73869\n",
      "\n",
      "best f1: 0.63, current f1: 0.63\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[15841 / 19085] - loss: 2.816751  \n",
      "Train Epoch[3] Step[15861 / 19085] - loss: 6.991216  \n",
      "Train Epoch[3] Step[15881 / 19085] - loss: 9.545233  \n",
      "Train Epoch[3] Step[15901 / 19085] - loss: 2.950878  \n",
      "Train Epoch[3] Step[15921 / 19085] - loss: 4.971272  \n",
      "Train Epoch[3] Step[15941 / 19085] - loss: 5.737270  \n",
      "Train Epoch[3] Step[15961 / 19085] - loss: 3.988075  \n",
      "Train Epoch[3] Step[15981 / 19085] - loss: 3.752000  \n",
      "Train Epoch[3] Step[16001 / 19085] - loss: 2.423254  \n",
      "Train Epoch[3] Step[16021 / 19085] - loss: 6.974584  \n",
      "Train Epoch[3] Step[16041 / 19085] - loss: 8.954327  \n",
      "Train Epoch[3] Step[16061 / 19085] - loss: 2.685843  \n",
      "Train Epoch[3] Step[16081 / 19085] - loss: 5.909113  \n",
      "Train Epoch[3] Step[16101 / 19085] - loss: 5.042887  \n",
      "Train Epoch[3] Step[16121 / 19085] - loss: 4.372163  \n",
      "Train Epoch[3] Step[16141 / 19085] - loss: 4.029183  \n",
      "Train Epoch[3] Step[16161 / 19085] - loss: 9.492916  \n",
      "Train Epoch[3] Step[16181 / 19085] - loss: 11.384456  \n",
      "Train Epoch[3] Step[16201 / 19085] - loss: 3.957903  \n",
      "Train Epoch[3] Step[16221 / 19085] - loss: 9.111090  \n",
      "Train Epoch[3] Step[16241 / 19085] - loss: 4.007192  \n",
      "Train Epoch[3] Step[16261 / 19085] - loss: 6.242427  \n",
      "Train Epoch[3] Step[16281 / 19085] - loss: 6.546823  \n",
      "Train Epoch[3] Step[16301 / 19085] - loss: 2.732187  \n",
      "Train Epoch[3] Step[16321 / 19085] - loss: 3.605999  \n",
      "Train Epoch[3] Step[16341 / 19085] - loss: 2.555156  \n",
      "Train Epoch[3] Step[16361 / 19085] - loss: 4.556901  \n",
      "Train Epoch[3] Step[16381 / 19085] - loss: 5.102484  \n",
      "Train Epoch[3] Step[16401 / 19085] - loss: 6.196117  \n",
      "Train Epoch[3] Step[16421 / 19085] - loss: 5.943269  \n",
      "Train Epoch[3] Step[16441 / 19085] - loss: 7.821879  \n",
      "Train Epoch[3] Step[16461 / 19085] - loss: 9.599615  \n",
      "Train Epoch[3] Step[16481 / 19085] - loss: 8.727237  \n",
      "Train Epoch[3] Step[16501 / 19085] - loss: 9.242695  \n",
      "Train Epoch[3] Step[16521 / 19085] - loss: 4.350530  \n",
      "Train Epoch[3] Step[16541 / 19085] - loss: 6.321479  \n",
      "Train Epoch[3] Step[16561 / 19085] - loss: 9.080849  \n",
      "Train Epoch[3] Step[16581 / 19085] - loss: 4.325727  \n",
      "Train Epoch[3] Step[16601 / 19085] - loss: 8.279583  \n",
      "Train Epoch[3] Step[16621 / 19085] - loss: 5.070134  \n",
      "Train Epoch[3] Step[16641 / 19085] - loss: 3.396757  \n",
      "Train Epoch[3] Step[16661 / 19085] - loss: 7.220932  \n",
      "Train Epoch[3] Step[16681 / 19085] - loss: 4.586068  \n",
      "Train Epoch[3] Step[16701 / 19085] - loss: 5.056728  \n",
      "Train Epoch[3] Step[16721 / 19085] - loss: 6.364592  \n",
      "Train Epoch[3] Step[16741 / 19085] - loss: 6.635448  \n",
      "Train Epoch[3] Step[16761 / 19085] - loss: 5.691434  \n",
      "Train Epoch[3] Step[16781 / 19085] - loss: 6.789186  \n",
      "Train Epoch[3] Step[16801 / 19085] - loss: 4.275680  \n",
      "Train Epoch[3] Step[16821 / 19085] - loss: 4.808982  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:19<00:00, 14.95it/s]\n",
      "Dev Loss: 5.704535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7153    0.5625    0.6298     26118\n",
      "         ORG     0.3678    0.0164    0.0313      1956\n",
      "         PER     0.7238    0.5483    0.6239     22839\n",
      "           T     0.7963    0.6135    0.6930     22956\n",
      "\n",
      "   micro avg     0.7432    0.5595    0.6384     73869\n",
      "   macro avg     0.6508    0.4351    0.4945     73869\n",
      "weighted avg     0.7339    0.5595    0.6318     73869\n",
      "\n",
      "best f1: 0.63, current f1: 0.64\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[16841 / 19085] - loss: 7.675319  \n",
      "Train Epoch[3] Step[16861 / 19085] - loss: 4.887481  \n",
      "Train Epoch[3] Step[16881 / 19085] - loss: 4.578475  \n",
      "Train Epoch[3] Step[16901 / 19085] - loss: 7.778131  \n",
      "Train Epoch[3] Step[16921 / 19085] - loss: 8.865385  \n",
      "Train Epoch[3] Step[16941 / 19085] - loss: 9.882123  \n",
      "Train Epoch[3] Step[16961 / 19085] - loss: 4.058187  \n",
      "Train Epoch[3] Step[16981 / 19085] - loss: 6.631038  \n",
      "Train Epoch[3] Step[17001 / 19085] - loss: 5.632745  \n",
      "Train Epoch[3] Step[17021 / 19085] - loss: 4.472539  \n",
      "Train Epoch[3] Step[17041 / 19085] - loss: 4.949769  \n",
      "Train Epoch[3] Step[17061 / 19085] - loss: 8.792150  \n",
      "Train Epoch[3] Step[17081 / 19085] - loss: 2.971334  \n",
      "Train Epoch[3] Step[17101 / 19085] - loss: 7.248390  \n",
      "Train Epoch[3] Step[17121 / 19085] - loss: 5.750114  \n",
      "Train Epoch[3] Step[17141 / 19085] - loss: 8.209270  \n",
      "Train Epoch[3] Step[17161 / 19085] - loss: 4.228872  \n",
      "Train Epoch[3] Step[17181 / 19085] - loss: 3.128039  \n",
      "Train Epoch[3] Step[17201 / 19085] - loss: 7.462617  \n",
      "Train Epoch[3] Step[17221 / 19085] - loss: 8.968370  \n",
      "Train Epoch[3] Step[17241 / 19085] - loss: 6.913367  \n",
      "Train Epoch[3] Step[17261 / 19085] - loss: 10.512842  \n",
      "Train Epoch[3] Step[17281 / 19085] - loss: 5.022132  \n",
      "Train Epoch[3] Step[17301 / 19085] - loss: 6.028934  \n",
      "Train Epoch[3] Step[17321 / 19085] - loss: 4.380140  \n",
      "Train Epoch[3] Step[17341 / 19085] - loss: 9.455985  \n",
      "Train Epoch[3] Step[17361 / 19085] - loss: 5.173768  \n",
      "Train Epoch[3] Step[17381 / 19085] - loss: 3.501443  \n",
      "Train Epoch[3] Step[17401 / 19085] - loss: 5.262763  \n",
      "Train Epoch[3] Step[17421 / 19085] - loss: 7.416675  \n",
      "Train Epoch[3] Step[17441 / 19085] - loss: 1.491012  \n",
      "Train Epoch[3] Step[17461 / 19085] - loss: 4.919186  \n",
      "Train Epoch[3] Step[17481 / 19085] - loss: 7.428977  \n",
      "Train Epoch[3] Step[17501 / 19085] - loss: 7.706556  \n",
      "Train Epoch[3] Step[17521 / 19085] - loss: 3.655396  \n",
      "Train Epoch[3] Step[17541 / 19085] - loss: 5.351642  \n",
      "Train Epoch[3] Step[17561 / 19085] - loss: 6.994876  \n",
      "Train Epoch[3] Step[17581 / 19085] - loss: 4.087879  \n",
      "Train Epoch[3] Step[17601 / 19085] - loss: 4.918352  \n",
      "Train Epoch[3] Step[17621 / 19085] - loss: 8.719108  \n",
      "Train Epoch[3] Step[17641 / 19085] - loss: 8.051987  \n",
      "Train Epoch[3] Step[17661 / 19085] - loss: 4.873346  \n",
      "Train Epoch[3] Step[17681 / 19085] - loss: 8.725819  \n",
      "Train Epoch[3] Step[17701 / 19085] - loss: 6.494543  \n",
      "Train Epoch[3] Step[17721 / 19085] - loss: 4.471632  \n",
      "Train Epoch[3] Step[17741 / 19085] - loss: 4.636971  \n",
      "Train Epoch[3] Step[17761 / 19085] - loss: 5.388209  \n",
      "Train Epoch[3] Step[17781 / 19085] - loss: 3.809060  \n",
      "Train Epoch[3] Step[17801 / 19085] - loss: 4.429764  \n",
      "Train Epoch[3] Step[17821 / 19085] - loss: 6.689272  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:25<00:00, 14.66it/s]\n",
      "Dev Loss: 5.644833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7156    0.5706    0.6349     26118\n",
      "         ORG     0.3956    0.0184    0.0352      1956\n",
      "         PER     0.7201    0.5627    0.6317     22839\n",
      "           T     0.7894    0.6290    0.7001     22956\n",
      "\n",
      "   micro avg     0.7402    0.5717    0.6451     73869\n",
      "   macro avg     0.6552    0.4452    0.5005     73869\n",
      "weighted avg     0.7315    0.5717    0.6383     73869\n",
      "\n",
      "best f1: 0.64, current f1: 0.65\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[3] Step[17841 / 19085] - loss: 4.862864  \n",
      "Train Epoch[3] Step[17861 / 19085] - loss: 5.191678  \n",
      "Train Epoch[3] Step[17881 / 19085] - loss: 4.759923  \n",
      "Train Epoch[3] Step[17901 / 19085] - loss: 5.542831  \n",
      "Train Epoch[3] Step[17921 / 19085] - loss: 5.759052  \n",
      "Train Epoch[3] Step[17941 / 19085] - loss: 3.802074  \n",
      "Train Epoch[3] Step[17961 / 19085] - loss: 6.118526  \n",
      "Train Epoch[3] Step[17981 / 19085] - loss: 6.334567  \n",
      "Train Epoch[3] Step[18001 / 19085] - loss: 6.474777  \n",
      "Train Epoch[3] Step[18021 / 19085] - loss: 8.051662  \n",
      "Train Epoch[3] Step[18041 / 19085] - loss: 3.985452  \n",
      "Train Epoch[3] Step[18061 / 19085] - loss: 6.479030  \n",
      "Train Epoch[3] Step[18081 / 19085] - loss: 6.120968  \n",
      "Train Epoch[3] Step[18101 / 19085] - loss: 5.006652  \n",
      "Train Epoch[3] Step[18121 / 19085] - loss: 3.710505  \n",
      "Train Epoch[3] Step[18141 / 19085] - loss: 4.081139  \n",
      "Train Epoch[3] Step[18161 / 19085] - loss: 5.539496  \n",
      "Train Epoch[3] Step[18181 / 19085] - loss: 6.411536  \n",
      "Train Epoch[3] Step[18201 / 19085] - loss: 5.036482  \n",
      "Train Epoch[3] Step[18221 / 19085] - loss: 2.303288  \n",
      "Train Epoch[3] Step[18241 / 19085] - loss: 5.687612  \n",
      "Train Epoch[3] Step[18261 / 19085] - loss: 7.386323  \n",
      "Train Epoch[3] Step[18281 / 19085] - loss: 4.712543  \n",
      "Train Epoch[3] Step[18301 / 19085] - loss: 5.748133  \n",
      "Train Epoch[3] Step[18321 / 19085] - loss: 7.410042  \n",
      "Train Epoch[3] Step[18341 / 19085] - loss: 5.200999  \n",
      "Train Epoch[3] Step[18361 / 19085] - loss: 7.021876  \n",
      "Train Epoch[3] Step[18381 / 19085] - loss: 5.655982  \n",
      "Train Epoch[3] Step[18401 / 19085] - loss: 10.237101  \n",
      "Train Epoch[3] Step[18421 / 19085] - loss: 4.313259  \n",
      "Train Epoch[3] Step[18441 / 19085] - loss: 2.579015  \n",
      "Train Epoch[3] Step[18461 / 19085] - loss: 5.773267  \n",
      "Train Epoch[3] Step[18481 / 19085] - loss: 8.098516  \n",
      "Train Epoch[3] Step[18501 / 19085] - loss: 2.721934  \n",
      "Train Epoch[3] Step[18521 / 19085] - loss: 4.582835  \n",
      "Train Epoch[3] Step[18541 / 19085] - loss: 5.961333  \n",
      "Train Epoch[3] Step[18561 / 19085] - loss: 6.866535  \n",
      "Train Epoch[3] Step[18581 / 19085] - loss: 4.556697  \n",
      "Train Epoch[3] Step[18601 / 19085] - loss: 4.425336  \n",
      "Train Epoch[3] Step[18621 / 19085] - loss: 4.675016  \n",
      "Train Epoch[3] Step[18641 / 19085] - loss: 5.547739  \n",
      "Train Epoch[3] Step[18661 / 19085] - loss: 10.898933  \n",
      "Train Epoch[3] Step[18681 / 19085] - loss: 1.564507  \n",
      "Train Epoch[3] Step[18701 / 19085] - loss: 4.186826  \n",
      "Train Epoch[3] Step[18721 / 19085] - loss: 6.469765  \n",
      "Train Epoch[3] Step[18741 / 19085] - loss: 6.093874  \n",
      "Train Epoch[3] Step[18761 / 19085] - loss: 1.771870  \n",
      "Train Epoch[3] Step[18781 / 19085] - loss: 4.138126  \n",
      "Train Epoch[3] Step[18801 / 19085] - loss: 4.381710  \n",
      "Train Epoch[3] Step[18821 / 19085] - loss: 6.623664  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:19<00:00, 14.93it/s]\n",
      "Dev Loss: 5.632831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7221    0.5521    0.6258     26118\n",
      "         ORG     0.4167    0.0179    0.0343      1956\n",
      "         PER     0.7221    0.5586    0.6299     22839\n",
      "           T     0.7974    0.6172    0.6958     22956\n",
      "\n",
      "   micro avg     0.7458    0.5602    0.6398     73869\n",
      "   macro avg     0.6646    0.4365    0.4965     73869\n",
      "weighted avg     0.7374    0.5602    0.6332     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.64\n",
      "\n",
      "Train Epoch[3] Step[18841 / 19085] - loss: 4.376135  \n",
      "Train Epoch[3] Step[18861 / 19085] - loss: 4.086437  \n",
      "Train Epoch[3] Step[18881 / 19085] - loss: 6.756395  \n",
      "Train Epoch[3] Step[18901 / 19085] - loss: 7.323765  \n",
      "Train Epoch[3] Step[18921 / 19085] - loss: 2.107695  \n",
      "Train Epoch[3] Step[18941 / 19085] - loss: 7.992568  \n",
      "Train Epoch[3] Step[18961 / 19085] - loss: 9.499249  \n",
      "Train Epoch[3] Step[18981 / 19085] - loss: 4.704210  \n",
      "Train Epoch[3] Step[19001 / 19085] - loss: 3.623302  \n",
      "Train Epoch[3] Step[19021 / 19085] - loss: 5.600920  \n",
      "Train Epoch[3] Step[19041 / 19085] - loss: 4.320894  \n",
      "Train Epoch[3] Step[19061 / 19085] - loss: 3.990868  \n",
      "Train Epoch[3] Step[19081 / 19085] - loss: 4.948831  \n",
      "Train Epoch[4] Step[1 / 19085] - loss: 5.233461  \n",
      "Train Epoch[4] Step[21 / 19085] - loss: 2.810792  \n",
      "Train Epoch[4] Step[41 / 19085] - loss: 3.573858  \n",
      "Train Epoch[4] Step[61 / 19085] - loss: 3.430179  \n",
      "Train Epoch[4] Step[81 / 19085] - loss: 7.086755  \n",
      "Train Epoch[4] Step[101 / 19085] - loss: 2.673057  \n",
      "Train Epoch[4] Step[121 / 19085] - loss: 4.780870  \n",
      "Train Epoch[4] Step[141 / 19085] - loss: 6.604007  \n",
      "Train Epoch[4] Step[161 / 19085] - loss: 5.009401  \n",
      "Train Epoch[4] Step[181 / 19085] - loss: 4.753227  \n",
      "Train Epoch[4] Step[201 / 19085] - loss: 5.157480  \n",
      "Train Epoch[4] Step[221 / 19085] - loss: 4.897159  \n",
      "Train Epoch[4] Step[241 / 19085] - loss: 7.173294  \n",
      "Train Epoch[4] Step[261 / 19085] - loss: 5.420976  \n",
      "Train Epoch[4] Step[281 / 19085] - loss: 6.540283  \n",
      "Train Epoch[4] Step[301 / 19085] - loss: 8.920971  \n",
      "Train Epoch[4] Step[321 / 19085] - loss: 2.688779  \n",
      "Train Epoch[4] Step[341 / 19085] - loss: 5.365514  \n",
      "Train Epoch[4] Step[361 / 19085] - loss: 4.674032  \n",
      "Train Epoch[4] Step[381 / 19085] - loss: 5.164322  \n",
      "Train Epoch[4] Step[401 / 19085] - loss: 6.642069  \n",
      "Train Epoch[4] Step[421 / 19085] - loss: 2.507609  \n",
      "Train Epoch[4] Step[441 / 19085] - loss: 5.097329  \n",
      "Train Epoch[4] Step[461 / 19085] - loss: 2.068822  \n",
      "Train Epoch[4] Step[481 / 19085] - loss: 6.958961  \n",
      "Train Epoch[4] Step[501 / 19085] - loss: 5.907108  \n",
      "Train Epoch[4] Step[521 / 19085] - loss: 2.890545  \n",
      "Train Epoch[4] Step[541 / 19085] - loss: 2.708358  \n",
      "Train Epoch[4] Step[561 / 19085] - loss: 8.730530  \n",
      "Train Epoch[4] Step[581 / 19085] - loss: 4.380466  \n",
      "Train Epoch[4] Step[601 / 19085] - loss: 5.424561  \n",
      "Train Epoch[4] Step[621 / 19085] - loss: 7.242313  \n",
      "Train Epoch[4] Step[641 / 19085] - loss: 6.350599  \n",
      "Train Epoch[4] Step[661 / 19085] - loss: 3.429493  \n",
      "Train Epoch[4] Step[681 / 19085] - loss: 3.504000  \n",
      "Train Epoch[4] Step[701 / 19085] - loss: 3.422002  \n",
      "Train Epoch[4] Step[721 / 19085] - loss: 4.827492  \n",
      "Train Epoch[4] Step[741 / 19085] - loss: 4.913651  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:20<00:00, 14.89it/s]\n",
      "Dev Loss: 5.544216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7101    0.5862    0.6422     26118\n",
      "         ORG     0.4343    0.0220    0.0418      1956\n",
      "         PER     0.7179    0.5787    0.6408     22839\n",
      "           T     0.7899    0.6245    0.6975     22956\n",
      "\n",
      "   micro avg     0.7370    0.5809    0.6497     73869\n",
      "   macro avg     0.6631    0.4529    0.5056     73869\n",
      "weighted avg     0.7300    0.5809    0.6431     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[4] Step[761 / 19085] - loss: 7.648492  \n",
      "Train Epoch[4] Step[781 / 19085] - loss: 1.999557  \n",
      "Train Epoch[4] Step[801 / 19085] - loss: 5.698730  \n",
      "Train Epoch[4] Step[821 / 19085] - loss: 4.971683  \n",
      "Train Epoch[4] Step[841 / 19085] - loss: 5.612241  \n",
      "Train Epoch[4] Step[861 / 19085] - loss: 6.461763  \n",
      "Train Epoch[4] Step[881 / 19085] - loss: 5.264747  \n",
      "Train Epoch[4] Step[901 / 19085] - loss: 6.741584  \n",
      "Train Epoch[4] Step[921 / 19085] - loss: 1.613706  \n",
      "Train Epoch[4] Step[941 / 19085] - loss: 2.796547  \n",
      "Train Epoch[4] Step[961 / 19085] - loss: 3.876107  \n",
      "Train Epoch[4] Step[981 / 19085] - loss: 5.556554  \n",
      "Train Epoch[4] Step[1001 / 19085] - loss: 5.448707  \n",
      "Train Epoch[4] Step[1021 / 19085] - loss: 5.001961  \n",
      "Train Epoch[4] Step[1041 / 19085] - loss: 3.943127  \n",
      "Train Epoch[4] Step[1061 / 19085] - loss: 6.819858  \n",
      "Train Epoch[4] Step[1081 / 19085] - loss: 4.206795  \n",
      "Train Epoch[4] Step[1101 / 19085] - loss: 8.689742  \n",
      "Train Epoch[4] Step[1121 / 19085] - loss: 7.133064  \n",
      "Train Epoch[4] Step[1141 / 19085] - loss: 3.247957  \n",
      "Train Epoch[4] Step[1161 / 19085] - loss: 3.605762  \n",
      "Train Epoch[4] Step[1181 / 19085] - loss: 4.579621  \n",
      "Train Epoch[4] Step[1201 / 19085] - loss: 6.126807  \n",
      "Train Epoch[4] Step[1221 / 19085] - loss: 10.314205  \n",
      "Train Epoch[4] Step[1241 / 19085] - loss: 5.543794  \n",
      "Train Epoch[4] Step[1261 / 19085] - loss: 2.359357  \n",
      "Train Epoch[4] Step[1281 / 19085] - loss: 6.623121  \n",
      "Train Epoch[4] Step[1301 / 19085] - loss: 8.616130  \n",
      "Train Epoch[4] Step[1321 / 19085] - loss: 6.738178  \n",
      "Train Epoch[4] Step[1341 / 19085] - loss: 5.856177  \n",
      "Train Epoch[4] Step[1361 / 19085] - loss: 5.891012  \n",
      "Train Epoch[4] Step[1381 / 19085] - loss: 9.649624  \n",
      "Train Epoch[4] Step[1401 / 19085] - loss: 10.579768  \n",
      "Train Epoch[4] Step[1421 / 19085] - loss: 3.112750  \n",
      "Train Epoch[4] Step[1441 / 19085] - loss: 6.398327  \n",
      "Train Epoch[4] Step[1461 / 19085] - loss: 4.911559  \n",
      "Train Epoch[4] Step[1481 / 19085] - loss: 8.841106  \n",
      "Train Epoch[4] Step[1501 / 19085] - loss: 11.041273  \n",
      "Train Epoch[4] Step[1521 / 19085] - loss: 9.905569  \n",
      "Train Epoch[4] Step[1541 / 19085] - loss: 5.578531  \n",
      "Train Epoch[4] Step[1561 / 19085] - loss: 2.347691  \n",
      "Train Epoch[4] Step[1581 / 19085] - loss: 5.030508  \n",
      "Train Epoch[4] Step[1601 / 19085] - loss: 5.336744  \n",
      "Train Epoch[4] Step[1621 / 19085] - loss: 4.276269  \n",
      "Train Epoch[4] Step[1641 / 19085] - loss: 4.134840  \n",
      "Train Epoch[4] Step[1661 / 19085] - loss: 3.860029  \n",
      "Train Epoch[4] Step[1681 / 19085] - loss: 6.789080  \n",
      "Train Epoch[4] Step[1701 / 19085] - loss: 5.252712  \n",
      "Train Epoch[4] Step[1721 / 19085] - loss: 3.743882  \n",
      "Train Epoch[4] Step[1741 / 19085] - loss: 6.918176  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:25<00:00, 14.67it/s]\n",
      "Dev Loss: 5.513875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7130    0.5829    0.6414     26118\n",
      "         ORG     0.4651    0.0307    0.0576      1956\n",
      "         PER     0.7240    0.5753    0.6411     22839\n",
      "           T     0.7978    0.6203    0.6980     22956\n",
      "\n",
      "   micro avg     0.7423    0.5776    0.6496     73869\n",
      "   macro avg     0.6750    0.4523    0.5095     73869\n",
      "weighted avg     0.7362    0.5776    0.6435     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[1761 / 19085] - loss: 5.023593  \n",
      "Train Epoch[4] Step[1781 / 19085] - loss: 3.199659  \n",
      "Train Epoch[4] Step[1801 / 19085] - loss: 6.334877  \n",
      "Train Epoch[4] Step[1821 / 19085] - loss: 6.803157  \n",
      "Train Epoch[4] Step[1841 / 19085] - loss: 3.611514  \n",
      "Train Epoch[4] Step[1861 / 19085] - loss: 6.412204  \n",
      "Train Epoch[4] Step[1881 / 19085] - loss: 7.099761  \n",
      "Train Epoch[4] Step[1901 / 19085] - loss: 7.884582  \n",
      "Train Epoch[4] Step[1921 / 19085] - loss: 5.262850  \n",
      "Train Epoch[4] Step[1941 / 19085] - loss: 6.256071  \n",
      "Train Epoch[4] Step[1961 / 19085] - loss: 4.232992  \n",
      "Train Epoch[4] Step[1981 / 19085] - loss: 6.265022  \n",
      "Train Epoch[4] Step[2001 / 19085] - loss: 11.573855  \n",
      "Train Epoch[4] Step[2021 / 19085] - loss: 4.754856  \n",
      "Train Epoch[4] Step[2041 / 19085] - loss: 5.435552  \n",
      "Train Epoch[4] Step[2061 / 19085] - loss: 4.069548  \n",
      "Train Epoch[4] Step[2081 / 19085] - loss: 9.603454  \n",
      "Train Epoch[4] Step[2101 / 19085] - loss: 4.735970  \n",
      "Train Epoch[4] Step[2121 / 19085] - loss: 7.367677  \n",
      "Train Epoch[4] Step[2141 / 19085] - loss: 11.205875  \n",
      "Train Epoch[4] Step[2161 / 19085] - loss: 6.958372  \n",
      "Train Epoch[4] Step[2181 / 19085] - loss: 9.772644  \n",
      "Train Epoch[4] Step[2201 / 19085] - loss: 4.013041  \n",
      "Train Epoch[4] Step[2221 / 19085] - loss: 9.839432  \n",
      "Train Epoch[4] Step[2241 / 19085] - loss: 3.322591  \n",
      "Train Epoch[4] Step[2261 / 19085] - loss: 8.926382  \n",
      "Train Epoch[4] Step[2281 / 19085] - loss: 4.189960  \n",
      "Train Epoch[4] Step[2301 / 19085] - loss: 3.056953  \n",
      "Train Epoch[4] Step[2321 / 19085] - loss: 4.027311  \n",
      "Train Epoch[4] Step[2341 / 19085] - loss: 2.780815  \n",
      "Train Epoch[4] Step[2361 / 19085] - loss: 1.866248  \n",
      "Train Epoch[4] Step[2381 / 19085] - loss: 8.579314  \n",
      "Train Epoch[4] Step[2401 / 19085] - loss: 14.205848  \n",
      "Train Epoch[4] Step[2421 / 19085] - loss: 8.097038  \n",
      "Train Epoch[4] Step[2441 / 19085] - loss: 6.648771  \n",
      "Train Epoch[4] Step[2461 / 19085] - loss: 6.810705  \n",
      "Train Epoch[4] Step[2481 / 19085] - loss: 6.938917  \n",
      "Train Epoch[4] Step[2501 / 19085] - loss: 2.906980  \n",
      "Train Epoch[4] Step[2521 / 19085] - loss: 6.175564  \n",
      "Train Epoch[4] Step[2541 / 19085] - loss: 4.846745  \n",
      "Train Epoch[4] Step[2561 / 19085] - loss: 3.672936  \n",
      "Train Epoch[4] Step[2581 / 19085] - loss: 3.509918  \n",
      "Train Epoch[4] Step[2601 / 19085] - loss: 7.582542  \n",
      "Train Epoch[4] Step[2621 / 19085] - loss: 6.500270  \n",
      "Train Epoch[4] Step[2641 / 19085] - loss: 2.930129  \n",
      "Train Epoch[4] Step[2661 / 19085] - loss: 6.116660  \n",
      "Train Epoch[4] Step[2681 / 19085] - loss: 8.434235  \n",
      "Train Epoch[4] Step[2701 / 19085] - loss: 6.724479  \n",
      "Train Epoch[4] Step[2721 / 19085] - loss: 3.140715  \n",
      "Train Epoch[4] Step[2741 / 19085] - loss: 2.618304  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:23<00:00, 14.74it/s]\n",
      "Dev Loss: 5.507232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7147    0.5711    0.6349     26118\n",
      "         ORG     0.4526    0.0220    0.0419      1956\n",
      "         PER     0.7382    0.5501    0.6304     22839\n",
      "           T     0.8008    0.6167    0.6968     22956\n",
      "\n",
      "   micro avg     0.7488    0.5642    0.6435     73869\n",
      "   macro avg     0.6766    0.4400    0.5010     73869\n",
      "weighted avg     0.7418    0.5642    0.6370     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.64\n",
      "\n",
      "Train Epoch[4] Step[2761 / 19085] - loss: 3.233941  \n",
      "Train Epoch[4] Step[2781 / 19085] - loss: 11.861732  \n",
      "Train Epoch[4] Step[2801 / 19085] - loss: 5.788493  \n",
      "Train Epoch[4] Step[2821 / 19085] - loss: 5.552276  \n",
      "Train Epoch[4] Step[2841 / 19085] - loss: 4.580198  \n",
      "Train Epoch[4] Step[2861 / 19085] - loss: 6.658626  \n",
      "Train Epoch[4] Step[2881 / 19085] - loss: 3.634576  \n",
      "Train Epoch[4] Step[2901 / 19085] - loss: 4.827967  \n",
      "Train Epoch[4] Step[2921 / 19085] - loss: 3.099202  \n",
      "Train Epoch[4] Step[2941 / 19085] - loss: 14.498493  \n",
      "Train Epoch[4] Step[2961 / 19085] - loss: 6.615444  \n",
      "Train Epoch[4] Step[2981 / 19085] - loss: 5.311175  \n",
      "Train Epoch[4] Step[3001 / 19085] - loss: 2.773275  \n",
      "Train Epoch[4] Step[3021 / 19085] - loss: 5.121321  \n",
      "Train Epoch[4] Step[3041 / 19085] - loss: 5.312373  \n",
      "Train Epoch[4] Step[3061 / 19085] - loss: 3.453481  \n",
      "Train Epoch[4] Step[3081 / 19085] - loss: 4.099103  \n",
      "Train Epoch[4] Step[3101 / 19085] - loss: 6.065918  \n",
      "Train Epoch[4] Step[3121 / 19085] - loss: 5.515037  \n",
      "Train Epoch[4] Step[3141 / 19085] - loss: 8.712288  \n",
      "Train Epoch[4] Step[3161 / 19085] - loss: 5.804519  \n",
      "Train Epoch[4] Step[3181 / 19085] - loss: 8.133920  \n",
      "Train Epoch[4] Step[3201 / 19085] - loss: 3.083223  \n",
      "Train Epoch[4] Step[3221 / 19085] - loss: 4.046467  \n",
      "Train Epoch[4] Step[3241 / 19085] - loss: 7.780665  \n",
      "Train Epoch[4] Step[3261 / 19085] - loss: 5.464311  \n",
      "Train Epoch[4] Step[3281 / 19085] - loss: 5.938650  \n",
      "Train Epoch[4] Step[3301 / 19085] - loss: 3.313344  \n",
      "Train Epoch[4] Step[3321 / 19085] - loss: 7.100155  \n",
      "Train Epoch[4] Step[3341 / 19085] - loss: 4.498178  \n",
      "Train Epoch[4] Step[3361 / 19085] - loss: 4.281979  \n",
      "Train Epoch[4] Step[3381 / 19085] - loss: 5.711047  \n",
      "Train Epoch[4] Step[3401 / 19085] - loss: 5.260276  \n",
      "Train Epoch[4] Step[3421 / 19085] - loss: 7.434992  \n",
      "Train Epoch[4] Step[3441 / 19085] - loss: 5.610708  \n",
      "Train Epoch[4] Step[3461 / 19085] - loss: 3.236101  \n",
      "Train Epoch[4] Step[3481 / 19085] - loss: 7.246455  \n",
      "Train Epoch[4] Step[3501 / 19085] - loss: 4.750479  \n",
      "Train Epoch[4] Step[3521 / 19085] - loss: 7.506542  \n",
      "Train Epoch[4] Step[3541 / 19085] - loss: 6.249906  \n",
      "Train Epoch[4] Step[3561 / 19085] - loss: 5.663606  \n",
      "Train Epoch[4] Step[3581 / 19085] - loss: 8.755119  \n",
      "Train Epoch[4] Step[3601 / 19085] - loss: 6.383273  \n",
      "Train Epoch[4] Step[3621 / 19085] - loss: 5.051272  \n",
      "Train Epoch[4] Step[3641 / 19085] - loss: 3.653179  \n",
      "Train Epoch[4] Step[3661 / 19085] - loss: 5.622470  \n",
      "Train Epoch[4] Step[3681 / 19085] - loss: 5.058064  \n",
      "Train Epoch[4] Step[3701 / 19085] - loss: 3.365865  \n",
      "Train Epoch[4] Step[3721 / 19085] - loss: 5.843084  \n",
      "Train Epoch[4] Step[3741 / 19085] - loss: 7.032355  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:19<00:00, 14.95it/s]\n",
      "Dev Loss: 5.472815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7170    0.5662    0.6327     26118\n",
      "         ORG     0.4891    0.0230    0.0439      1956\n",
      "         PER     0.7362    0.5573    0.6344     22839\n",
      "           T     0.7964    0.6229    0.6991     22956\n",
      "\n",
      "   micro avg     0.7481    0.5667    0.6449     73869\n",
      "   macro avg     0.6847    0.4424    0.5025     73869\n",
      "weighted avg     0.7416    0.5667    0.6383     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.64\n",
      "\n",
      "Train Epoch[4] Step[3761 / 19085] - loss: 7.405291  \n",
      "Train Epoch[4] Step[3781 / 19085] - loss: 7.188033  \n",
      "Train Epoch[4] Step[3801 / 19085] - loss: 8.849387  \n",
      "Train Epoch[4] Step[3821 / 19085] - loss: 8.290286  \n",
      "Train Epoch[4] Step[3841 / 19085] - loss: 2.363836  \n",
      "Train Epoch[4] Step[3861 / 19085] - loss: 6.222415  \n",
      "Train Epoch[4] Step[3881 / 19085] - loss: 4.387748  \n",
      "Train Epoch[4] Step[3901 / 19085] - loss: 4.211523  \n",
      "Train Epoch[4] Step[3921 / 19085] - loss: 3.682375  \n",
      "Train Epoch[4] Step[3941 / 19085] - loss: 4.116361  \n",
      "Train Epoch[4] Step[3961 / 19085] - loss: 6.208598  \n",
      "Train Epoch[4] Step[3981 / 19085] - loss: 6.523302  \n",
      "Train Epoch[4] Step[4001 / 19085] - loss: 2.179991  \n",
      "Train Epoch[4] Step[4021 / 19085] - loss: 4.738164  \n",
      "Train Epoch[4] Step[4041 / 19085] - loss: 4.337477  \n",
      "Train Epoch[4] Step[4061 / 19085] - loss: 5.097354  \n",
      "Train Epoch[4] Step[4081 / 19085] - loss: 6.669132  \n",
      "Train Epoch[4] Step[4101 / 19085] - loss: 6.122079  \n",
      "Train Epoch[4] Step[4121 / 19085] - loss: 6.507822  \n",
      "Train Epoch[4] Step[4141 / 19085] - loss: 10.583207  \n",
      "Train Epoch[4] Step[4161 / 19085] - loss: 4.540227  \n",
      "Train Epoch[4] Step[4181 / 19085] - loss: 6.369790  \n",
      "Train Epoch[4] Step[4201 / 19085] - loss: 7.318927  \n",
      "Train Epoch[4] Step[4221 / 19085] - loss: 7.014840  \n",
      "Train Epoch[4] Step[4241 / 19085] - loss: 3.699323  \n",
      "Train Epoch[4] Step[4261 / 19085] - loss: 9.439069  \n",
      "Train Epoch[4] Step[4281 / 19085] - loss: 5.120595  \n",
      "Train Epoch[4] Step[4301 / 19085] - loss: 3.059986  \n",
      "Train Epoch[4] Step[4321 / 19085] - loss: 3.968598  \n",
      "Train Epoch[4] Step[4341 / 19085] - loss: 4.963265  \n",
      "Train Epoch[4] Step[4361 / 19085] - loss: 8.487883  \n",
      "Train Epoch[4] Step[4381 / 19085] - loss: 3.895073  \n",
      "Train Epoch[4] Step[4401 / 19085] - loss: 3.170054  \n",
      "Train Epoch[4] Step[4421 / 19085] - loss: 7.913418  \n",
      "Train Epoch[4] Step[4441 / 19085] - loss: 4.031549  \n",
      "Train Epoch[4] Step[4461 / 19085] - loss: 8.266421  \n",
      "Train Epoch[4] Step[4481 / 19085] - loss: 6.553539  \n",
      "Train Epoch[4] Step[4501 / 19085] - loss: 6.991651  \n",
      "Train Epoch[4] Step[4521 / 19085] - loss: 4.611305  \n",
      "Train Epoch[4] Step[4541 / 19085] - loss: 5.058311  \n",
      "Train Epoch[4] Step[4561 / 19085] - loss: 5.440989  \n",
      "Train Epoch[4] Step[4581 / 19085] - loss: 9.031360  \n",
      "Train Epoch[4] Step[4601 / 19085] - loss: 6.467359  \n",
      "Train Epoch[4] Step[4621 / 19085] - loss: 7.139762  \n",
      "Train Epoch[4] Step[4641 / 19085] - loss: 4.981184  \n",
      "Train Epoch[4] Step[4661 / 19085] - loss: 5.515134  \n",
      "Train Epoch[4] Step[4681 / 19085] - loss: 8.997482  \n",
      "Train Epoch[4] Step[4701 / 19085] - loss: 9.287949  \n",
      "Train Epoch[4] Step[4721 / 19085] - loss: 3.624461  \n",
      "Train Epoch[4] Step[4741 / 19085] - loss: 7.944308  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:17<00:00, 15.02it/s]\n",
      "Dev Loss: 5.417762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7158    0.5782    0.6397     26118\n",
      "         ORG     0.4851    0.0251    0.0476      1956\n",
      "         PER     0.7347    0.5682    0.6408     22839\n",
      "           T     0.7946    0.6220    0.6978     22956\n",
      "\n",
      "   micro avg     0.7462    0.5741    0.6489     73869\n",
      "   macro avg     0.6826    0.4484    0.5065     73869\n",
      "weighted avg     0.7400    0.5741    0.6424     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[4761 / 19085] - loss: 10.111692  \n",
      "Train Epoch[4] Step[4781 / 19085] - loss: 7.369504  \n",
      "Train Epoch[4] Step[4801 / 19085] - loss: 7.053020  \n",
      "Train Epoch[4] Step[4821 / 19085] - loss: 5.342167  \n",
      "Train Epoch[4] Step[4841 / 19085] - loss: 6.185543  \n",
      "Train Epoch[4] Step[4861 / 19085] - loss: 4.626259  \n",
      "Train Epoch[4] Step[4881 / 19085] - loss: 3.416207  \n",
      "Train Epoch[4] Step[4901 / 19085] - loss: 8.863110  \n",
      "Train Epoch[4] Step[4921 / 19085] - loss: 1.530616  \n",
      "Train Epoch[4] Step[4941 / 19085] - loss: 4.924350  \n",
      "Train Epoch[4] Step[4961 / 19085] - loss: 4.750543  \n",
      "Train Epoch[4] Step[4981 / 19085] - loss: 6.248296  \n",
      "Train Epoch[4] Step[5001 / 19085] - loss: 6.673412  \n",
      "Train Epoch[4] Step[5021 / 19085] - loss: 4.548666  \n",
      "Train Epoch[4] Step[5041 / 19085] - loss: 4.491539  \n",
      "Train Epoch[4] Step[5061 / 19085] - loss: 4.916473  \n",
      "Train Epoch[4] Step[5081 / 19085] - loss: 5.685688  \n",
      "Train Epoch[4] Step[5101 / 19085] - loss: 5.689704  \n",
      "Train Epoch[4] Step[5121 / 19085] - loss: 4.109428  \n",
      "Train Epoch[4] Step[5141 / 19085] - loss: 4.169526  \n",
      "Train Epoch[4] Step[5161 / 19085] - loss: 6.355050  \n",
      "Train Epoch[4] Step[5181 / 19085] - loss: 5.613529  \n",
      "Train Epoch[4] Step[5201 / 19085] - loss: 7.162513  \n",
      "Train Epoch[4] Step[5221 / 19085] - loss: 6.215036  \n",
      "Train Epoch[4] Step[5241 / 19085] - loss: 3.060272  \n",
      "Train Epoch[4] Step[5261 / 19085] - loss: 2.732471  \n",
      "Train Epoch[4] Step[5281 / 19085] - loss: 4.036849  \n",
      "Train Epoch[4] Step[5301 / 19085] - loss: 4.732852  \n",
      "Train Epoch[4] Step[5321 / 19085] - loss: 4.920543  \n",
      "Train Epoch[4] Step[5341 / 19085] - loss: 7.406845  \n",
      "Train Epoch[4] Step[5361 / 19085] - loss: 4.843556  \n",
      "Train Epoch[4] Step[5381 / 19085] - loss: 2.986444  \n",
      "Train Epoch[4] Step[5401 / 19085] - loss: 5.942019  \n",
      "Train Epoch[4] Step[5421 / 19085] - loss: 5.403324  \n",
      "Train Epoch[4] Step[5441 / 19085] - loss: 7.402019  \n",
      "Train Epoch[4] Step[5461 / 19085] - loss: 4.692838  \n",
      "Train Epoch[4] Step[5481 / 19085] - loss: 6.983476  \n",
      "Train Epoch[4] Step[5501 / 19085] - loss: 8.267094  \n",
      "Train Epoch[4] Step[5521 / 19085] - loss: 6.629524  \n",
      "Train Epoch[4] Step[5541 / 19085] - loss: 4.668437  \n",
      "Train Epoch[4] Step[5561 / 19085] - loss: 3.943961  \n",
      "Train Epoch[4] Step[5581 / 19085] - loss: 5.274269  \n",
      "Train Epoch[4] Step[5601 / 19085] - loss: 2.661073  \n",
      "Train Epoch[4] Step[5621 / 19085] - loss: 4.934675  \n",
      "Train Epoch[4] Step[5641 / 19085] - loss: 5.910607  \n",
      "Train Epoch[4] Step[5661 / 19085] - loss: 4.936703  \n",
      "Train Epoch[4] Step[5681 / 19085] - loss: 3.097541  \n",
      "Train Epoch[4] Step[5701 / 19085] - loss: 7.250940  \n",
      "Train Epoch[4] Step[5721 / 19085] - loss: 10.639240  \n",
      "Train Epoch[4] Step[5741 / 19085] - loss: 7.007711  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:15<00:00, 15.14it/s]\n",
      "Dev Loss: 5.382816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7196    0.5717    0.6372     26118\n",
      "         ORG     0.4886    0.0220    0.0421      1956\n",
      "         PER     0.7297    0.5827    0.6480     22839\n",
      "           T     0.7916    0.6286    0.7008     22956\n",
      "\n",
      "   micro avg     0.7454    0.5782    0.6512     73869\n",
      "   macro avg     0.6824    0.4512    0.5070     73869\n",
      "weighted avg     0.7390    0.5782    0.6445     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[4] Step[5761 / 19085] - loss: 3.528615  \n",
      "Train Epoch[4] Step[5781 / 19085] - loss: 5.146791  \n",
      "Train Epoch[4] Step[5801 / 19085] - loss: 4.649636  \n",
      "Train Epoch[4] Step[5821 / 19085] - loss: 6.853948  \n",
      "Train Epoch[4] Step[5841 / 19085] - loss: 5.403298  \n",
      "Train Epoch[4] Step[5861 / 19085] - loss: 7.038146  \n",
      "Train Epoch[4] Step[5881 / 19085] - loss: 6.457352  \n",
      "Train Epoch[4] Step[5901 / 19085] - loss: 4.697838  \n",
      "Train Epoch[4] Step[5921 / 19085] - loss: 7.156156  \n",
      "Train Epoch[4] Step[5941 / 19085] - loss: 3.829823  \n",
      "Train Epoch[4] Step[5961 / 19085] - loss: 6.635658  \n",
      "Train Epoch[4] Step[5981 / 19085] - loss: 3.225554  \n",
      "Train Epoch[4] Step[6001 / 19085] - loss: 2.785273  \n",
      "Train Epoch[4] Step[6021 / 19085] - loss: 5.497022  \n",
      "Train Epoch[4] Step[6041 / 19085] - loss: 4.746742  \n",
      "Train Epoch[4] Step[6061 / 19085] - loss: 2.489063  \n",
      "Train Epoch[4] Step[6081 / 19085] - loss: 5.307776  \n",
      "Train Epoch[4] Step[6101 / 19085] - loss: 6.452528  \n",
      "Train Epoch[4] Step[6121 / 19085] - loss: 4.801688  \n",
      "Train Epoch[4] Step[6141 / 19085] - loss: 2.345113  \n",
      "Train Epoch[4] Step[6161 / 19085] - loss: 3.663041  \n",
      "Train Epoch[4] Step[6181 / 19085] - loss: 5.462865  \n",
      "Train Epoch[4] Step[6201 / 19085] - loss: 7.925049  \n",
      "Train Epoch[4] Step[6221 / 19085] - loss: 3.088125  \n",
      "Train Epoch[4] Step[6241 / 19085] - loss: 6.139078  \n",
      "Train Epoch[4] Step[6261 / 19085] - loss: 6.392795  \n",
      "Train Epoch[4] Step[6281 / 19085] - loss: 4.310415  \n",
      "Train Epoch[4] Step[6301 / 19085] - loss: 3.862655  \n",
      "Train Epoch[4] Step[6321 / 19085] - loss: 4.422877  \n",
      "Train Epoch[4] Step[6341 / 19085] - loss: 5.191834  \n",
      "Train Epoch[4] Step[6361 / 19085] - loss: 7.935104  \n",
      "Train Epoch[4] Step[6381 / 19085] - loss: 5.621008  \n",
      "Train Epoch[4] Step[6401 / 19085] - loss: 5.858512  \n",
      "Train Epoch[4] Step[6421 / 19085] - loss: 7.742641  \n",
      "Train Epoch[4] Step[6441 / 19085] - loss: 5.061738  \n",
      "Train Epoch[4] Step[6461 / 19085] - loss: 3.770490  \n",
      "Train Epoch[4] Step[6481 / 19085] - loss: 5.506378  \n",
      "Train Epoch[4] Step[6501 / 19085] - loss: 5.320281  \n",
      "Train Epoch[4] Step[6521 / 19085] - loss: 4.817691  \n",
      "Train Epoch[4] Step[6541 / 19085] - loss: 2.410622  \n",
      "Train Epoch[4] Step[6561 / 19085] - loss: 6.670286  \n",
      "Train Epoch[4] Step[6581 / 19085] - loss: 4.231568  \n",
      "Train Epoch[4] Step[6601 / 19085] - loss: 4.157804  \n",
      "Train Epoch[4] Step[6621 / 19085] - loss: 10.028446  \n",
      "Train Epoch[4] Step[6641 / 19085] - loss: 7.823548  \n",
      "Train Epoch[4] Step[6661 / 19085] - loss: 5.528537  \n",
      "Train Epoch[4] Step[6681 / 19085] - loss: 7.701906  \n",
      "Train Epoch[4] Step[6701 / 19085] - loss: 6.981336  \n",
      "Train Epoch[4] Step[6721 / 19085] - loss: 6.146978  \n",
      "Train Epoch[4] Step[6741 / 19085] - loss: 4.842780  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:31<00:00, 14.39it/s]\n",
      "Dev Loss: 5.357244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7170    0.5765    0.6391     26118\n",
      "         ORG     0.4874    0.0297    0.0559      1956\n",
      "         PER     0.7383    0.5730    0.6452     22839\n",
      "           T     0.7982    0.6168    0.6959     22956\n",
      "\n",
      "   micro avg     0.7486    0.5735    0.6494     73869\n",
      "   macro avg     0.6852    0.4490    0.5090     73869\n",
      "weighted avg     0.7427    0.5735    0.6432     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[6761 / 19085] - loss: 4.229760  \n",
      "Train Epoch[4] Step[6781 / 19085] - loss: 3.962890  \n",
      "Train Epoch[4] Step[6801 / 19085] - loss: 9.706533  \n",
      "Train Epoch[4] Step[6821 / 19085] - loss: 3.990325  \n",
      "Train Epoch[4] Step[6841 / 19085] - loss: 9.169070  \n",
      "Train Epoch[4] Step[6861 / 19085] - loss: 5.033307  \n",
      "Train Epoch[4] Step[6881 / 19085] - loss: 3.174006  \n",
      "Train Epoch[4] Step[6901 / 19085] - loss: 2.287845  \n",
      "Train Epoch[4] Step[6921 / 19085] - loss: 10.592035  \n",
      "Train Epoch[4] Step[6941 / 19085] - loss: 2.797211  \n",
      "Train Epoch[4] Step[6961 / 19085] - loss: 5.202215  \n",
      "Train Epoch[4] Step[6981 / 19085] - loss: 8.627388  \n",
      "Train Epoch[4] Step[7001 / 19085] - loss: 4.543934  \n",
      "Train Epoch[4] Step[7021 / 19085] - loss: 4.685194  \n",
      "Train Epoch[4] Step[7041 / 19085] - loss: 6.475509  \n",
      "Train Epoch[4] Step[7061 / 19085] - loss: 3.657220  \n",
      "Train Epoch[4] Step[7081 / 19085] - loss: 3.619209  \n",
      "Train Epoch[4] Step[7101 / 19085] - loss: 7.296213  \n",
      "Train Epoch[4] Step[7121 / 19085] - loss: 5.194173  \n",
      "Train Epoch[4] Step[7141 / 19085] - loss: 6.735734  \n",
      "Train Epoch[4] Step[7161 / 19085] - loss: 3.942686  \n",
      "Train Epoch[4] Step[7181 / 19085] - loss: 5.220912  \n",
      "Train Epoch[4] Step[7201 / 19085] - loss: 3.831789  \n",
      "Train Epoch[4] Step[7221 / 19085] - loss: 5.314487  \n",
      "Train Epoch[4] Step[7241 / 19085] - loss: 4.840713  \n",
      "Train Epoch[4] Step[7261 / 19085] - loss: 8.253397  \n",
      "Train Epoch[4] Step[7281 / 19085] - loss: 5.118497  \n",
      "Train Epoch[4] Step[7301 / 19085] - loss: 5.801391  \n",
      "Train Epoch[4] Step[7321 / 19085] - loss: 4.651498  \n",
      "Train Epoch[4] Step[7341 / 19085] - loss: 7.086776  \n",
      "Train Epoch[4] Step[7361 / 19085] - loss: 8.938414  \n",
      "Train Epoch[4] Step[7381 / 19085] - loss: 2.818670  \n",
      "Train Epoch[4] Step[7401 / 19085] - loss: 4.648163  \n",
      "Train Epoch[4] Step[7421 / 19085] - loss: 3.227428  \n",
      "Train Epoch[4] Step[7441 / 19085] - loss: 4.799593  \n",
      "Train Epoch[4] Step[7461 / 19085] - loss: 9.429721  \n",
      "Train Epoch[4] Step[7481 / 19085] - loss: 4.358588  \n",
      "Train Epoch[4] Step[7501 / 19085] - loss: 7.918549  \n",
      "Train Epoch[4] Step[7521 / 19085] - loss: 7.757205  \n",
      "Train Epoch[4] Step[7541 / 19085] - loss: 4.304029  \n",
      "Train Epoch[4] Step[7561 / 19085] - loss: 6.297674  \n",
      "Train Epoch[4] Step[7581 / 19085] - loss: 7.627257  \n",
      "Train Epoch[4] Step[7601 / 19085] - loss: 4.677446  \n",
      "Train Epoch[4] Step[7621 / 19085] - loss: 6.351326  \n",
      "Train Epoch[4] Step[7641 / 19085] - loss: 3.669696  \n",
      "Train Epoch[4] Step[7661 / 19085] - loss: 6.381381  \n",
      "Train Epoch[4] Step[7681 / 19085] - loss: 4.077106  \n",
      "Train Epoch[4] Step[7701 / 19085] - loss: 4.218129  \n",
      "Train Epoch[4] Step[7721 / 19085] - loss: 7.753501  \n",
      "Train Epoch[4] Step[7741 / 19085] - loss: 3.804424  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:26<00:00, 14.61it/s]\n",
      "Dev Loss: 5.366045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7215    0.5627    0.6323     26118\n",
      "         ORG     0.5238    0.0225    0.0431      1956\n",
      "         PER     0.7394    0.5689    0.6431     22839\n",
      "           T     0.8034    0.6046    0.6900     22956\n",
      "\n",
      "   micro avg     0.7525    0.5633    0.6443     73869\n",
      "   macro avg     0.6970    0.4397    0.5021     73869\n",
      "weighted avg     0.7473    0.5633    0.6379     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.64\n",
      "\n",
      "Train Epoch[4] Step[7761 / 19085] - loss: 6.347578  \n",
      "Train Epoch[4] Step[7781 / 19085] - loss: 4.221357  \n",
      "Train Epoch[4] Step[7801 / 19085] - loss: 5.217051  \n",
      "Train Epoch[4] Step[7821 / 19085] - loss: 2.238409  \n",
      "Train Epoch[4] Step[7841 / 19085] - loss: 10.916369  \n",
      "Train Epoch[4] Step[7861 / 19085] - loss: 4.928165  \n",
      "Train Epoch[4] Step[7881 / 19085] - loss: 4.608374  \n",
      "Train Epoch[4] Step[7901 / 19085] - loss: 7.317954  \n",
      "Train Epoch[4] Step[7921 / 19085] - loss: 4.016446  \n",
      "Train Epoch[4] Step[7941 / 19085] - loss: 4.138129  \n",
      "Train Epoch[4] Step[7961 / 19085] - loss: 6.160873  \n",
      "Train Epoch[4] Step[7981 / 19085] - loss: 4.932971  \n",
      "Train Epoch[4] Step[8001 / 19085] - loss: 5.117640  \n",
      "Train Epoch[4] Step[8021 / 19085] - loss: 1.841792  \n",
      "Train Epoch[4] Step[8041 / 19085] - loss: 5.348657  \n",
      "Train Epoch[4] Step[8061 / 19085] - loss: 1.941559  \n",
      "Train Epoch[4] Step[8081 / 19085] - loss: 5.123453  \n",
      "Train Epoch[4] Step[8101 / 19085] - loss: 6.157875  \n",
      "Train Epoch[4] Step[8121 / 19085] - loss: 3.616256  \n",
      "Train Epoch[4] Step[8141 / 19085] - loss: 6.590572  \n",
      "Train Epoch[4] Step[8161 / 19085] - loss: 3.424190  \n",
      "Train Epoch[4] Step[8181 / 19085] - loss: 9.073341  \n",
      "Train Epoch[4] Step[8201 / 19085] - loss: 5.475356  \n",
      "Train Epoch[4] Step[8221 / 19085] - loss: 6.931026  \n",
      "Train Epoch[4] Step[8241 / 19085] - loss: 8.333903  \n",
      "Train Epoch[4] Step[8261 / 19085] - loss: 6.180721  \n",
      "Train Epoch[4] Step[8281 / 19085] - loss: 4.897615  \n",
      "Train Epoch[4] Step[8301 / 19085] - loss: 6.720655  \n",
      "Train Epoch[4] Step[8321 / 19085] - loss: 5.339757  \n",
      "Train Epoch[4] Step[8341 / 19085] - loss: 10.331763  \n",
      "Train Epoch[4] Step[8361 / 19085] - loss: 5.304418  \n",
      "Train Epoch[4] Step[8381 / 19085] - loss: 8.079929  \n",
      "Train Epoch[4] Step[8401 / 19085] - loss: 3.612262  \n",
      "Train Epoch[4] Step[8421 / 19085] - loss: 2.904073  \n",
      "Train Epoch[4] Step[8441 / 19085] - loss: 5.383497  \n",
      "Train Epoch[4] Step[8461 / 19085] - loss: 4.203798  \n",
      "Train Epoch[4] Step[8481 / 19085] - loss: 4.684704  \n",
      "Train Epoch[4] Step[8501 / 19085] - loss: 5.987827  \n",
      "Train Epoch[4] Step[8521 / 19085] - loss: 9.143525  \n",
      "Train Epoch[4] Step[8541 / 19085] - loss: 4.766073  \n",
      "Train Epoch[4] Step[8561 / 19085] - loss: 9.205837  \n",
      "Train Epoch[4] Step[8581 / 19085] - loss: 6.531695  \n",
      "Train Epoch[4] Step[8601 / 19085] - loss: 3.079499  \n",
      "Train Epoch[4] Step[8621 / 19085] - loss: 4.157742  \n",
      "Train Epoch[4] Step[8641 / 19085] - loss: 8.718158  \n",
      "Train Epoch[4] Step[8661 / 19085] - loss: 3.568567  \n",
      "Train Epoch[4] Step[8681 / 19085] - loss: 5.959902  \n",
      "Train Epoch[4] Step[8701 / 19085] - loss: 2.821454  \n",
      "Train Epoch[4] Step[8721 / 19085] - loss: 4.988714  \n",
      "Train Epoch[4] Step[8741 / 19085] - loss: 4.487616  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:08<00:00, 15.45it/s]\n",
      "Dev Loss: 5.280099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7127    0.5902    0.6457     26118\n",
      "         ORG     0.5188    0.0353    0.0661      1956\n",
      "         PER     0.7367    0.5854    0.6524     22839\n",
      "           T     0.7927    0.6238    0.6982     22956\n",
      "\n",
      "   micro avg     0.7447    0.5845    0.6549     73869\n",
      "   macro avg     0.6902    0.4587    0.5156     73869\n",
      "weighted avg     0.7398    0.5845    0.6487     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[4] Step[8761 / 19085] - loss: 4.963743  \n",
      "Train Epoch[4] Step[8781 / 19085] - loss: 6.153919  \n",
      "Train Epoch[4] Step[8801 / 19085] - loss: 6.798341  \n",
      "Train Epoch[4] Step[8821 / 19085] - loss: 6.224463  \n",
      "Train Epoch[4] Step[8841 / 19085] - loss: 6.346470  \n",
      "Train Epoch[4] Step[8861 / 19085] - loss: 4.462684  \n",
      "Train Epoch[4] Step[8881 / 19085] - loss: 2.801230  \n",
      "Train Epoch[4] Step[8901 / 19085] - loss: 4.142478  \n",
      "Train Epoch[4] Step[8921 / 19085] - loss: 8.424992  \n",
      "Train Epoch[4] Step[8941 / 19085] - loss: 5.964083  \n",
      "Train Epoch[4] Step[8961 / 19085] - loss: 5.171309  \n",
      "Train Epoch[4] Step[8981 / 19085] - loss: 4.178428  \n",
      "Train Epoch[4] Step[9001 / 19085] - loss: 5.572366  \n",
      "Train Epoch[4] Step[9021 / 19085] - loss: 5.491047  \n",
      "Train Epoch[4] Step[9041 / 19085] - loss: 2.950191  \n",
      "Train Epoch[4] Step[9061 / 19085] - loss: 3.997451  \n",
      "Train Epoch[4] Step[9081 / 19085] - loss: 4.147296  \n",
      "Train Epoch[4] Step[9101 / 19085] - loss: 4.021409  \n",
      "Train Epoch[4] Step[9121 / 19085] - loss: 5.613210  \n",
      "Train Epoch[4] Step[9141 / 19085] - loss: 5.019088  \n",
      "Train Epoch[4] Step[9161 / 19085] - loss: 4.037247  \n",
      "Train Epoch[4] Step[9181 / 19085] - loss: 8.315693  \n",
      "Train Epoch[4] Step[9201 / 19085] - loss: 1.729559  \n",
      "Train Epoch[4] Step[9221 / 19085] - loss: 3.253848  \n",
      "Train Epoch[4] Step[9241 / 19085] - loss: 10.662262  \n",
      "Train Epoch[4] Step[9261 / 19085] - loss: 5.787979  \n",
      "Train Epoch[4] Step[9281 / 19085] - loss: 4.512057  \n",
      "Train Epoch[4] Step[9301 / 19085] - loss: 3.147572  \n",
      "Train Epoch[4] Step[9321 / 19085] - loss: 2.816116  \n",
      "Train Epoch[4] Step[9341 / 19085] - loss: 5.554979  \n",
      "Train Epoch[4] Step[9361 / 19085] - loss: 7.060464  \n",
      "Train Epoch[4] Step[9381 / 19085] - loss: 6.616424  \n",
      "Train Epoch[4] Step[9401 / 19085] - loss: 6.329532  \n",
      "Train Epoch[4] Step[9421 / 19085] - loss: 4.473444  \n",
      "Train Epoch[4] Step[9441 / 19085] - loss: 4.100052  \n",
      "Train Epoch[4] Step[9461 / 19085] - loss: 7.423732  \n",
      "Train Epoch[4] Step[9481 / 19085] - loss: 4.554218  \n",
      "Train Epoch[4] Step[9501 / 19085] - loss: 7.691830  \n",
      "Train Epoch[4] Step[9521 / 19085] - loss: 6.692306  \n",
      "Train Epoch[4] Step[9541 / 19085] - loss: 1.598561  \n",
      "Train Epoch[4] Step[9561 / 19085] - loss: 4.108797  \n",
      "Train Epoch[4] Step[9581 / 19085] - loss: 7.101064  \n",
      "Train Epoch[4] Step[9601 / 19085] - loss: 5.996184  \n",
      "Train Epoch[4] Step[9621 / 19085] - loss: 7.543664  \n",
      "Train Epoch[4] Step[9641 / 19085] - loss: 5.426334  \n",
      "Train Epoch[4] Step[9661 / 19085] - loss: 3.994614  \n",
      "Train Epoch[4] Step[9681 / 19085] - loss: 5.285637  \n",
      "Train Epoch[4] Step[9701 / 19085] - loss: 6.239252  \n",
      "Train Epoch[4] Step[9721 / 19085] - loss: 5.884159  \n",
      "Train Epoch[4] Step[9741 / 19085] - loss: 3.773261  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:06<00:00, 15.58it/s]\n",
      "Dev Loss: 5.261631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7153    0.5832    0.6425     26118\n",
      "         ORG     0.5512    0.0358    0.0672      1956\n",
      "         PER     0.7331    0.5892    0.6533     22839\n",
      "           T     0.7950    0.6240    0.6992     22956\n",
      "\n",
      "   micro avg     0.7454    0.5832    0.6544     73869\n",
      "   macro avg     0.6986    0.4580    0.5156     73869\n",
      "weighted avg     0.7412    0.5832    0.6482     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[9761 / 19085] - loss: 5.148609  \n",
      "Train Epoch[4] Step[9781 / 19085] - loss: 4.227051  \n",
      "Train Epoch[4] Step[9801 / 19085] - loss: 6.281732  \n",
      "Train Epoch[4] Step[9821 / 19085] - loss: 5.447659  \n",
      "Train Epoch[4] Step[9841 / 19085] - loss: 6.321748  \n",
      "Train Epoch[4] Step[9861 / 19085] - loss: 3.504739  \n",
      "Train Epoch[4] Step[9881 / 19085] - loss: 4.468457  \n",
      "Train Epoch[4] Step[9901 / 19085] - loss: 3.454231  \n",
      "Train Epoch[4] Step[9921 / 19085] - loss: 4.336477  \n",
      "Train Epoch[4] Step[9941 / 19085] - loss: 6.156202  \n",
      "Train Epoch[4] Step[9961 / 19085] - loss: 12.493713  \n",
      "Train Epoch[4] Step[9981 / 19085] - loss: 4.782442  \n",
      "Train Epoch[4] Step[10001 / 19085] - loss: 4.786714  \n",
      "Train Epoch[4] Step[10021 / 19085] - loss: 3.124469  \n",
      "Train Epoch[4] Step[10041 / 19085] - loss: 5.535313  \n",
      "Train Epoch[4] Step[10061 / 19085] - loss: 5.710580  \n",
      "Train Epoch[4] Step[10081 / 19085] - loss: 3.496469  \n",
      "Train Epoch[4] Step[10101 / 19085] - loss: 5.205486  \n",
      "Train Epoch[4] Step[10121 / 19085] - loss: 7.532949  \n",
      "Train Epoch[4] Step[10141 / 19085] - loss: 6.500163  \n",
      "Train Epoch[4] Step[10161 / 19085] - loss: 4.834421  \n",
      "Train Epoch[4] Step[10181 / 19085] - loss: 3.961238  \n",
      "Train Epoch[4] Step[10201 / 19085] - loss: 3.348574  \n",
      "Train Epoch[4] Step[10221 / 19085] - loss: 3.976107  \n",
      "Train Epoch[4] Step[10241 / 19085] - loss: 3.105144  \n",
      "Train Epoch[4] Step[10261 / 19085] - loss: 6.487220  \n",
      "Train Epoch[4] Step[10281 / 19085] - loss: 4.136467  \n",
      "Train Epoch[4] Step[10301 / 19085] - loss: 3.124096  \n",
      "Train Epoch[4] Step[10321 / 19085] - loss: 6.606556  \n",
      "Train Epoch[4] Step[10341 / 19085] - loss: 5.559457  \n",
      "Train Epoch[4] Step[10361 / 19085] - loss: 6.827224  \n",
      "Train Epoch[4] Step[10381 / 19085] - loss: 5.633661  \n",
      "Train Epoch[4] Step[10401 / 19085] - loss: 5.588136  \n",
      "Train Epoch[4] Step[10421 / 19085] - loss: 5.023272  \n",
      "Train Epoch[4] Step[10441 / 19085] - loss: 2.578411  \n",
      "Train Epoch[4] Step[10461 / 19085] - loss: 5.141571  \n",
      "Train Epoch[4] Step[10481 / 19085] - loss: 7.077152  \n",
      "Train Epoch[4] Step[10501 / 19085] - loss: 3.749832  \n",
      "Train Epoch[4] Step[10521 / 19085] - loss: 4.343885  \n",
      "Train Epoch[4] Step[10541 / 19085] - loss: 5.575231  \n",
      "Train Epoch[4] Step[10561 / 19085] - loss: 7.615898  \n",
      "Train Epoch[4] Step[10581 / 19085] - loss: 4.445980  \n",
      "Train Epoch[4] Step[10601 / 19085] - loss: 3.536812  \n",
      "Train Epoch[4] Step[10621 / 19085] - loss: 6.981268  \n",
      "Train Epoch[4] Step[10641 / 19085] - loss: 3.494743  \n",
      "Train Epoch[4] Step[10661 / 19085] - loss: 6.571727  \n",
      "Train Epoch[4] Step[10681 / 19085] - loss: 6.078103  \n",
      "Train Epoch[4] Step[10701 / 19085] - loss: 4.812562  \n",
      "Train Epoch[4] Step[10721 / 19085] - loss: 1.937226  \n",
      "Train Epoch[4] Step[10741 / 19085] - loss: 4.601886  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:12<00:00, 15.27it/s]\n",
      "Dev Loss: 5.259043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7194    0.5749    0.6391     26118\n",
      "         ORG     0.5231    0.0348    0.0652      1956\n",
      "         PER     0.7453    0.5725    0.6476     22839\n",
      "           T     0.7953    0.6233    0.6989     22956\n",
      "\n",
      "   micro avg     0.7511    0.5749    0.6513     73869\n",
      "   macro avg     0.6958    0.4514    0.5127     73869\n",
      "weighted avg     0.7458    0.5749    0.6451     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[10761 / 19085] - loss: 5.143724  \n",
      "Train Epoch[4] Step[10781 / 19085] - loss: 6.544456  \n",
      "Train Epoch[4] Step[10801 / 19085] - loss: 6.882319  \n",
      "Train Epoch[4] Step[10821 / 19085] - loss: 4.220722  \n",
      "Train Epoch[4] Step[10841 / 19085] - loss: 8.297529  \n",
      "Train Epoch[4] Step[10861 / 19085] - loss: 4.286791  \n",
      "Train Epoch[4] Step[10881 / 19085] - loss: 4.707604  \n",
      "Train Epoch[4] Step[10901 / 19085] - loss: 5.531849  \n",
      "Train Epoch[4] Step[10921 / 19085] - loss: 4.661822  \n",
      "Train Epoch[4] Step[10941 / 19085] - loss: 7.304778  \n",
      "Train Epoch[4] Step[10961 / 19085] - loss: 2.314084  \n",
      "Train Epoch[4] Step[10981 / 19085] - loss: 4.390368  \n",
      "Train Epoch[4] Step[11001 / 19085] - loss: 7.747392  \n",
      "Train Epoch[4] Step[11021 / 19085] - loss: 6.251218  \n",
      "Train Epoch[4] Step[11041 / 19085] - loss: 8.892055  \n",
      "Train Epoch[4] Step[11061 / 19085] - loss: 5.209738  \n",
      "Train Epoch[4] Step[11081 / 19085] - loss: 4.667085  \n",
      "Train Epoch[4] Step[11101 / 19085] - loss: 4.971272  \n",
      "Train Epoch[4] Step[11121 / 19085] - loss: 6.140695  \n",
      "Train Epoch[4] Step[11141 / 19085] - loss: 2.916464  \n",
      "Train Epoch[4] Step[11161 / 19085] - loss: 4.976923  \n",
      "Train Epoch[4] Step[11181 / 19085] - loss: 3.441233  \n",
      "Train Epoch[4] Step[11201 / 19085] - loss: 4.041966  \n",
      "Train Epoch[4] Step[11221 / 19085] - loss: 1.595138  \n",
      "Train Epoch[4] Step[11241 / 19085] - loss: 8.677111  \n",
      "Train Epoch[4] Step[11261 / 19085] - loss: 3.202143  \n",
      "Train Epoch[4] Step[11281 / 19085] - loss: 2.710608  \n",
      "Train Epoch[4] Step[11301 / 19085] - loss: 3.721539  \n",
      "Train Epoch[4] Step[11321 / 19085] - loss: 4.703841  \n",
      "Train Epoch[4] Step[11341 / 19085] - loss: 3.037158  \n",
      "Train Epoch[4] Step[11361 / 19085] - loss: 5.882610  \n",
      "Train Epoch[4] Step[11381 / 19085] - loss: 5.010655  \n",
      "Train Epoch[4] Step[11401 / 19085] - loss: 7.966636  \n",
      "Train Epoch[4] Step[11421 / 19085] - loss: 4.580369  \n",
      "Train Epoch[4] Step[11441 / 19085] - loss: 6.196178  \n",
      "Train Epoch[4] Step[11461 / 19085] - loss: 6.253617  \n",
      "Train Epoch[4] Step[11481 / 19085] - loss: 2.544557  \n",
      "Train Epoch[4] Step[11501 / 19085] - loss: 3.156706  \n",
      "Train Epoch[4] Step[11521 / 19085] - loss: 5.376342  \n",
      "Train Epoch[4] Step[11541 / 19085] - loss: 5.625608  \n",
      "Train Epoch[4] Step[11561 / 19085] - loss: 4.602300  \n",
      "Train Epoch[4] Step[11581 / 19085] - loss: 3.514983  \n",
      "Train Epoch[4] Step[11601 / 19085] - loss: 2.959614  \n",
      "Train Epoch[4] Step[11621 / 19085] - loss: 7.602411  \n",
      "Train Epoch[4] Step[11641 / 19085] - loss: 7.659613  \n",
      "Train Epoch[4] Step[11661 / 19085] - loss: 8.291110  \n",
      "Train Epoch[4] Step[11681 / 19085] - loss: 8.634204  \n",
      "Train Epoch[4] Step[11701 / 19085] - loss: 8.307101  \n",
      "Train Epoch[4] Step[11721 / 19085] - loss: 3.914589  \n",
      "Train Epoch[4] Step[11741 / 19085] - loss: 3.040508  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:10<00:00, 15.36it/s]\n",
      "Dev Loss: 5.291313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7197    0.5665    0.6340     26118\n",
      "         ORG     0.5698    0.0251    0.0480      1956\n",
      "         PER     0.7527    0.5562    0.6397     22839\n",
      "           T     0.8049    0.5983    0.6864     22956\n",
      "\n",
      "   micro avg     0.7563    0.5589    0.6428     73869\n",
      "   macro avg     0.7117    0.4365    0.5020     73869\n",
      "weighted avg     0.7524    0.5589    0.6365     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.64\n",
      "\n",
      "Train Epoch[4] Step[11761 / 19085] - loss: 7.585745  \n",
      "Train Epoch[4] Step[11781 / 19085] - loss: 5.092849  \n",
      "Train Epoch[4] Step[11801 / 19085] - loss: 6.945971  \n",
      "Train Epoch[4] Step[11821 / 19085] - loss: 6.447248  \n",
      "Train Epoch[4] Step[11841 / 19085] - loss: 5.109258  \n",
      "Train Epoch[4] Step[11861 / 19085] - loss: 6.071699  \n",
      "Train Epoch[4] Step[11881 / 19085] - loss: 7.342937  \n",
      "Train Epoch[4] Step[11901 / 19085] - loss: 3.378091  \n",
      "Train Epoch[4] Step[11921 / 19085] - loss: 6.327152  \n",
      "Train Epoch[4] Step[11941 / 19085] - loss: 2.288918  \n",
      "Train Epoch[4] Step[11961 / 19085] - loss: 7.510231  \n",
      "Train Epoch[4] Step[11981 / 19085] - loss: 4.414876  \n",
      "Train Epoch[4] Step[12001 / 19085] - loss: 4.986470  \n",
      "Train Epoch[4] Step[12021 / 19085] - loss: 4.534829  \n",
      "Train Epoch[4] Step[12041 / 19085] - loss: 5.650334  \n",
      "Train Epoch[4] Step[12061 / 19085] - loss: 2.708771  \n",
      "Train Epoch[4] Step[12081 / 19085] - loss: 3.165355  \n",
      "Train Epoch[4] Step[12101 / 19085] - loss: 7.351749  \n",
      "Train Epoch[4] Step[12121 / 19085] - loss: 3.434589  \n",
      "Train Epoch[4] Step[12141 / 19085] - loss: 3.402182  \n",
      "Train Epoch[4] Step[12161 / 19085] - loss: 3.200272  \n",
      "Train Epoch[4] Step[12181 / 19085] - loss: 6.959146  \n",
      "Train Epoch[4] Step[12201 / 19085] - loss: 3.222326  \n",
      "Train Epoch[4] Step[12221 / 19085] - loss: 9.032064  \n",
      "Train Epoch[4] Step[12241 / 19085] - loss: 2.804976  \n",
      "Train Epoch[4] Step[12261 / 19085] - loss: 4.602407  \n",
      "Train Epoch[4] Step[12281 / 19085] - loss: 2.291266  \n",
      "Train Epoch[4] Step[12301 / 19085] - loss: 6.600782  \n",
      "Train Epoch[4] Step[12321 / 19085] - loss: 4.720109  \n",
      "Train Epoch[4] Step[12341 / 19085] - loss: 4.857596  \n",
      "Train Epoch[4] Step[12361 / 19085] - loss: 3.043039  \n",
      "Train Epoch[4] Step[12381 / 19085] - loss: 5.232727  \n",
      "Train Epoch[4] Step[12401 / 19085] - loss: 6.435949  \n",
      "Train Epoch[4] Step[12421 / 19085] - loss: 2.850786  \n",
      "Train Epoch[4] Step[12441 / 19085] - loss: 5.047099  \n",
      "Train Epoch[4] Step[12461 / 19085] - loss: 6.901772  \n",
      "Train Epoch[4] Step[12481 / 19085] - loss: 2.043558  \n",
      "Train Epoch[4] Step[12501 / 19085] - loss: 5.991255  \n",
      "Train Epoch[4] Step[12521 / 19085] - loss: 5.944615  \n",
      "Train Epoch[4] Step[12541 / 19085] - loss: 4.462545  \n",
      "Train Epoch[4] Step[12561 / 19085] - loss: 3.474575  \n",
      "Train Epoch[4] Step[12581 / 19085] - loss: 6.387707  \n",
      "Train Epoch[4] Step[12601 / 19085] - loss: 4.078513  \n",
      "Train Epoch[4] Step[12621 / 19085] - loss: 2.920657  \n",
      "Train Epoch[4] Step[12641 / 19085] - loss: 5.176036  \n",
      "Train Epoch[4] Step[12661 / 19085] - loss: 2.828024  \n",
      "Train Epoch[4] Step[12681 / 19085] - loss: 2.076577  \n",
      "Train Epoch[4] Step[12701 / 19085] - loss: 2.468771  \n",
      "Train Epoch[4] Step[12721 / 19085] - loss: 6.116881  \n",
      "Train Epoch[4] Step[12741 / 19085] - loss: 4.619075  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:09<00:00, 15.40it/s]\n",
      "Dev Loss: 5.202957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7186    0.5804    0.6421     26118\n",
      "         ORG     0.5423    0.0394    0.0734      1956\n",
      "         PER     0.7396    0.5854    0.6535     22839\n",
      "           T     0.7981    0.6207    0.6983     22956\n",
      "\n",
      "   micro avg     0.7496    0.5801    0.6541     73869\n",
      "   macro avg     0.6996    0.4565    0.5168     73869\n",
      "weighted avg     0.7451    0.5801    0.6481     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[12761 / 19085] - loss: 6.325066  \n",
      "Train Epoch[4] Step[12781 / 19085] - loss: 5.522165  \n",
      "Train Epoch[4] Step[12801 / 19085] - loss: 7.548110  \n",
      "Train Epoch[4] Step[12821 / 19085] - loss: 3.179768  \n",
      "Train Epoch[4] Step[12841 / 19085] - loss: 3.920591  \n",
      "Train Epoch[4] Step[12861 / 19085] - loss: 6.425709  \n",
      "Train Epoch[4] Step[12881 / 19085] - loss: 6.018327  \n",
      "Train Epoch[4] Step[12901 / 19085] - loss: 3.682696  \n",
      "Train Epoch[4] Step[12921 / 19085] - loss: 6.194529  \n",
      "Train Epoch[4] Step[12941 / 19085] - loss: 3.326426  \n",
      "Train Epoch[4] Step[12961 / 19085] - loss: 5.278429  \n",
      "Train Epoch[4] Step[12981 / 19085] - loss: 4.917687  \n",
      "Train Epoch[4] Step[13001 / 19085] - loss: 6.934386  \n",
      "Train Epoch[4] Step[13021 / 19085] - loss: 3.651703  \n",
      "Train Epoch[4] Step[13041 / 19085] - loss: 4.293131  \n",
      "Train Epoch[4] Step[13061 / 19085] - loss: 6.946190  \n",
      "Train Epoch[4] Step[13081 / 19085] - loss: 6.191784  \n",
      "Train Epoch[4] Step[13101 / 19085] - loss: 4.152877  \n",
      "Train Epoch[4] Step[13121 / 19085] - loss: 9.886095  \n",
      "Train Epoch[4] Step[13141 / 19085] - loss: 6.059051  \n",
      "Train Epoch[4] Step[13161 / 19085] - loss: 4.415711  \n",
      "Train Epoch[4] Step[13181 / 19085] - loss: 2.113498  \n",
      "Train Epoch[4] Step[13201 / 19085] - loss: 3.915383  \n",
      "Train Epoch[4] Step[13221 / 19085] - loss: 3.926838  \n",
      "Train Epoch[4] Step[13241 / 19085] - loss: 7.153505  \n",
      "Train Epoch[4] Step[13261 / 19085] - loss: 5.676166  \n",
      "Train Epoch[4] Step[13281 / 19085] - loss: 6.045188  \n",
      "Train Epoch[4] Step[13301 / 19085] - loss: 6.208149  \n",
      "Train Epoch[4] Step[13321 / 19085] - loss: 4.235225  \n",
      "Train Epoch[4] Step[13341 / 19085] - loss: 3.751474  \n",
      "Train Epoch[4] Step[13361 / 19085] - loss: 5.848188  \n",
      "Train Epoch[4] Step[13381 / 19085] - loss: 2.445597  \n",
      "Train Epoch[4] Step[13401 / 19085] - loss: 4.682736  \n",
      "Train Epoch[4] Step[13421 / 19085] - loss: 6.048299  \n",
      "Train Epoch[4] Step[13441 / 19085] - loss: 2.434547  \n",
      "Train Epoch[4] Step[13461 / 19085] - loss: 6.312843  \n",
      "Train Epoch[4] Step[13481 / 19085] - loss: 4.111304  \n",
      "Train Epoch[4] Step[13501 / 19085] - loss: 4.968435  \n",
      "Train Epoch[4] Step[13521 / 19085] - loss: 3.647106  \n",
      "Train Epoch[4] Step[13541 / 19085] - loss: 7.718986  \n",
      "Train Epoch[4] Step[13561 / 19085] - loss: 5.035280  \n",
      "Train Epoch[4] Step[13581 / 19085] - loss: 2.920977  \n",
      "Train Epoch[4] Step[13601 / 19085] - loss: 5.321776  \n",
      "Train Epoch[4] Step[13621 / 19085] - loss: 4.510459  \n",
      "Train Epoch[4] Step[13641 / 19085] - loss: 3.623513  \n",
      "Train Epoch[4] Step[13661 / 19085] - loss: 9.458065  \n",
      "Train Epoch[4] Step[13681 / 19085] - loss: 4.121993  \n",
      "Train Epoch[4] Step[13701 / 19085] - loss: 11.591431  \n",
      "Train Epoch[4] Step[13721 / 19085] - loss: 3.290352  \n",
      "Train Epoch[4] Step[13741 / 19085] - loss: 4.355102  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:07<00:00, 15.54it/s]\n",
      "Dev Loss: 5.180022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7171    0.5845    0.6441     26118\n",
      "         ORG     0.5349    0.0353    0.0662      1956\n",
      "         PER     0.7444    0.5826    0.6536     22839\n",
      "           T     0.7961    0.6234    0.6992     22956\n",
      "\n",
      "   micro avg     0.7500    0.5815    0.6551     73869\n",
      "   macro avg     0.6981    0.4565    0.5158     73869\n",
      "weighted avg     0.7453    0.5815    0.6489     73869\n",
      "\n",
      "best f1: 0.65, current f1: 0.66\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[4] Step[13761 / 19085] - loss: 3.927729  \n",
      "Train Epoch[4] Step[13781 / 19085] - loss: 4.219412  \n",
      "Train Epoch[4] Step[13801 / 19085] - loss: 4.890853  \n",
      "Train Epoch[4] Step[13821 / 19085] - loss: 4.428985  \n",
      "Train Epoch[4] Step[13841 / 19085] - loss: 7.108966  \n",
      "Train Epoch[4] Step[13861 / 19085] - loss: 3.342855  \n",
      "Train Epoch[4] Step[13881 / 19085] - loss: 3.958572  \n",
      "Train Epoch[4] Step[13901 / 19085] - loss: 6.834750  \n",
      "Train Epoch[4] Step[13921 / 19085] - loss: 5.806534  \n",
      "Train Epoch[4] Step[13941 / 19085] - loss: 3.321342  \n",
      "Train Epoch[4] Step[13961 / 19085] - loss: 4.926790  \n",
      "Train Epoch[4] Step[13981 / 19085] - loss: 8.753576  \n",
      "Train Epoch[4] Step[14001 / 19085] - loss: 4.416726  \n",
      "Train Epoch[4] Step[14021 / 19085] - loss: 3.032088  \n",
      "Train Epoch[4] Step[14041 / 19085] - loss: 6.662050  \n",
      "Train Epoch[4] Step[14061 / 19085] - loss: 4.112144  \n",
      "Train Epoch[4] Step[14081 / 19085] - loss: 4.804899  \n",
      "Train Epoch[4] Step[14101 / 19085] - loss: 2.517286  \n",
      "Train Epoch[4] Step[14121 / 19085] - loss: 4.117773  \n",
      "Train Epoch[4] Step[14141 / 19085] - loss: 3.517444  \n",
      "Train Epoch[4] Step[14161 / 19085] - loss: 6.523868  \n",
      "Train Epoch[4] Step[14181 / 19085] - loss: 2.857973  \n",
      "Train Epoch[4] Step[14201 / 19085] - loss: 5.274110  \n",
      "Train Epoch[4] Step[14221 / 19085] - loss: 2.274468  \n",
      "Train Epoch[4] Step[14241 / 19085] - loss: 3.872029  \n",
      "Train Epoch[4] Step[14261 / 19085] - loss: 6.096127  \n",
      "Train Epoch[4] Step[14281 / 19085] - loss: 2.771090  \n",
      "Train Epoch[4] Step[14301 / 19085] - loss: 5.465234  \n",
      "Train Epoch[4] Step[14321 / 19085] - loss: 5.515043  \n",
      "Train Epoch[4] Step[14341 / 19085] - loss: 7.176380  \n",
      "Train Epoch[4] Step[14361 / 19085] - loss: 3.410527  \n",
      "Train Epoch[4] Step[14381 / 19085] - loss: 2.627547  \n",
      "Train Epoch[4] Step[14401 / 19085] - loss: 3.064142  \n",
      "Train Epoch[4] Step[14421 / 19085] - loss: 4.567136  \n",
      "Train Epoch[4] Step[14441 / 19085] - loss: 5.984266  \n",
      "Train Epoch[4] Step[14461 / 19085] - loss: 2.925404  \n",
      "Train Epoch[4] Step[14481 / 19085] - loss: 6.049090  \n",
      "Train Epoch[4] Step[14501 / 19085] - loss: 5.350314  \n",
      "Train Epoch[4] Step[14521 / 19085] - loss: 3.105923  \n",
      "Train Epoch[4] Step[14541 / 19085] - loss: 4.783115  \n",
      "Train Epoch[4] Step[14561 / 19085] - loss: 6.715069  \n",
      "Train Epoch[4] Step[14581 / 19085] - loss: 4.682651  \n",
      "Train Epoch[4] Step[14601 / 19085] - loss: 6.171586  \n",
      "Train Epoch[4] Step[14621 / 19085] - loss: 5.983830  \n",
      "Train Epoch[4] Step[14641 / 19085] - loss: 5.795216  \n",
      "Train Epoch[4] Step[14661 / 19085] - loss: 4.949970  \n",
      "Train Epoch[4] Step[14681 / 19085] - loss: 2.579392  \n",
      "Train Epoch[4] Step[14701 / 19085] - loss: 6.288412  \n",
      "Train Epoch[4] Step[14721 / 19085] - loss: 4.750184  \n",
      "Train Epoch[4] Step[14741 / 19085] - loss: 7.820267  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:08<00:00, 15.46it/s]\n",
      "Dev Loss: 5.170403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7111    0.5928    0.6466     26118\n",
      "         ORG     0.5865    0.0312    0.0592      1956\n",
      "         PER     0.7515    0.5727    0.6501     22839\n",
      "           T     0.8004    0.6199    0.6987     22956\n",
      "\n",
      "   micro avg     0.7510    0.5802    0.6546     73869\n",
      "   macro avg     0.7124    0.4542    0.5136     73869\n",
      "weighted avg     0.7480    0.5802    0.6483     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[14761 / 19085] - loss: 7.679090  \n",
      "Train Epoch[4] Step[14781 / 19085] - loss: 3.192391  \n",
      "Train Epoch[4] Step[14801 / 19085] - loss: 7.205940  \n",
      "Train Epoch[4] Step[14821 / 19085] - loss: 2.755470  \n",
      "Train Epoch[4] Step[14841 / 19085] - loss: 6.563422  \n",
      "Train Epoch[4] Step[14861 / 19085] - loss: 4.662952  \n",
      "Train Epoch[4] Step[14881 / 19085] - loss: 4.183496  \n",
      "Train Epoch[4] Step[14901 / 19085] - loss: 7.188119  \n",
      "Train Epoch[4] Step[14921 / 19085] - loss: 6.004140  \n",
      "Train Epoch[4] Step[14941 / 19085] - loss: 3.135964  \n",
      "Train Epoch[4] Step[14961 / 19085] - loss: 4.629519  \n",
      "Train Epoch[4] Step[14981 / 19085] - loss: 3.034665  \n",
      "Train Epoch[4] Step[15001 / 19085] - loss: 4.207872  \n",
      "Train Epoch[4] Step[15021 / 19085] - loss: 2.675568  \n",
      "Train Epoch[4] Step[15041 / 19085] - loss: 4.540961  \n",
      "Train Epoch[4] Step[15061 / 19085] - loss: 6.221627  \n",
      "Train Epoch[4] Step[15081 / 19085] - loss: 6.048600  \n",
      "Train Epoch[4] Step[15101 / 19085] - loss: 2.815718  \n",
      "Train Epoch[4] Step[15121 / 19085] - loss: 5.789901  \n",
      "Train Epoch[4] Step[15141 / 19085] - loss: 5.353372  \n",
      "Train Epoch[4] Step[15161 / 19085] - loss: 3.374718  \n",
      "Train Epoch[4] Step[15181 / 19085] - loss: 4.458550  \n",
      "Train Epoch[4] Step[15201 / 19085] - loss: 7.341792  \n",
      "Train Epoch[4] Step[15221 / 19085] - loss: 6.906515  \n",
      "Train Epoch[4] Step[15241 / 19085] - loss: 3.876803  \n",
      "Train Epoch[4] Step[15261 / 19085] - loss: 3.115464  \n",
      "Train Epoch[4] Step[15281 / 19085] - loss: 5.733221  \n",
      "Train Epoch[4] Step[15301 / 19085] - loss: 5.581050  \n",
      "Train Epoch[4] Step[15321 / 19085] - loss: 6.602815  \n",
      "Train Epoch[4] Step[15341 / 19085] - loss: 2.675140  \n",
      "Train Epoch[4] Step[15361 / 19085] - loss: 7.203619  \n",
      "Train Epoch[4] Step[15381 / 19085] - loss: 3.425400  \n",
      "Train Epoch[4] Step[15401 / 19085] - loss: 5.444596  \n",
      "Train Epoch[4] Step[15421 / 19085] - loss: 2.600014  \n",
      "Train Epoch[4] Step[15441 / 19085] - loss: 6.990896  \n",
      "Train Epoch[4] Step[15461 / 19085] - loss: 6.665056  \n",
      "Train Epoch[4] Step[15481 / 19085] - loss: 3.005543  \n",
      "Train Epoch[4] Step[15501 / 19085] - loss: 6.920522  \n",
      "Train Epoch[4] Step[15521 / 19085] - loss: 3.928118  \n",
      "Train Epoch[4] Step[15541 / 19085] - loss: 3.703501  \n",
      "Train Epoch[4] Step[15561 / 19085] - loss: 4.241900  \n",
      "Train Epoch[4] Step[15581 / 19085] - loss: 4.687249  \n",
      "Train Epoch[4] Step[15601 / 19085] - loss: 6.409003  \n",
      "Train Epoch[4] Step[15621 / 19085] - loss: 8.106124  \n",
      "Train Epoch[4] Step[15641 / 19085] - loss: 5.428728  \n",
      "Train Epoch[4] Step[15661 / 19085] - loss: 4.253519  \n",
      "Train Epoch[4] Step[15681 / 19085] - loss: 7.658644  \n",
      "Train Epoch[4] Step[15701 / 19085] - loss: 4.376092  \n",
      "Train Epoch[4] Step[15721 / 19085] - loss: 6.702543  \n",
      "Train Epoch[4] Step[15741 / 19085] - loss: 6.988236  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:10<00:00, 15.38it/s]\n",
      "Dev Loss: 5.161330\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7235    0.5698    0.6375     26118\n",
      "         ORG     0.5563    0.0404    0.0753      1956\n",
      "         PER     0.7433    0.5850    0.6547     22839\n",
      "           T     0.8012    0.6202    0.6992     22956\n",
      "\n",
      "   micro avg     0.7539    0.5761    0.6531     73869\n",
      "   macro avg     0.7061    0.4538    0.5167     73869\n",
      "weighted avg     0.7494    0.5761    0.6471     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[15761 / 19085] - loss: 3.773135  \n",
      "Train Epoch[4] Step[15781 / 19085] - loss: 5.426083  \n",
      "Train Epoch[4] Step[15801 / 19085] - loss: 5.163141  \n",
      "Train Epoch[4] Step[15821 / 19085] - loss: 5.492867  \n",
      "Train Epoch[4] Step[15841 / 19085] - loss: 5.709528  \n",
      "Train Epoch[4] Step[15861 / 19085] - loss: 7.182629  \n",
      "Train Epoch[4] Step[15881 / 19085] - loss: 3.497608  \n",
      "Train Epoch[4] Step[15901 / 19085] - loss: 3.905281  \n",
      "Train Epoch[4] Step[15921 / 19085] - loss: 7.615237  \n",
      "Train Epoch[4] Step[15941 / 19085] - loss: 4.738619  \n",
      "Train Epoch[4] Step[15961 / 19085] - loss: 4.135904  \n",
      "Train Epoch[4] Step[15981 / 19085] - loss: 8.051929  \n",
      "Train Epoch[4] Step[16001 / 19085] - loss: 4.489275  \n",
      "Train Epoch[4] Step[16021 / 19085] - loss: 6.353498  \n",
      "Train Epoch[4] Step[16041 / 19085] - loss: 4.313956  \n",
      "Train Epoch[4] Step[16061 / 19085] - loss: 2.313289  \n",
      "Train Epoch[4] Step[16081 / 19085] - loss: 7.139154  \n",
      "Train Epoch[4] Step[16101 / 19085] - loss: 4.645150  \n",
      "Train Epoch[4] Step[16121 / 19085] - loss: 5.042706  \n",
      "Train Epoch[4] Step[16141 / 19085] - loss: 3.068306  \n",
      "Train Epoch[4] Step[16161 / 19085] - loss: 6.935606  \n",
      "Train Epoch[4] Step[16181 / 19085] - loss: 4.297510  \n",
      "Train Epoch[4] Step[16201 / 19085] - loss: 5.954504  \n",
      "Train Epoch[4] Step[16221 / 19085] - loss: 3.402989  \n",
      "Train Epoch[4] Step[16241 / 19085] - loss: 2.285481  \n",
      "Train Epoch[4] Step[16261 / 19085] - loss: 4.509534  \n",
      "Train Epoch[4] Step[16281 / 19085] - loss: 8.492975  \n",
      "Train Epoch[4] Step[16301 / 19085] - loss: 6.987862  \n",
      "Train Epoch[4] Step[16321 / 19085] - loss: 3.001967  \n",
      "Train Epoch[4] Step[16341 / 19085] - loss: 8.675091  \n",
      "Train Epoch[4] Step[16361 / 19085] - loss: 2.732933  \n",
      "Train Epoch[4] Step[16381 / 19085] - loss: 3.955908  \n",
      "Train Epoch[4] Step[16401 / 19085] - loss: 7.537305  \n",
      "Train Epoch[4] Step[16421 / 19085] - loss: 2.670344  \n",
      "Train Epoch[4] Step[16441 / 19085] - loss: 5.866617  \n",
      "Train Epoch[4] Step[16461 / 19085] - loss: 9.617727  \n",
      "Train Epoch[4] Step[16481 / 19085] - loss: 3.778982  \n",
      "Train Epoch[4] Step[16501 / 19085] - loss: 5.343577  \n",
      "Train Epoch[4] Step[16521 / 19085] - loss: 4.088663  \n",
      "Train Epoch[4] Step[16541 / 19085] - loss: 3.376760  \n",
      "Train Epoch[4] Step[16561 / 19085] - loss: 3.327261  \n",
      "Train Epoch[4] Step[16581 / 19085] - loss: 2.804915  \n",
      "Train Epoch[4] Step[16601 / 19085] - loss: 4.920601  \n",
      "Train Epoch[4] Step[16621 / 19085] - loss: 2.902400  \n",
      "Train Epoch[4] Step[16641 / 19085] - loss: 13.810787  \n",
      "Train Epoch[4] Step[16661 / 19085] - loss: 6.157186  \n",
      "Train Epoch[4] Step[16681 / 19085] - loss: 7.945721  \n",
      "Train Epoch[4] Step[16701 / 19085] - loss: 4.377986  \n",
      "Train Epoch[4] Step[16721 / 19085] - loss: 4.592649  \n",
      "Train Epoch[4] Step[16741 / 19085] - loss: 5.754198  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:08<00:00, 15.49it/s]\n",
      "Dev Loss: 5.140491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7205    0.5791    0.6421     26118\n",
      "         ORG     0.5818    0.0327    0.0620      1956\n",
      "         PER     0.7520    0.5754    0.6519     22839\n",
      "           T     0.7992    0.6269    0.7027     22956\n",
      "\n",
      "   micro avg     0.7550    0.5783    0.6550     73869\n",
      "   macro avg     0.7134    0.4535    0.5147     73869\n",
      "weighted avg     0.7510    0.5783    0.6486     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.65\n",
      "\n",
      "Train Epoch[4] Step[16761 / 19085] - loss: 2.013285  \n",
      "Train Epoch[4] Step[16781 / 19085] - loss: 3.787756  \n",
      "Train Epoch[4] Step[16801 / 19085] - loss: 4.151953  \n",
      "Train Epoch[4] Step[16821 / 19085] - loss: 3.114403  \n",
      "Train Epoch[4] Step[16841 / 19085] - loss: 3.780972  \n",
      "Train Epoch[4] Step[16861 / 19085] - loss: 7.154947  \n",
      "Train Epoch[4] Step[16881 / 19085] - loss: 12.517612  \n",
      "Train Epoch[4] Step[16901 / 19085] - loss: 4.950490  \n",
      "Train Epoch[4] Step[16921 / 19085] - loss: 9.750613  \n",
      "Train Epoch[4] Step[16941 / 19085] - loss: 3.667608  \n",
      "Train Epoch[4] Step[16961 / 19085] - loss: 6.478648  \n",
      "Train Epoch[4] Step[16981 / 19085] - loss: 4.288191  \n",
      "Train Epoch[4] Step[17001 / 19085] - loss: 3.908062  \n",
      "Train Epoch[4] Step[17021 / 19085] - loss: 3.469493  \n",
      "Train Epoch[4] Step[17041 / 19085] - loss: 4.023984  \n",
      "Train Epoch[4] Step[17061 / 19085] - loss: 2.484999  \n",
      "Train Epoch[4] Step[17081 / 19085] - loss: 3.753065  \n",
      "Train Epoch[4] Step[17101 / 19085] - loss: 3.892537  \n",
      "Train Epoch[4] Step[17121 / 19085] - loss: 5.193511  \n",
      "Train Epoch[4] Step[17141 / 19085] - loss: 4.709091  \n",
      "Train Epoch[4] Step[17161 / 19085] - loss: 3.634561  \n",
      "Train Epoch[4] Step[17181 / 19085] - loss: 8.087497  \n",
      "Train Epoch[4] Step[17201 / 19085] - loss: 7.528754  \n",
      "Train Epoch[4] Step[17221 / 19085] - loss: 4.001996  \n",
      "Train Epoch[4] Step[17241 / 19085] - loss: 6.013279  \n",
      "Train Epoch[4] Step[17261 / 19085] - loss: 6.579462  \n",
      "Train Epoch[4] Step[17281 / 19085] - loss: 7.235534  \n",
      "Train Epoch[4] Step[17301 / 19085] - loss: 4.203095  \n",
      "Train Epoch[4] Step[17321 / 19085] - loss: 4.566734  \n",
      "Train Epoch[4] Step[17341 / 19085] - loss: 5.699860  \n",
      "Train Epoch[4] Step[17361 / 19085] - loss: 4.798738  \n",
      "Train Epoch[4] Step[17381 / 19085] - loss: 4.245189  \n",
      "Train Epoch[4] Step[17401 / 19085] - loss: 5.222330  \n",
      "Train Epoch[4] Step[17421 / 19085] - loss: 6.626691  \n",
      "Train Epoch[4] Step[17441 / 19085] - loss: 2.923566  \n",
      "Train Epoch[4] Step[17461 / 19085] - loss: 3.006925  \n",
      "Train Epoch[4] Step[17481 / 19085] - loss: 8.689257  \n",
      "Train Epoch[4] Step[17501 / 19085] - loss: 3.030843  \n",
      "Train Epoch[4] Step[17521 / 19085] - loss: 5.854902  \n",
      "Train Epoch[4] Step[17541 / 19085] - loss: 1.470952  \n",
      "Train Epoch[4] Step[17561 / 19085] - loss: 4.449989  \n",
      "Train Epoch[4] Step[17581 / 19085] - loss: 6.750688  \n",
      "Train Epoch[4] Step[17601 / 19085] - loss: 4.576026  \n",
      "Train Epoch[4] Step[17621 / 19085] - loss: 5.845210  \n",
      "Train Epoch[4] Step[17641 / 19085] - loss: 3.586802  \n",
      "Train Epoch[4] Step[17661 / 19085] - loss: 5.793952  \n",
      "Train Epoch[4] Step[17681 / 19085] - loss: 2.309821  \n",
      "Train Epoch[4] Step[17701 / 19085] - loss: 6.581924  \n",
      "Train Epoch[4] Step[17721 / 19085] - loss: 7.901346  \n",
      "Train Epoch[4] Step[17741 / 19085] - loss: 8.479867  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:05<00:00, 15.61it/s]\n",
      "Dev Loss: 5.114298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7231    0.5775    0.6422     26118\n",
      "         ORG     0.5705    0.0455    0.0843      1956\n",
      "         PER     0.7469    0.5852    0.6562     22839\n",
      "           T     0.7966    0.6235    0.6995     22956\n",
      "\n",
      "   micro avg     0.7534    0.5801    0.6555     73869\n",
      "   macro avg     0.7093    0.4579    0.5206     73869\n",
      "weighted avg     0.7493    0.5801    0.6496     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[4] Step[17761 / 19085] - loss: 8.705290  \n",
      "Train Epoch[4] Step[17781 / 19085] - loss: 3.392882  \n",
      "Train Epoch[4] Step[17801 / 19085] - loss: 2.315164  \n",
      "Train Epoch[4] Step[17821 / 19085] - loss: 9.565738  \n",
      "Train Epoch[4] Step[17841 / 19085] - loss: 4.855817  \n",
      "Train Epoch[4] Step[17861 / 19085] - loss: 3.738057  \n",
      "Train Epoch[4] Step[17881 / 19085] - loss: 3.824661  \n",
      "Train Epoch[4] Step[17901 / 19085] - loss: 4.914523  \n",
      "Train Epoch[4] Step[17921 / 19085] - loss: 3.098810  \n",
      "Train Epoch[4] Step[17941 / 19085] - loss: 4.206032  \n",
      "Train Epoch[4] Step[17961 / 19085] - loss: 4.831365  \n",
      "Train Epoch[4] Step[17981 / 19085] - loss: 6.063920  \n",
      "Train Epoch[4] Step[18001 / 19085] - loss: 4.483941  \n",
      "Train Epoch[4] Step[18021 / 19085] - loss: 9.029391  \n",
      "Train Epoch[4] Step[18041 / 19085] - loss: 8.146825  \n",
      "Train Epoch[4] Step[18061 / 19085] - loss: 6.811054  \n",
      "Train Epoch[4] Step[18081 / 19085] - loss: 3.864384  \n",
      "Train Epoch[4] Step[18101 / 19085] - loss: 3.751299  \n",
      "Train Epoch[4] Step[18121 / 19085] - loss: 4.802979  \n",
      "Train Epoch[4] Step[18141 / 19085] - loss: 3.785079  \n",
      "Train Epoch[4] Step[18161 / 19085] - loss: 5.777288  \n",
      "Train Epoch[4] Step[18181 / 19085] - loss: 5.061029  \n",
      "Train Epoch[4] Step[18201 / 19085] - loss: 18.637558  \n",
      "Train Epoch[4] Step[18221 / 19085] - loss: 3.328327  \n",
      "Train Epoch[4] Step[18241 / 19085] - loss: 5.536948  \n",
      "Train Epoch[4] Step[18261 / 19085] - loss: 4.809485  \n",
      "Train Epoch[4] Step[18281 / 19085] - loss: 6.752917  \n",
      "Train Epoch[4] Step[18301 / 19085] - loss: 9.401726  \n",
      "Train Epoch[4] Step[18321 / 19085] - loss: 6.141033  \n",
      "Train Epoch[4] Step[18341 / 19085] - loss: 5.169873  \n",
      "Train Epoch[4] Step[18361 / 19085] - loss: 3.612178  \n",
      "Train Epoch[4] Step[18381 / 19085] - loss: 5.408031  \n",
      "Train Epoch[4] Step[18401 / 19085] - loss: 3.964315  \n",
      "Train Epoch[4] Step[18421 / 19085] - loss: 2.064461  \n",
      "Train Epoch[4] Step[18441 / 19085] - loss: 1.342917  \n",
      "Train Epoch[4] Step[18461 / 19085] - loss: 5.158247  \n",
      "Train Epoch[4] Step[18481 / 19085] - loss: 3.181879  \n",
      "Train Epoch[4] Step[18501 / 19085] - loss: 2.785747  \n",
      "Train Epoch[4] Step[18521 / 19085] - loss: 2.325030  \n",
      "Train Epoch[4] Step[18541 / 19085] - loss: 4.051140  \n",
      "Train Epoch[4] Step[18561 / 19085] - loss: 3.164951  \n",
      "Train Epoch[4] Step[18581 / 19085] - loss: 4.144146  \n",
      "Train Epoch[4] Step[18601 / 19085] - loss: 4.194688  \n",
      "Train Epoch[4] Step[18621 / 19085] - loss: 7.361284  \n",
      "Train Epoch[4] Step[18641 / 19085] - loss: 4.400616  \n",
      "Train Epoch[4] Step[18661 / 19085] - loss: 4.337768  \n",
      "Train Epoch[4] Step[18681 / 19085] - loss: 5.356281  \n",
      "Train Epoch[4] Step[18701 / 19085] - loss: 6.967873  \n",
      "Train Epoch[4] Step[18721 / 19085] - loss: 7.061474  \n",
      "Train Epoch[4] Step[18741 / 19085] - loss: 3.640713  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:11<00:00, 15.30it/s]\n",
      "Dev Loss: 5.094572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7193    0.5863    0.6461     26118\n",
      "         ORG     0.6034    0.0358    0.0676      1956\n",
      "         PER     0.7527    0.5805    0.6555     22839\n",
      "           T     0.7927    0.6323    0.7035     22956\n",
      "\n",
      "   micro avg     0.7528    0.5842    0.6579     73869\n",
      "   macro avg     0.7170    0.4587    0.5181     73869\n",
      "weighted avg     0.7494    0.5842    0.6515     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[4] Step[18761 / 19085] - loss: 4.181401  \n",
      "Train Epoch[4] Step[18781 / 19085] - loss: 7.953094  \n",
      "Train Epoch[4] Step[18801 / 19085] - loss: 4.943617  \n",
      "Train Epoch[4] Step[18821 / 19085] - loss: 3.347833  \n",
      "Train Epoch[4] Step[18841 / 19085] - loss: 4.937995  \n",
      "Train Epoch[4] Step[18861 / 19085] - loss: 5.049368  \n",
      "Train Epoch[4] Step[18881 / 19085] - loss: 3.299594  \n",
      "Train Epoch[4] Step[18901 / 19085] - loss: 4.378222  \n",
      "Train Epoch[4] Step[18921 / 19085] - loss: 4.114870  \n",
      "Train Epoch[4] Step[18941 / 19085] - loss: 8.631327  \n",
      "Train Epoch[4] Step[18961 / 19085] - loss: 4.666093  \n",
      "Train Epoch[4] Step[18981 / 19085] - loss: 3.166699  \n",
      "Train Epoch[4] Step[19001 / 19085] - loss: 5.024250  \n",
      "Train Epoch[4] Step[19021 / 19085] - loss: 2.403595  \n",
      "Train Epoch[4] Step[19041 / 19085] - loss: 5.243127  \n",
      "Train Epoch[4] Step[19061 / 19085] - loss: 2.992516  \n",
      "Train Epoch[4] Step[19081 / 19085] - loss: 4.063302  \n",
      "Train Epoch[5] Step[1 / 19085] - loss: 7.697070  \n",
      "Train Epoch[5] Step[21 / 19085] - loss: 5.776855  \n",
      "Train Epoch[5] Step[41 / 19085] - loss: 6.590278  \n",
      "Train Epoch[5] Step[61 / 19085] - loss: 5.815282  \n",
      "Train Epoch[5] Step[81 / 19085] - loss: 4.635008  \n",
      "Train Epoch[5] Step[101 / 19085] - loss: 5.932578  \n",
      "Train Epoch[5] Step[121 / 19085] - loss: 5.879223  \n",
      "Train Epoch[5] Step[141 / 19085] - loss: 12.137386  \n",
      "Train Epoch[5] Step[161 / 19085] - loss: 4.319289  \n",
      "Train Epoch[5] Step[181 / 19085] - loss: 5.683887  \n",
      "Train Epoch[5] Step[201 / 19085] - loss: 5.358846  \n",
      "Train Epoch[5] Step[221 / 19085] - loss: 3.692886  \n",
      "Train Epoch[5] Step[241 / 19085] - loss: 5.448633  \n",
      "Train Epoch[5] Step[261 / 19085] - loss: 3.613108  \n",
      "Train Epoch[5] Step[281 / 19085] - loss: 5.031447  \n",
      "Train Epoch[5] Step[301 / 19085] - loss: 4.747184  \n",
      "Train Epoch[5] Step[321 / 19085] - loss: 4.927195  \n",
      "Train Epoch[5] Step[341 / 19085] - loss: 7.782004  \n",
      "Train Epoch[5] Step[361 / 19085] - loss: 4.158509  \n",
      "Train Epoch[5] Step[381 / 19085] - loss: 8.622218  \n",
      "Train Epoch[5] Step[401 / 19085] - loss: 4.080415  \n",
      "Train Epoch[5] Step[421 / 19085] - loss: 8.033493  \n",
      "Train Epoch[5] Step[441 / 19085] - loss: 3.407546  \n",
      "Train Epoch[5] Step[461 / 19085] - loss: 4.289085  \n",
      "Train Epoch[5] Step[481 / 19085] - loss: 6.901174  \n",
      "Train Epoch[5] Step[501 / 19085] - loss: 3.504000  \n",
      "Train Epoch[5] Step[521 / 19085] - loss: 2.262595  \n",
      "Train Epoch[5] Step[541 / 19085] - loss: 3.669819  \n",
      "Train Epoch[5] Step[561 / 19085] - loss: 5.187795  \n",
      "Train Epoch[5] Step[581 / 19085] - loss: 2.953574  \n",
      "Train Epoch[5] Step[601 / 19085] - loss: 5.311996  \n",
      "Train Epoch[5] Step[621 / 19085] - loss: 3.603900  \n",
      "Train Epoch[5] Step[641 / 19085] - loss: 2.620450  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:11<00:00, 15.30it/s]\n",
      "Dev Loss: 5.093851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7211    0.5815    0.6438     26118\n",
      "         ORG     0.6000    0.0337    0.0639      1956\n",
      "         PER     0.7547    0.5775    0.6543     22839\n",
      "           T     0.7990    0.6281    0.7033     22956\n",
      "\n",
      "   micro avg     0.7560    0.5802    0.6566     73869\n",
      "   macro avg     0.7187    0.4552    0.5163     73869\n",
      "weighted avg     0.7525    0.5802    0.6502     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "Train Epoch[5] Step[661 / 19085] - loss: 5.738346  \n",
      "Train Epoch[5] Step[681 / 19085] - loss: 2.905842  \n",
      "Train Epoch[5] Step[701 / 19085] - loss: 2.846013  \n",
      "Train Epoch[5] Step[721 / 19085] - loss: 3.825541  \n",
      "Train Epoch[5] Step[741 / 19085] - loss: 1.753440  \n",
      "Train Epoch[5] Step[761 / 19085] - loss: 4.204292  \n",
      "Train Epoch[5] Step[781 / 19085] - loss: 3.506550  \n",
      "Train Epoch[5] Step[801 / 19085] - loss: 4.412633  \n",
      "Train Epoch[5] Step[821 / 19085] - loss: 4.060602  \n",
      "Train Epoch[5] Step[841 / 19085] - loss: 4.140936  \n",
      "Train Epoch[5] Step[861 / 19085] - loss: 7.528795  \n",
      "Train Epoch[5] Step[881 / 19085] - loss: 4.116209  \n",
      "Train Epoch[5] Step[901 / 19085] - loss: 5.056859  \n",
      "Train Epoch[5] Step[921 / 19085] - loss: 4.379306  \n",
      "Train Epoch[5] Step[941 / 19085] - loss: 5.246036  \n",
      "Train Epoch[5] Step[961 / 19085] - loss: 4.291613  \n",
      "Train Epoch[5] Step[981 / 19085] - loss: 6.608787  \n",
      "Train Epoch[5] Step[1001 / 19085] - loss: 2.928373  \n",
      "Train Epoch[5] Step[1021 / 19085] - loss: 4.482328  \n",
      "Train Epoch[5] Step[1041 / 19085] - loss: 3.142056  \n",
      "Train Epoch[5] Step[1061 / 19085] - loss: 4.133121  \n",
      "Train Epoch[5] Step[1081 / 19085] - loss: 6.122016  \n",
      "Train Epoch[5] Step[1101 / 19085] - loss: 3.836699  \n",
      "Train Epoch[5] Step[1121 / 19085] - loss: 4.713722  \n",
      "Train Epoch[5] Step[1141 / 19085] - loss: 3.911067  \n",
      "Train Epoch[5] Step[1161 / 19085] - loss: 5.745121  \n",
      "Train Epoch[5] Step[1181 / 19085] - loss: 2.540139  \n",
      "Train Epoch[5] Step[1201 / 19085] - loss: 5.223160  \n",
      "Train Epoch[5] Step[1221 / 19085] - loss: 6.099388  \n",
      "Train Epoch[5] Step[1241 / 19085] - loss: 5.951306  \n",
      "Train Epoch[5] Step[1261 / 19085] - loss: 9.266623  \n",
      "Train Epoch[5] Step[1281 / 19085] - loss: 5.183681  \n",
      "Train Epoch[5] Step[1301 / 19085] - loss: 3.727734  \n",
      "Train Epoch[5] Step[1321 / 19085] - loss: 4.536295  \n",
      "Train Epoch[5] Step[1341 / 19085] - loss: 6.139593  \n",
      "Train Epoch[5] Step[1361 / 19085] - loss: 3.424686  \n",
      "Train Epoch[5] Step[1381 / 19085] - loss: 7.496396  \n",
      "Train Epoch[5] Step[1401 / 19085] - loss: 2.483021  \n",
      "Train Epoch[5] Step[1421 / 19085] - loss: 1.786801  \n",
      "Train Epoch[5] Step[1441 / 19085] - loss: 3.440567  \n",
      "Train Epoch[5] Step[1461 / 19085] - loss: 5.093243  \n",
      "Train Epoch[5] Step[1481 / 19085] - loss: 5.747254  \n",
      "Train Epoch[5] Step[1501 / 19085] - loss: 4.737009  \n",
      "Train Epoch[5] Step[1521 / 19085] - loss: 5.681674  \n",
      "Train Epoch[5] Step[1541 / 19085] - loss: 7.828479  \n",
      "Train Epoch[5] Step[1561 / 19085] - loss: 5.453897  \n",
      "Train Epoch[5] Step[1581 / 19085] - loss: 3.374018  \n",
      "Train Epoch[5] Step[1601 / 19085] - loss: 3.247755  \n",
      "Train Epoch[5] Step[1621 / 19085] - loss: 7.249249  \n",
      "Train Epoch[5] Step[1641 / 19085] - loss: 5.105188  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:09<00:00, 15.39it/s]\n",
      "Dev Loss: 5.070745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7215    0.5856    0.6465     26118\n",
      "         ORG     0.5705    0.0455    0.0843      1956\n",
      "         PER     0.7545    0.5797    0.6556     22839\n",
      "           T     0.7960    0.6302    0.7034     22956\n",
      "\n",
      "   micro avg     0.7549    0.5833    0.6581     73869\n",
      "   macro avg     0.7106    0.4602    0.5225     73869\n",
      "weighted avg     0.7508    0.5833    0.6521     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[5] Step[1661 / 19085] - loss: 2.397667  \n",
      "Train Epoch[5] Step[1681 / 19085] - loss: 5.058974  \n",
      "Train Epoch[5] Step[1701 / 19085] - loss: 3.674298  \n",
      "Train Epoch[5] Step[1721 / 19085] - loss: 7.559154  \n",
      "Train Epoch[5] Step[1741 / 19085] - loss: 5.368744  \n",
      "Train Epoch[5] Step[1761 / 19085] - loss: 6.336865  \n",
      "Train Epoch[5] Step[1781 / 19085] - loss: 4.067327  \n",
      "Train Epoch[5] Step[1801 / 19085] - loss: 2.615428  \n",
      "Train Epoch[5] Step[1821 / 19085] - loss: 3.845759  \n",
      "Train Epoch[5] Step[1841 / 19085] - loss: 3.035478  \n",
      "Train Epoch[5] Step[1861 / 19085] - loss: 3.629333  \n",
      "Train Epoch[5] Step[1881 / 19085] - loss: 3.410799  \n",
      "Train Epoch[5] Step[1901 / 19085] - loss: 3.123420  \n",
      "Train Epoch[5] Step[1921 / 19085] - loss: 6.553298  \n",
      "Train Epoch[5] Step[1941 / 19085] - loss: 7.235233  \n",
      "Train Epoch[5] Step[1961 / 19085] - loss: 10.983722  \n",
      "Train Epoch[5] Step[1981 / 19085] - loss: 8.196141  \n",
      "Train Epoch[5] Step[2001 / 19085] - loss: 3.144892  \n",
      "Train Epoch[5] Step[2021 / 19085] - loss: 5.789659  \n",
      "Train Epoch[5] Step[2041 / 19085] - loss: 7.086021  \n",
      "Train Epoch[5] Step[2061 / 19085] - loss: 6.069248  \n",
      "Train Epoch[5] Step[2081 / 19085] - loss: 3.418813  \n",
      "Train Epoch[5] Step[2101 / 19085] - loss: 5.186099  \n",
      "Train Epoch[5] Step[2121 / 19085] - loss: 5.142784  \n",
      "Train Epoch[5] Step[2141 / 19085] - loss: 3.930830  \n",
      "Train Epoch[5] Step[2161 / 19085] - loss: 3.486982  \n",
      "Train Epoch[5] Step[2181 / 19085] - loss: 5.117039  \n",
      "Train Epoch[5] Step[2201 / 19085] - loss: 9.839882  \n",
      "Train Epoch[5] Step[2221 / 19085] - loss: 5.058732  \n",
      "Train Epoch[5] Step[2241 / 19085] - loss: 6.194782  \n",
      "Train Epoch[5] Step[2261 / 19085] - loss: 11.456322  \n",
      "Train Epoch[5] Step[2281 / 19085] - loss: 8.374921  \n",
      "Train Epoch[5] Step[2301 / 19085] - loss: 4.365857  \n",
      "Train Epoch[5] Step[2321 / 19085] - loss: 7.439434  \n",
      "Train Epoch[5] Step[2341 / 19085] - loss: 4.571351  \n",
      "Train Epoch[5] Step[2361 / 19085] - loss: 7.630550  \n",
      "Train Epoch[5] Step[2381 / 19085] - loss: 5.432552  \n",
      "Train Epoch[5] Step[2401 / 19085] - loss: 2.727374  \n",
      "Train Epoch[5] Step[2421 / 19085] - loss: 5.483646  \n",
      "Train Epoch[5] Step[2441 / 19085] - loss: 6.232257  \n",
      "Train Epoch[5] Step[2461 / 19085] - loss: 9.108111  \n",
      "Train Epoch[5] Step[2481 / 19085] - loss: 10.835478  \n",
      "Train Epoch[5] Step[2501 / 19085] - loss: 9.552668  \n",
      "Train Epoch[5] Step[2521 / 19085] - loss: 4.389138  \n",
      "Train Epoch[5] Step[2541 / 19085] - loss: 5.704748  \n",
      "Train Epoch[5] Step[2561 / 19085] - loss: 3.964217  \n",
      "Train Epoch[5] Step[2581 / 19085] - loss: 4.347068  \n",
      "Train Epoch[5] Step[2601 / 19085] - loss: 6.732246  \n",
      "Train Epoch[5] Step[2621 / 19085] - loss: 6.329271  \n",
      "Train Epoch[5] Step[2641 / 19085] - loss: 2.938582  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:27<00:00, 14.57it/s]\n",
      "Dev Loss: 5.057844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7194    0.5897    0.6481     26118\n",
      "         ORG     0.6075    0.0332    0.0630      1956\n",
      "         PER     0.7521    0.5868    0.6592     22839\n",
      "           T     0.8005    0.6232    0.7008     22956\n",
      "\n",
      "   micro avg     0.7547    0.5845    0.6588     73869\n",
      "   macro avg     0.7199    0.4582    0.5178     73869\n",
      "weighted avg     0.7517    0.5845    0.6524     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[5] Step[2661 / 19085] - loss: 5.805921  \n",
      "Train Epoch[5] Step[2681 / 19085] - loss: 7.851971  \n",
      "Train Epoch[5] Step[2701 / 19085] - loss: 5.681353  \n",
      "Train Epoch[5] Step[2721 / 19085] - loss: 5.230505  \n",
      "Train Epoch[5] Step[2741 / 19085] - loss: 4.693446  \n",
      "Train Epoch[5] Step[2761 / 19085] - loss: 9.784759  \n",
      "Train Epoch[5] Step[2781 / 19085] - loss: 3.497461  \n",
      "Train Epoch[5] Step[2801 / 19085] - loss: 1.438185  \n",
      "Train Epoch[5] Step[2821 / 19085] - loss: 5.906183  \n",
      "Train Epoch[5] Step[2841 / 19085] - loss: 4.110826  \n",
      "Train Epoch[5] Step[2861 / 19085] - loss: 2.176451  \n",
      "Train Epoch[5] Step[2881 / 19085] - loss: 2.793972  \n",
      "Train Epoch[5] Step[2901 / 19085] - loss: 8.634539  \n",
      "Train Epoch[5] Step[2921 / 19085] - loss: 6.822244  \n",
      "Train Epoch[5] Step[2941 / 19085] - loss: 5.889770  \n",
      "Train Epoch[5] Step[2961 / 19085] - loss: 3.422591  \n",
      "Train Epoch[5] Step[2981 / 19085] - loss: 5.010040  \n",
      "Train Epoch[5] Step[3001 / 19085] - loss: 5.719877  \n",
      "Train Epoch[5] Step[3021 / 19085] - loss: 7.813655  \n",
      "Train Epoch[5] Step[3041 / 19085] - loss: 5.916990  \n",
      "Train Epoch[5] Step[3061 / 19085] - loss: 5.010519  \n",
      "Train Epoch[5] Step[3081 / 19085] - loss: 6.701153  \n",
      "Train Epoch[5] Step[3101 / 19085] - loss: 2.875632  \n",
      "Train Epoch[5] Step[3121 / 19085] - loss: 7.401347  \n",
      "Train Epoch[5] Step[3141 / 19085] - loss: 3.168690  \n",
      "Train Epoch[5] Step[3161 / 19085] - loss: 5.174684  \n",
      "Train Epoch[5] Step[3181 / 19085] - loss: 6.387148  \n",
      "Train Epoch[5] Step[3201 / 19085] - loss: 4.147749  \n",
      "Train Epoch[5] Step[3221 / 19085] - loss: 5.148954  \n",
      "Train Epoch[5] Step[3241 / 19085] - loss: 4.939901  \n",
      "Train Epoch[5] Step[3261 / 19085] - loss: 6.106288  \n",
      "Train Epoch[5] Step[3281 / 19085] - loss: 8.255754  \n",
      "Train Epoch[5] Step[3301 / 19085] - loss: 3.492830  \n",
      "Train Epoch[5] Step[3321 / 19085] - loss: 6.406672  \n",
      "Train Epoch[5] Step[3341 / 19085] - loss: 6.528386  \n",
      "Train Epoch[5] Step[3361 / 19085] - loss: 4.196241  \n",
      "Train Epoch[5] Step[3381 / 19085] - loss: 3.259771  \n",
      "Train Epoch[5] Step[3401 / 19085] - loss: 6.579888  \n",
      "Train Epoch[5] Step[3421 / 19085] - loss: 3.106572  \n",
      "Train Epoch[5] Step[3441 / 19085] - loss: 6.098479  \n",
      "Train Epoch[5] Step[3461 / 19085] - loss: 14.700600  \n",
      "Train Epoch[5] Step[3481 / 19085] - loss: 4.083918  \n",
      "Train Epoch[5] Step[3501 / 19085] - loss: 9.003584  \n",
      "Train Epoch[5] Step[3521 / 19085] - loss: 3.266589  \n",
      "Train Epoch[5] Step[3541 / 19085] - loss: 5.490742  \n",
      "Train Epoch[5] Step[3561 / 19085] - loss: 8.427292  \n",
      "Train Epoch[5] Step[3581 / 19085] - loss: 4.484416  \n",
      "Train Epoch[5] Step[3601 / 19085] - loss: 9.352070  \n",
      "Train Epoch[5] Step[3621 / 19085] - loss: 6.918660  \n",
      "Train Epoch[5] Step[3641 / 19085] - loss: 6.610686  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:33<00:00, 12.12it/s]\n",
      "Dev Loss: 5.021629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7173    0.5951    0.6505     26118\n",
      "         ORG     0.6000    0.0368    0.0694      1956\n",
      "         PER     0.7452    0.6020    0.6660     22839\n",
      "           T     0.7923    0.6341    0.7044     22956\n",
      "\n",
      "   micro avg     0.7493    0.5946    0.6630     73869\n",
      "   macro avg     0.7137    0.4670    0.5226     73869\n",
      "weighted avg     0.7461    0.5946    0.6566     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[5] Step[3661 / 19085] - loss: 3.610164  \n",
      "Train Epoch[5] Step[3681 / 19085] - loss: 2.646136  \n",
      "Train Epoch[5] Step[3701 / 19085] - loss: 1.831057  \n",
      "Train Epoch[5] Step[3721 / 19085] - loss: 1.781424  \n",
      "Train Epoch[5] Step[3741 / 19085] - loss: 2.483864  \n",
      "Train Epoch[5] Step[3761 / 19085] - loss: 3.396570  \n",
      "Train Epoch[5] Step[3781 / 19085] - loss: 5.781433  \n",
      "Train Epoch[5] Step[3801 / 19085] - loss: 5.711062  \n",
      "Train Epoch[5] Step[3821 / 19085] - loss: 4.691813  \n",
      "Train Epoch[5] Step[3841 / 19085] - loss: 6.141276  \n",
      "Train Epoch[5] Step[3861 / 19085] - loss: 4.624518  \n",
      "Train Epoch[5] Step[3881 / 19085] - loss: 6.558155  \n",
      "Train Epoch[5] Step[3901 / 19085] - loss: 1.935043  \n",
      "Train Epoch[5] Step[3921 / 19085] - loss: 4.550853  \n",
      "Train Epoch[5] Step[3941 / 19085] - loss: 3.750870  \n",
      "Train Epoch[5] Step[3961 / 19085] - loss: 9.911869  \n",
      "Train Epoch[5] Step[3981 / 19085] - loss: 5.271588  \n",
      "Train Epoch[5] Step[4001 / 19085] - loss: 5.774617  \n",
      "Train Epoch[5] Step[4021 / 19085] - loss: 6.490784  \n",
      "Train Epoch[5] Step[4041 / 19085] - loss: 4.651165  \n",
      "Train Epoch[5] Step[4061 / 19085] - loss: 4.689347  \n",
      "Train Epoch[5] Step[4081 / 19085] - loss: 7.136074  \n",
      "Train Epoch[5] Step[4101 / 19085] - loss: 2.461411  \n",
      "Train Epoch[5] Step[4121 / 19085] - loss: 4.468969  \n",
      "Train Epoch[5] Step[4141 / 19085] - loss: 5.220907  \n",
      "Train Epoch[5] Step[4161 / 19085] - loss: 2.201216  \n",
      "Train Epoch[5] Step[4181 / 19085] - loss: 6.554626  \n",
      "Train Epoch[5] Step[4201 / 19085] - loss: 4.290119  \n",
      "Train Epoch[5] Step[4221 / 19085] - loss: 4.704441  \n",
      "Train Epoch[5] Step[4241 / 19085] - loss: 6.036392  \n",
      "Train Epoch[5] Step[4261 / 19085] - loss: 1.953016  \n",
      "Train Epoch[5] Step[4281 / 19085] - loss: 4.868704  \n",
      "Train Epoch[5] Step[4301 / 19085] - loss: 2.088130  \n",
      "Train Epoch[5] Step[4321 / 19085] - loss: 5.130197  \n",
      "Train Epoch[5] Step[4341 / 19085] - loss: 4.248934  \n",
      "Train Epoch[5] Step[4361 / 19085] - loss: 4.385526  \n",
      "Train Epoch[5] Step[4381 / 19085] - loss: 8.288168  \n",
      "Train Epoch[5] Step[4401 / 19085] - loss: 10.355274  \n",
      "Train Epoch[5] Step[4421 / 19085] - loss: 3.831062  \n",
      "Train Epoch[5] Step[4441 / 19085] - loss: 3.568061  \n",
      "Train Epoch[5] Step[4461 / 19085] - loss: 3.550487  \n",
      "Train Epoch[5] Step[4481 / 19085] - loss: 9.897815  \n",
      "Train Epoch[5] Step[4501 / 19085] - loss: 2.148982  \n",
      "Train Epoch[5] Step[4521 / 19085] - loss: 6.709808  \n",
      "Train Epoch[5] Step[4541 / 19085] - loss: 2.832680  \n",
      "Train Epoch[5] Step[4561 / 19085] - loss: 3.665650  \n",
      "Train Epoch[5] Step[4581 / 19085] - loss: 2.599924  \n",
      "Train Epoch[5] Step[4601 / 19085] - loss: 5.548580  \n",
      "Train Epoch[5] Step[4621 / 19085] - loss: 3.564972  \n",
      "Train Epoch[5] Step[4641 / 19085] - loss: 3.854277  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:48<00:00, 11.67it/s]\n",
      "Dev Loss: 5.021647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7193    0.5936    0.6504     26118\n",
      "         ORG     0.6014    0.0424    0.0793      1956\n",
      "         PER     0.7500    0.5960    0.6642     22839\n",
      "           T     0.8004    0.6272    0.7033     22956\n",
      "\n",
      "   micro avg     0.7539    0.5902    0.6621     73869\n",
      "   macro avg     0.7178    0.4648    0.5243     73869\n",
      "weighted avg     0.7508    0.5902    0.6560     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "Train Epoch[5] Step[4661 / 19085] - loss: 5.378423  \n",
      "Train Epoch[5] Step[4681 / 19085] - loss: 3.214624  \n",
      "Train Epoch[5] Step[4701 / 19085] - loss: 5.337926  \n",
      "Train Epoch[5] Step[4721 / 19085] - loss: 2.713318  \n",
      "Train Epoch[5] Step[4741 / 19085] - loss: 4.842928  \n",
      "Train Epoch[5] Step[4761 / 19085] - loss: 3.737277  \n",
      "Train Epoch[5] Step[4781 / 19085] - loss: 5.950895  \n",
      "Train Epoch[5] Step[4801 / 19085] - loss: 6.633449  \n",
      "Train Epoch[5] Step[4821 / 19085] - loss: 6.268768  \n",
      "Train Epoch[5] Step[4841 / 19085] - loss: 2.290192  \n",
      "Train Epoch[5] Step[4861 / 19085] - loss: 1.989448  \n",
      "Train Epoch[5] Step[4881 / 19085] - loss: 4.586071  \n",
      "Train Epoch[5] Step[4901 / 19085] - loss: 4.957618  \n",
      "Train Epoch[5] Step[4921 / 19085] - loss: 3.981677  \n",
      "Train Epoch[5] Step[4941 / 19085] - loss: 4.647214  \n",
      "Train Epoch[5] Step[4961 / 19085] - loss: 4.154828  \n",
      "Train Epoch[5] Step[4981 / 19085] - loss: 3.704918  \n",
      "Train Epoch[5] Step[5001 / 19085] - loss: 3.189044  \n",
      "Train Epoch[5] Step[5021 / 19085] - loss: 4.592506  \n",
      "Train Epoch[5] Step[5041 / 19085] - loss: 3.567840  \n",
      "Train Epoch[5] Step[5061 / 19085] - loss: 2.157212  \n",
      "Train Epoch[5] Step[5081 / 19085] - loss: 9.448019  \n",
      "Train Epoch[5] Step[5101 / 19085] - loss: 4.722708  \n",
      "Train Epoch[5] Step[5121 / 19085] - loss: 1.520798  \n",
      "Train Epoch[5] Step[5141 / 19085] - loss: 6.582817  \n",
      "Train Epoch[5] Step[5161 / 19085] - loss: 5.747102  \n",
      "Train Epoch[5] Step[5181 / 19085] - loss: 2.830914  \n",
      "Train Epoch[5] Step[5201 / 19085] - loss: 1.952736  \n",
      "Train Epoch[5] Step[5221 / 19085] - loss: 6.523571  \n",
      "Train Epoch[5] Step[5241 / 19085] - loss: 4.336704  \n",
      "Train Epoch[5] Step[5261 / 19085] - loss: 4.480180  \n",
      "Train Epoch[5] Step[5281 / 19085] - loss: 4.496934  \n",
      "Train Epoch[5] Step[5301 / 19085] - loss: 5.467061  \n",
      "Train Epoch[5] Step[5321 / 19085] - loss: 2.901966  \n",
      "Train Epoch[5] Step[5341 / 19085] - loss: 5.919826  \n",
      "Train Epoch[5] Step[5361 / 19085] - loss: 5.650185  \n",
      "Train Epoch[5] Step[5381 / 19085] - loss: 5.692698  \n",
      "Train Epoch[5] Step[5401 / 19085] - loss: 4.911169  \n",
      "Train Epoch[5] Step[5421 / 19085] - loss: 4.704436  \n",
      "Train Epoch[5] Step[5441 / 19085] - loss: 5.593488  \n",
      "Train Epoch[5] Step[5461 / 19085] - loss: 4.539171  \n",
      "Train Epoch[5] Step[5481 / 19085] - loss: 3.048363  \n",
      "Train Epoch[5] Step[5501 / 19085] - loss: 4.326150  \n",
      "Train Epoch[5] Step[5521 / 19085] - loss: 4.438332  \n",
      "Train Epoch[5] Step[5541 / 19085] - loss: 2.167896  \n",
      "Train Epoch[5] Step[5561 / 19085] - loss: 3.950019  \n",
      "Train Epoch[5] Step[5581 / 19085] - loss: 4.501169  \n",
      "Train Epoch[5] Step[5601 / 19085] - loss: 5.366493  \n",
      "Train Epoch[5] Step[5621 / 19085] - loss: 4.655796  \n",
      "Train Epoch[5] Step[5641 / 19085] - loss: 5.812944  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:26<00:00, 12.35it/s]\n",
      "Dev Loss: 5.028489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7222    0.5868    0.6475     26118\n",
      "         ORG     0.6048    0.0383    0.0721      1956\n",
      "         PER     0.7524    0.5881    0.6601     22839\n",
      "           T     0.8030    0.6233    0.7018     22956\n",
      "\n",
      "   micro avg     0.7566    0.5840    0.6592     73869\n",
      "   macro avg     0.7206    0.4591    0.5204     73869\n",
      "weighted avg     0.7535    0.5840    0.6530     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "Train Epoch[5] Step[5661 / 19085] - loss: 6.095602  \n",
      "Train Epoch[5] Step[5681 / 19085] - loss: 4.855333  \n",
      "Train Epoch[5] Step[5701 / 19085] - loss: 7.390214  \n",
      "Train Epoch[5] Step[5721 / 19085] - loss: 6.267448  \n",
      "Train Epoch[5] Step[5741 / 19085] - loss: 3.256485  \n",
      "Train Epoch[5] Step[5761 / 19085] - loss: 3.247756  \n",
      "Train Epoch[5] Step[5781 / 19085] - loss: 3.728410  \n",
      "Train Epoch[5] Step[5801 / 19085] - loss: 8.958977  \n",
      "Train Epoch[5] Step[5821 / 19085] - loss: 6.225091  \n",
      "Train Epoch[5] Step[5841 / 19085] - loss: 4.797341  \n",
      "Train Epoch[5] Step[5861 / 19085] - loss: 3.333849  \n",
      "Train Epoch[5] Step[5881 / 19085] - loss: 4.429226  \n",
      "Train Epoch[5] Step[5901 / 19085] - loss: 2.239658  \n",
      "Train Epoch[5] Step[5921 / 19085] - loss: 1.966870  \n",
      "Train Epoch[5] Step[5941 / 19085] - loss: 1.207672  \n",
      "Train Epoch[5] Step[5961 / 19085] - loss: 3.635718  \n",
      "Train Epoch[5] Step[5981 / 19085] - loss: 4.071513  \n",
      "Train Epoch[5] Step[6001 / 19085] - loss: 2.676301  \n",
      "Train Epoch[5] Step[6021 / 19085] - loss: 4.075505  \n",
      "Train Epoch[5] Step[6041 / 19085] - loss: 5.708162  \n",
      "Train Epoch[5] Step[6061 / 19085] - loss: 9.029100  \n",
      "Train Epoch[5] Step[6081 / 19085] - loss: 5.553531  \n",
      "Train Epoch[5] Step[6101 / 19085] - loss: 5.960149  \n",
      "Train Epoch[5] Step[6121 / 19085] - loss: 4.654951  \n",
      "Train Epoch[5] Step[6141 / 19085] - loss: 3.788910  \n",
      "Train Epoch[5] Step[6161 / 19085] - loss: 3.444812  \n",
      "Train Epoch[5] Step[6181 / 19085] - loss: 2.765009  \n",
      "Train Epoch[5] Step[6201 / 19085] - loss: 6.810284  \n",
      "Train Epoch[5] Step[6221 / 19085] - loss: 3.820045  \n",
      "Train Epoch[5] Step[6241 / 19085] - loss: 5.073181  \n",
      "Train Epoch[5] Step[6261 / 19085] - loss: 6.060842  \n",
      "Train Epoch[5] Step[6281 / 19085] - loss: 2.916507  \n",
      "Train Epoch[5] Step[6301 / 19085] - loss: 7.655408  \n",
      "Train Epoch[5] Step[6321 / 19085] - loss: 6.416096  \n",
      "Train Epoch[5] Step[6341 / 19085] - loss: 5.334377  \n",
      "Train Epoch[5] Step[6361 / 19085] - loss: 3.609776  \n",
      "Train Epoch[5] Step[6381 / 19085] - loss: 6.773767  \n",
      "Train Epoch[5] Step[6401 / 19085] - loss: 2.856433  \n",
      "Train Epoch[5] Step[6421 / 19085] - loss: 5.522012  \n",
      "Train Epoch[5] Step[6441 / 19085] - loss: 4.984203  \n",
      "Train Epoch[5] Step[6461 / 19085] - loss: 3.626002  \n",
      "Train Epoch[5] Step[6481 / 19085] - loss: 10.958778  \n",
      "Train Epoch[5] Step[6501 / 19085] - loss: 6.430914  \n",
      "Train Epoch[5] Step[6521 / 19085] - loss: 4.288806  \n",
      "Train Epoch[5] Step[6541 / 19085] - loss: 3.496077  \n",
      "Train Epoch[5] Step[6561 / 19085] - loss: 1.508753  \n",
      "Train Epoch[5] Step[6581 / 19085] - loss: 4.958052  \n",
      "Train Epoch[5] Step[6601 / 19085] - loss: 6.944994  \n",
      "Train Epoch[5] Step[6621 / 19085] - loss: 6.137319  \n",
      "Train Epoch[5] Step[6641 / 19085] - loss: 4.732969  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [05:50<00:00, 13.61it/s]\n",
      "Dev Loss: 4.987253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7152    0.5996    0.6523     26118\n",
      "         ORG     0.5957    0.0429    0.0801      1956\n",
      "         PER     0.7468    0.6025    0.6670     22839\n",
      "           T     0.7961    0.6340    0.7059     22956\n",
      "\n",
      "   micro avg     0.7500    0.5965    0.6645     73869\n",
      "   macro avg     0.7135    0.4698    0.5263     73869\n",
      "weighted avg     0.7470    0.5965    0.6583     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "Saving model checkpoint to ./save_model/bilstm.pt\n",
      "\n",
      "Train Epoch[5] Step[6661 / 19085] - loss: 5.109543  \n",
      "Train Epoch[5] Step[6681 / 19085] - loss: 3.147011  \n",
      "Train Epoch[5] Step[6701 / 19085] - loss: 3.777711  \n",
      "Train Epoch[5] Step[6721 / 19085] - loss: 2.193183  \n",
      "Train Epoch[5] Step[6741 / 19085] - loss: 3.246344  \n",
      "Train Epoch[5] Step[6761 / 19085] - loss: 4.938185  \n",
      "Train Epoch[5] Step[6781 / 19085] - loss: 3.560799  \n",
      "Train Epoch[5] Step[6801 / 19085] - loss: 5.771866  \n",
      "Train Epoch[5] Step[6821 / 19085] - loss: 3.025255  \n",
      "Train Epoch[5] Step[6841 / 19085] - loss: 4.468872  \n",
      "Train Epoch[5] Step[6861 / 19085] - loss: 7.889788  \n",
      "Train Epoch[5] Step[6881 / 19085] - loss: 6.888827  \n",
      "Train Epoch[5] Step[6901 / 19085] - loss: 6.400579  \n",
      "Train Epoch[5] Step[6921 / 19085] - loss: 4.951070  \n",
      "Train Epoch[5] Step[6941 / 19085] - loss: 3.505191  \n",
      "Train Epoch[5] Step[6961 / 19085] - loss: 3.620815  \n",
      "Train Epoch[5] Step[6981 / 19085] - loss: 4.398614  \n",
      "Train Epoch[5] Step[7001 / 19085] - loss: 8.208982  \n",
      "Train Epoch[5] Step[7021 / 19085] - loss: 8.160289  \n",
      "Train Epoch[5] Step[7041 / 19085] - loss: 4.197842  \n",
      "Train Epoch[5] Step[7061 / 19085] - loss: 4.722466  \n",
      "Train Epoch[5] Step[7081 / 19085] - loss: 4.364442  \n",
      "Train Epoch[5] Step[7101 / 19085] - loss: 6.057718  \n",
      "Train Epoch[5] Step[7121 / 19085] - loss: 8.204635  \n",
      "Train Epoch[5] Step[7141 / 19085] - loss: 2.163406  \n",
      "Train Epoch[5] Step[7161 / 19085] - loss: 3.387139  \n",
      "Train Epoch[5] Step[7181 / 19085] - loss: 5.933352  \n",
      "Train Epoch[5] Step[7201 / 19085] - loss: 5.536302  \n",
      "Train Epoch[5] Step[7221 / 19085] - loss: 3.435459  \n",
      "Train Epoch[5] Step[7241 / 19085] - loss: 3.695614  \n",
      "Train Epoch[5] Step[7261 / 19085] - loss: 3.209627  \n",
      "Train Epoch[5] Step[7281 / 19085] - loss: 4.603370  \n",
      "Train Epoch[5] Step[7301 / 19085] - loss: 5.297481  \n",
      "Train Epoch[5] Step[7321 / 19085] - loss: 7.603127  \n",
      "Train Epoch[5] Step[7341 / 19085] - loss: 7.818080  \n",
      "Train Epoch[5] Step[7361 / 19085] - loss: 5.187245  \n",
      "Train Epoch[5] Step[7381 / 19085] - loss: 3.763628  \n",
      "Train Epoch[5] Step[7401 / 19085] - loss: 5.095963  \n",
      "Train Epoch[5] Step[7421 / 19085] - loss: 3.866563  \n",
      "Train Epoch[5] Step[7441 / 19085] - loss: 5.185121  \n",
      "Train Epoch[5] Step[7461 / 19085] - loss: 6.143899  \n",
      "Train Epoch[5] Step[7481 / 19085] - loss: 8.527690  \n",
      "Train Epoch[5] Step[7501 / 19085] - loss: 5.494751  \n",
      "Train Epoch[5] Step[7521 / 19085] - loss: 2.848555  \n",
      "Train Epoch[5] Step[7541 / 19085] - loss: 3.777040  \n",
      "Train Epoch[5] Step[7561 / 19085] - loss: 4.104609  \n",
      "Train Epoch[5] Step[7581 / 19085] - loss: 7.497680  \n",
      "Train Epoch[5] Step[7601 / 19085] - loss: 2.442394  \n",
      "Train Epoch[5] Step[7621 / 19085] - loss: 4.377818  \n",
      "Train Epoch[5] Step[7641 / 19085] - loss: 8.122885  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:09<00:00, 12.91it/s]\n",
      "Dev Loss: 5.003433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7194    0.5902    0.6485     26118\n",
      "         ORG     0.6306    0.0358    0.0677      1956\n",
      "         PER     0.7539    0.5901    0.6620     22839\n",
      "           T     0.8000    0.6289    0.7042     22956\n",
      "\n",
      "   micro avg     0.7553    0.5876    0.6609     73869\n",
      "   macro avg     0.7260    0.4613    0.5206     73869\n",
      "weighted avg     0.7528    0.5876    0.6546     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "Train Epoch[5] Step[7661 / 19085] - loss: 5.918900  \n",
      "Train Epoch[5] Step[7681 / 19085] - loss: 2.549587  \n",
      "Train Epoch[5] Step[7701 / 19085] - loss: 8.925095  \n",
      "Train Epoch[5] Step[7721 / 19085] - loss: 6.053659  \n",
      "Train Epoch[5] Step[7741 / 19085] - loss: 2.429906  \n",
      "Train Epoch[5] Step[7761 / 19085] - loss: 4.973161  \n",
      "Train Epoch[5] Step[7781 / 19085] - loss: 4.942109  \n",
      "Train Epoch[5] Step[7801 / 19085] - loss: 4.575399  \n",
      "Train Epoch[5] Step[7821 / 19085] - loss: 5.293634  \n",
      "Train Epoch[5] Step[7841 / 19085] - loss: 2.297589  \n",
      "Train Epoch[5] Step[7861 / 19085] - loss: 9.020475  \n",
      "Train Epoch[5] Step[7881 / 19085] - loss: 2.986897  \n",
      "Train Epoch[5] Step[7901 / 19085] - loss: 4.213294  \n",
      "Train Epoch[5] Step[7921 / 19085] - loss: 4.085190  \n",
      "Train Epoch[5] Step[7941 / 19085] - loss: 6.278738  \n",
      "Train Epoch[5] Step[7961 / 19085] - loss: 5.377750  \n",
      "Train Epoch[5] Step[7981 / 19085] - loss: 5.365964  \n",
      "Train Epoch[5] Step[8001 / 19085] - loss: 4.154971  \n",
      "Train Epoch[5] Step[8021 / 19085] - loss: 4.353000  \n",
      "Train Epoch[5] Step[8041 / 19085] - loss: 11.136874  \n",
      "Train Epoch[5] Step[8061 / 19085] - loss: 5.262833  \n",
      "Train Epoch[5] Step[8081 / 19085] - loss: 6.219012  \n",
      "Train Epoch[5] Step[8101 / 19085] - loss: 3.084228  \n",
      "Train Epoch[5] Step[8121 / 19085] - loss: 4.947779  \n",
      "Train Epoch[5] Step[8141 / 19085] - loss: 2.939310  \n",
      "Train Epoch[5] Step[8161 / 19085] - loss: 3.389576  \n",
      "Train Epoch[5] Step[8181 / 19085] - loss: 4.674407  \n",
      "Train Epoch[5] Step[8201 / 19085] - loss: 5.195827  \n",
      "Train Epoch[5] Step[8221 / 19085] - loss: 4.754513  \n",
      "Train Epoch[5] Step[8241 / 19085] - loss: 3.421434  \n",
      "Train Epoch[5] Step[8261 / 19085] - loss: 2.389967  \n",
      "Train Epoch[5] Step[8281 / 19085] - loss: 8.589727  \n",
      "Train Epoch[5] Step[8301 / 19085] - loss: 6.017671  \n",
      "Train Epoch[5] Step[8321 / 19085] - loss: 5.160454  \n",
      "Train Epoch[5] Step[8341 / 19085] - loss: 5.089574  \n",
      "Train Epoch[5] Step[8361 / 19085] - loss: 2.801484  \n",
      "Train Epoch[5] Step[8381 / 19085] - loss: 3.399718  \n",
      "Train Epoch[5] Step[8401 / 19085] - loss: 6.552156  \n",
      "Train Epoch[5] Step[8421 / 19085] - loss: 4.523038  \n",
      "Train Epoch[5] Step[8441 / 19085] - loss: 4.350391  \n",
      "Train Epoch[5] Step[8461 / 19085] - loss: 3.955655  \n",
      "Train Epoch[5] Step[8481 / 19085] - loss: 2.209095  \n",
      "Train Epoch[5] Step[8501 / 19085] - loss: 2.005312  \n",
      "Train Epoch[5] Step[8521 / 19085] - loss: 4.891399  \n",
      "Train Epoch[5] Step[8541 / 19085] - loss: 11.383764  \n",
      "Train Epoch[5] Step[8561 / 19085] - loss: 8.065150  \n",
      "Train Epoch[5] Step[8581 / 19085] - loss: 4.606241  \n",
      "Train Epoch[5] Step[8601 / 19085] - loss: 4.686250  \n",
      "Train Epoch[5] Step[8621 / 19085] - loss: 4.880336  \n",
      "Train Epoch[5] Step[8641 / 19085] - loss: 3.386092  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:43<00:00, 11.84it/s]\n",
      "Dev Loss: 4.994063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7199    0.5897    0.6484     26118\n",
      "         ORG     0.6207    0.0368    0.0695      1956\n",
      "         PER     0.7557    0.5884    0.6616     22839\n",
      "           T     0.7988    0.6300    0.7044     22956\n",
      "\n",
      "   micro avg     0.7557    0.5872    0.6609     73869\n",
      "   macro avg     0.7238    0.4612    0.5210     73869\n",
      "weighted avg     0.7529    0.5872    0.6546     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "Train Epoch[5] Step[8661 / 19085] - loss: 2.055200  \n",
      "Train Epoch[5] Step[8681 / 19085] - loss: 3.024168  \n",
      "Train Epoch[5] Step[8701 / 19085] - loss: 6.313316  \n",
      "Train Epoch[5] Step[8721 / 19085] - loss: 4.392396  \n",
      "Train Epoch[5] Step[8741 / 19085] - loss: 6.918998  \n",
      "Train Epoch[5] Step[8761 / 19085] - loss: 7.198596  \n",
      "Train Epoch[5] Step[8781 / 19085] - loss: 6.534794  \n",
      "Train Epoch[5] Step[8801 / 19085] - loss: 3.291996  \n",
      "Train Epoch[5] Step[8821 / 19085] - loss: 7.703720  \n",
      "Train Epoch[5] Step[8841 / 19085] - loss: 5.787191  \n",
      "Train Epoch[5] Step[8861 / 19085] - loss: 5.456008  \n",
      "Train Epoch[5] Step[8881 / 19085] - loss: 2.679447  \n",
      "Train Epoch[5] Step[8901 / 19085] - loss: 4.559997  \n",
      "Train Epoch[5] Step[8921 / 19085] - loss: 3.547480  \n",
      "Train Epoch[5] Step[8941 / 19085] - loss: 7.541137  \n",
      "Train Epoch[5] Step[8961 / 19085] - loss: 4.859032  \n",
      "Train Epoch[5] Step[8981 / 19085] - loss: 7.836093  \n",
      "Train Epoch[5] Step[9001 / 19085] - loss: 5.630527  \n",
      "Train Epoch[5] Step[9021 / 19085] - loss: 3.525010  \n",
      "Train Epoch[5] Step[9041 / 19085] - loss: 5.554931  \n",
      "Train Epoch[5] Step[9061 / 19085] - loss: 7.810683  \n",
      "Train Epoch[5] Step[9081 / 19085] - loss: 4.590074  \n",
      "Train Epoch[5] Step[9101 / 19085] - loss: 2.077248  \n",
      "Train Epoch[5] Step[9121 / 19085] - loss: 2.370337  \n",
      "Train Epoch[5] Step[9141 / 19085] - loss: 4.983739  \n",
      "Train Epoch[5] Step[9161 / 19085] - loss: 6.159357  \n",
      "Train Epoch[5] Step[9181 / 19085] - loss: 5.001264  \n",
      "Train Epoch[5] Step[9201 / 19085] - loss: 9.314794  \n",
      "Train Epoch[5] Step[9221 / 19085] - loss: 4.690675  \n",
      "Train Epoch[5] Step[9241 / 19085] - loss: 6.554729  \n",
      "Train Epoch[5] Step[9261 / 19085] - loss: 5.012903  \n",
      "Train Epoch[5] Step[9281 / 19085] - loss: 3.259419  \n",
      "Train Epoch[5] Step[9301 / 19085] - loss: 2.338922  \n",
      "Train Epoch[5] Step[9321 / 19085] - loss: 3.335829  \n",
      "Train Epoch[5] Step[9341 / 19085] - loss: 3.847051  \n",
      "Train Epoch[5] Step[9361 / 19085] - loss: 5.419294  \n",
      "Train Epoch[5] Step[9381 / 19085] - loss: 3.071275  \n",
      "Train Epoch[5] Step[9401 / 19085] - loss: 6.208763  \n",
      "Train Epoch[5] Step[9421 / 19085] - loss: 4.707709  \n",
      "Train Epoch[5] Step[9441 / 19085] - loss: 3.882536  \n",
      "Train Epoch[5] Step[9461 / 19085] - loss: 2.380082  \n",
      "Train Epoch[5] Step[9481 / 19085] - loss: 3.489937  \n",
      "Train Epoch[5] Step[9501 / 19085] - loss: 5.150559  \n",
      "Train Epoch[5] Step[9521 / 19085] - loss: 2.842797  \n",
      "Train Epoch[5] Step[9541 / 19085] - loss: 7.583569  \n",
      "Train Epoch[5] Step[9561 / 19085] - loss: 4.357732  \n",
      "Train Epoch[5] Step[9581 / 19085] - loss: 8.675684  \n",
      "Train Epoch[5] Step[9601 / 19085] - loss: 6.163269  \n",
      "Train Epoch[5] Step[9621 / 19085] - loss: 5.336103  \n",
      "Train Epoch[5] Step[9641 / 19085] - loss: 4.814355  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:10<00:00, 12.89it/s]\n",
      "Dev Loss: 4.981500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7173    0.5946    0.6502     26118\n",
      "         ORG     0.6190    0.0399    0.0749      1956\n",
      "         PER     0.7557    0.5909    0.6632     22839\n",
      "           T     0.8003    0.6280    0.7038     22956\n",
      "\n",
      "   micro avg     0.7549    0.5892    0.6618     73869\n",
      "   macro avg     0.7231    0.4633    0.5230     73869\n",
      "weighted avg     0.7524    0.5892    0.6556     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "Train Epoch[5] Step[9661 / 19085] - loss: 3.875000  \n",
      "Train Epoch[5] Step[9681 / 19085] - loss: 4.908758  \n",
      "Train Epoch[5] Step[9701 / 19085] - loss: 3.347556  \n",
      "Train Epoch[5] Step[9721 / 19085] - loss: 10.185667  \n",
      "Train Epoch[5] Step[9741 / 19085] - loss: 6.676622  \n",
      "Train Epoch[5] Step[9761 / 19085] - loss: 5.123528  \n",
      "Train Epoch[5] Step[9781 / 19085] - loss: 3.254775  \n",
      "Train Epoch[5] Step[9801 / 19085] - loss: 7.418010  \n",
      "Train Epoch[5] Step[9821 / 19085] - loss: 3.099689  \n",
      "Train Epoch[5] Step[9841 / 19085] - loss: 3.511868  \n",
      "Train Epoch[5] Step[9861 / 19085] - loss: 3.720494  \n",
      "Train Epoch[5] Step[9881 / 19085] - loss: 6.417029  \n",
      "Train Epoch[5] Step[9901 / 19085] - loss: 2.910816  \n",
      "Train Epoch[5] Step[9921 / 19085] - loss: 5.954816  \n",
      "Train Epoch[5] Step[9941 / 19085] - loss: 6.977222  \n",
      "Train Epoch[5] Step[9961 / 19085] - loss: 5.695898  \n",
      "Train Epoch[5] Step[9981 / 19085] - loss: 5.594198  \n",
      "Train Epoch[5] Step[10001 / 19085] - loss: 3.696792  \n",
      "Train Epoch[5] Step[10021 / 19085] - loss: 5.220876  \n",
      "Train Epoch[5] Step[10041 / 19085] - loss: 2.140180  \n",
      "Train Epoch[5] Step[10061 / 19085] - loss: 7.627283  \n",
      "Train Epoch[5] Step[10081 / 19085] - loss: 3.814000  \n",
      "Train Epoch[5] Step[10101 / 19085] - loss: 6.419114  \n",
      "Train Epoch[5] Step[10121 / 19085] - loss: 6.147120  \n",
      "Train Epoch[5] Step[10141 / 19085] - loss: 5.352157  \n",
      "Train Epoch[5] Step[10161 / 19085] - loss: 9.089351  \n",
      "Train Epoch[5] Step[10181 / 19085] - loss: 4.031887  \n",
      "Train Epoch[5] Step[10201 / 19085] - loss: 4.877387  \n",
      "Train Epoch[5] Step[10221 / 19085] - loss: 5.752141  \n",
      "Train Epoch[5] Step[10241 / 19085] - loss: 8.707949  \n",
      "Train Epoch[5] Step[10261 / 19085] - loss: 4.643940  \n",
      "Train Epoch[5] Step[10281 / 19085] - loss: 5.396762  \n",
      "Train Epoch[5] Step[10301 / 19085] - loss: 2.678923  \n",
      "Train Epoch[5] Step[10321 / 19085] - loss: 3.681495  \n",
      "Train Epoch[5] Step[10341 / 19085] - loss: 2.966469  \n",
      "Train Epoch[5] Step[10361 / 19085] - loss: 5.367107  \n",
      "Train Epoch[5] Step[10381 / 19085] - loss: 4.754713  \n",
      "Train Epoch[5] Step[10401 / 19085] - loss: 3.253266  \n",
      "Train Epoch[5] Step[10421 / 19085] - loss: 5.332792  \n",
      "Train Epoch[5] Step[10441 / 19085] - loss: 5.439267  \n",
      "Train Epoch[5] Step[10461 / 19085] - loss: 2.807013  \n",
      "Train Epoch[5] Step[10481 / 19085] - loss: 3.712511  \n",
      "Train Epoch[5] Step[10501 / 19085] - loss: 2.894321  \n",
      "Train Epoch[5] Step[10521 / 19085] - loss: 7.727810  \n",
      "Train Epoch[5] Step[10541 / 19085] - loss: 4.456131  \n",
      "Train Epoch[5] Step[10561 / 19085] - loss: 4.247730  \n",
      "Train Epoch[5] Step[10581 / 19085] - loss: 3.665617  \n",
      "Train Epoch[5] Step[10601 / 19085] - loss: 3.982628  \n",
      "Train Epoch[5] Step[10621 / 19085] - loss: 3.349559  \n",
      "Train Epoch[5] Step[10641 / 19085] - loss: 6.636859  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:37<00:00, 12.00it/s]\n",
      "Dev Loss: 4.973543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7161    0.5968    0.6510     26118\n",
      "         ORG     0.6087    0.0429    0.0802      1956\n",
      "         PER     0.7559    0.5896    0.6625     22839\n",
      "           T     0.8003    0.6282    0.7039     22956\n",
      "\n",
      "   micro avg     0.7544    0.5897    0.6620     73869\n",
      "   macro avg     0.7203    0.4644    0.5244     73869\n",
      "weighted avg     0.7517    0.5897    0.6559     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "Train Epoch[5] Step[10661 / 19085] - loss: 2.868291  \n",
      "Train Epoch[5] Step[10681 / 19085] - loss: 4.301731  \n",
      "Train Epoch[5] Step[10701 / 19085] - loss: 2.834031  \n",
      "Train Epoch[5] Step[10721 / 19085] - loss: 2.382896  \n",
      "Train Epoch[5] Step[10741 / 19085] - loss: 7.061000  \n",
      "Train Epoch[5] Step[10761 / 19085] - loss: 4.076103  \n",
      "Train Epoch[5] Step[10781 / 19085] - loss: 5.484612  \n",
      "Train Epoch[5] Step[10801 / 19085] - loss: 4.352663  \n",
      "Train Epoch[5] Step[10821 / 19085] - loss: 6.659321  \n",
      "Train Epoch[5] Step[10841 / 19085] - loss: 4.545351  \n",
      "Train Epoch[5] Step[10861 / 19085] - loss: 4.259559  \n",
      "Train Epoch[5] Step[10881 / 19085] - loss: 3.364674  \n",
      "Train Epoch[5] Step[10901 / 19085] - loss: 3.907453  \n",
      "Train Epoch[5] Step[10921 / 19085] - loss: 3.338886  \n",
      "Train Epoch[5] Step[10941 / 19085] - loss: 6.653343  \n",
      "Train Epoch[5] Step[10961 / 19085] - loss: 5.824544  \n",
      "Train Epoch[5] Step[10981 / 19085] - loss: 5.352058  \n",
      "Train Epoch[5] Step[11001 / 19085] - loss: 3.977675  \n",
      "Train Epoch[5] Step[11021 / 19085] - loss: 3.821782  \n",
      "Train Epoch[5] Step[11041 / 19085] - loss: 1.733203  \n",
      "Train Epoch[5] Step[11061 / 19085] - loss: 3.002028  \n",
      "Train Epoch[5] Step[11081 / 19085] - loss: 5.430411  \n",
      "Train Epoch[5] Step[11101 / 19085] - loss: 2.735245  \n",
      "Train Epoch[5] Step[11121 / 19085] - loss: 5.548021  \n",
      "Train Epoch[5] Step[11141 / 19085] - loss: 2.564377  \n",
      "Train Epoch[5] Step[11161 / 19085] - loss: 3.352091  \n",
      "Train Epoch[5] Step[11181 / 19085] - loss: 4.061067  \n",
      "Train Epoch[5] Step[11201 / 19085] - loss: 3.378812  \n",
      "Train Epoch[5] Step[11221 / 19085] - loss: 5.767869  \n",
      "Train Epoch[5] Step[11241 / 19085] - loss: 6.150285  \n",
      "Train Epoch[5] Step[11261 / 19085] - loss: 4.249275  \n",
      "Train Epoch[5] Step[11281 / 19085] - loss: 4.354391  \n",
      "Train Epoch[5] Step[11301 / 19085] - loss: 3.869230  \n",
      "Train Epoch[5] Step[11321 / 19085] - loss: 4.450867  \n",
      "Train Epoch[5] Step[11341 / 19085] - loss: 2.311559  \n",
      "Train Epoch[5] Step[11361 / 19085] - loss: 7.730221  \n",
      "Train Epoch[5] Step[11381 / 19085] - loss: 5.437845  \n",
      "Train Epoch[5] Step[11401 / 19085] - loss: 4.851404  \n",
      "Train Epoch[5] Step[11421 / 19085] - loss: 3.259239  \n",
      "Train Epoch[5] Step[11441 / 19085] - loss: 7.625646  \n",
      "Train Epoch[5] Step[11461 / 19085] - loss: 4.031133  \n",
      "Train Epoch[5] Step[11481 / 19085] - loss: 7.655349  \n",
      "Train Epoch[5] Step[11501 / 19085] - loss: 4.065038  \n",
      "Train Epoch[5] Step[11521 / 19085] - loss: 2.390560  \n",
      "Train Epoch[5] Step[11541 / 19085] - loss: 6.108702  \n",
      "Train Epoch[5] Step[11561 / 19085] - loss: 7.729735  \n",
      "Train Epoch[5] Step[11581 / 19085] - loss: 3.341560  \n",
      "Train Epoch[5] Step[11601 / 19085] - loss: 3.356567  \n",
      "Train Epoch[5] Step[11621 / 19085] - loss: 4.641622  \n",
      "Train Epoch[5] Step[11641 / 19085] - loss: 3.936918  \n",
      "\n",
      " Evaluating ...\n",
      "100%|███████████████████████████████████████| 4771/4771 [06:20<00:00, 12.54it/s]\n",
      "Dev Loss: 4.967972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7187    0.5951    0.6511     26118\n",
      "         ORG     0.6304    0.0445    0.0831      1956\n",
      "         PER     0.7534    0.5953    0.6651     22839\n",
      "           T     0.8020    0.6252    0.7026     22956\n",
      "\n",
      "   micro avg     0.7552    0.5899    0.6624     73869\n",
      "   macro avg     0.7261    0.4650    0.5255     73869\n",
      "weighted avg     0.7530    0.5899    0.6564     73869\n",
      "\n",
      "best f1: 0.66, current f1: 0.66\n",
      "\n",
      "\\Testing ...\n",
      "loading dev datasets\n",
      "100%|██████████████████████████████████| 28626/28626 [00:02<00:00, 11402.25it/s]\n",
      "100%|███████████████████████████████████████| 4771/4771 [02:01<00:00, 39.19it/s]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     0.7036    0.5932    0.6437     25888\n",
      "         ORG     0.5487    0.0316    0.0598      1961\n",
      "         PER     0.7380    0.5933    0.6578     22941\n",
      "           T     0.7980    0.6336    0.7063     23263\n",
      "\n",
      "   micro avg     0.7437    0.5910    0.6586     74053\n",
      "   macro avg     0.6971    0.4629    0.5169     74053\n",
      "weighted avg     0.7398    0.5910    0.6523     74053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab275ae-da9a-42a6-93d7-1ef558e6a317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
